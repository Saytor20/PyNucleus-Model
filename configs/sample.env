# PyNucleus Configuration
# Copy this file to .env and customize values as needed

# API Keys
PYNUCLEUS_API_KEY=your_api_key_here
OPENAI_API_KEY=your_openai_key_here
HUGGINGFACE_API_KEY=your_huggingface_key_here

# Vector Store Backend Configuration
VSTORE_BACKEND=faiss  # Options: faiss, qdrant

# Device Configuration
DEVICE_PREFERENCE=cpu        # Options: cpu, cuda
PYNUCLEUS_DEVICE=auto       # Options: cpu, cuda, auto
CUDA_VISIBLE_DEVICES=0      # GPU device ID for CUDA

# Model Configuration
PYNUCLEUS_DEFAULT_MODEL=Qwen/Qwen2.5-0.5B-Instruct
PYNUCLEUS_EMBEDDING_MODEL=all-MiniLM-L6-v2

# Model Selection Flags (set to true to enable when you have better hardware)
# Enable larger Qwen models (1.5B, 3B) - requires ~3-6GB RAM
PYNUCLEUS_ENABLE_LARGER_QWEN=false

# Enable DeepSeek models - requires ~3GB+ RAM
PYNUCLEUS_ENABLE_DEEPSEEK=false  

# Enable heavy models (7B+) - requires ~14GB+ RAM
PYNUCLEUS_ENABLE_HEAVY_MODELS=false

# Data Paths
PYNUCLEUS_DATA_DIR=data
PYNUCLEUS_INDEX_DIR=data/04_models

# Server Configuration
PYNUCLEUS_HOST=0.0.0.0
PYNUCLEUS_PORT=5000
PYNUCLEUS_DEBUG=false

# RAG Configuration
PYNUCLEUS_TOP_K=5
PYNUCLEUS_CHUNK_SIZE=1000
PYNUCLEUS_CHUNK_OVERLAP=200

# Remote Vector Store Configuration (Qdrant)
# QDRANT_URL=http://localhost:6333
# QDRANT_API_KEY=your_qdrant_key_here
# QDRANT_COLLECTION_NAME=pynucleus

# Performance Tuning
# TORCH_NUM_THREADS=4
# OMP_NUM_THREADS=4 