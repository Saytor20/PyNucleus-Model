{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# **PyNucleus Developer Notebook** üõ†Ô∏è\n",
    "\n",
    "## **Advanced Development Environment**\n",
    "\n",
    "This notebook provides advanced features, diagnostics, and development tools for PyNucleus developers and power users.\n",
    "\n",
    "### **üîß Developer Features:**\n",
    "- **System Diagnostics**: Comprehensive health checks and validation\n",
    "- **Enhanced Pipeline**: Advanced configuration and integration testing\n",
    "- **LLM Development**: Prompt engineering, model testing, and DSPy integration\n",
    "- **Performance Analysis**: Detailed metrics, benchmarking, and optimization\n",
    "- **Configuration Management**: Template creation and batch processing\n",
    "- **Debug Tools**: Advanced logging, tracing, and error analysis\n",
    "\n",
    "### **üìã Notebook Sections:**\n",
    "1. **System Initialization & Health Checks** (Cells 1-3)\n",
    "2. **Enhanced Pipeline & Configuration** (Cells 4-6)\n",
    "3. **Advanced Integration & Analysis** (Cells 7-9)\n",
    "4. **LLM Development & DSPy Workflow** (Cells 10-12)\n",
    "5. **Performance Analysis & Debug Tools** (Cells 13-15)\n",
    "\n",
    "### **üÜï Recent Updates (2025-06-18):**\n",
    "- ‚úÖ **Streamlined Initialization**: Aligned with Capstone Project structure\n",
    "- ‚úÖ **Enhanced Error Handling**: Better diagnostics and recovery\n",
    "- ‚úÖ **DSPy Integration**: Advanced LLM workflow development\n",
    "- ‚úÖ **Improved Performance Tools**: Better benchmarking and analysis\n",
    "\n",
    "---\n",
    "**‚ö†Ô∏è Note**: This is the advanced developer interface. For basic usage, use `Capstone Project.ipynb`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß PyNucleus Developer Environment - Advanced Initialization...\n",
      "üìÖ Session started: 2025-06-18 23:27:34\n",
      "‚úÖ All PyNucleus modules imported successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/mohammadalmusaiteer/PyNucleus-Model/src/pynucleus/rag/vector_store.py:340: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = SentenceTransformerEmbeddings(model_name='all-MiniLM-L6-v2')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Core components initialized\n",
      "‚úÖ Advanced components initialized\n",
      "üéØ Developer environment ready!\n",
      "üìä System Status: 1 files in results directory\n"
     ]
    }
   ],
   "source": [
    "# SECTION 1: System Initialization & Health Checks\n",
    "# ================================================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"üîß PyNucleus Developer Environment - Advanced Initialization...\")\n",
    "print(f\"üìÖ Session started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Add src to Python path\n",
    "src_path = str(Path().resolve() / 'src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "# Import PyNucleus components with enhanced error handling\n",
    "try:\n",
    "    # Core pipeline components (aligned with Capstone Project)\n",
    "    from pynucleus.pipeline import PipelineUtils\n",
    "    from pynucleus.integration.llm_output_generator import LLMOutputGenerator\n",
    "    \n",
    "    # Advanced developer components\n",
    "    from pynucleus.integration.config_manager import ConfigManager\n",
    "    from pynucleus.integration.dwsim_rag_integrator import DWSIMRAGIntegrator\n",
    "    from pynucleus.llm import LLMRunner\n",
    "    from pynucleus.llm.query_llm import LLMQueryManager\n",
    "    \n",
    "    print(\"‚úÖ All PyNucleus modules imported successfully\")\n",
    "    \n",
    "    # Initialize core components (matching Capstone Project pattern)\n",
    "    pipeline = PipelineUtils(results_dir=\"data/05_output/results\")\n",
    "    llm_generator = LLMOutputGenerator(results_dir=\"data/05_output/reports\")\n",
    "    \n",
    "    # Initialize advanced developer components\n",
    "    config_manager = ConfigManager(config_dir=\"configs\")\n",
    "    dwsim_rag_integrator = DWSIMRAGIntegrator(results_dir=\"data/05_output/results\")\n",
    "    \n",
    "    print(\"‚úÖ Core components initialized\")\n",
    "    print(\"‚úÖ Advanced components initialized\")\n",
    "    print(\"üéØ Developer environment ready!\")\n",
    "    \n",
    "    # Quick system health check\n",
    "    try:\n",
    "        quick_status = pipeline.quick_test()\n",
    "        print(f\"üìä System Status: {quick_status['csv_files_count']} files in results directory\")\n",
    "    except Exception as status_error:\n",
    "        print(f\"‚ö†Ô∏è Status check warning: {status_error}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import Error: {e}\")\n",
    "    print(\"üí° Please ensure you're in the PyNucleus-Model directory and all dependencies are installed\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Initialization error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    print(\"üí° Check system setup and try restarting the kernel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Running Advanced System Diagnostic...\n",
      "‚úÖ System diagnostic completed successfully\n",
      "\n",
      "üîç Manual System Health Checks:\n",
      "   ‚úÖ data/01_raw (16 items) - Raw data storage\n",
      "   ‚úÖ data/02_processed (20 items) - Processed data cache\n",
      "   ‚úÖ data/03_intermediate (4 items) - Intermediate results\n",
      "   ‚úÖ data/04_models (26 items) - Model artifacts\n",
      "   ‚úÖ data/05_output (150 items) - Pipeline outputs\n",
      "\n",
      "üèóÔ∏è Source Code Structure:\n",
      "   ‚úÖ src/pynucleus/pipeline (5 Python files) - Pipeline components\n",
      "   ‚úÖ src/pynucleus/rag (6 Python files) - RAG system\n",
      "   ‚úÖ src/pynucleus/integration (4 Python files) - Integration modules\n",
      "   ‚úÖ src/pynucleus/llm (10 Python files) - LLM components\n",
      "\n",
      "üêç Python Environment:\n",
      "   ‚Ä¢ Python Version: 3.13.1\n",
      "   ‚Ä¢ Working Directory: /Users/mohammadalmusaiteer/PyNucleus-Model\n",
      "   ‚Ä¢ PyNucleus Path: ‚úÖ Found\n",
      "\n",
      "üéØ ‚úÖ System diagnostic complete - All checks passed!\n"
     ]
    }
   ],
   "source": [
    "# SECTION 1.2: Advanced System Diagnostic & Health Check\n",
    "# ======================================================\n",
    "\n",
    "print(\"üîç Running Advanced System Diagnostic...\")\n",
    "\n",
    "# Enhanced system diagnostic with better error handling\n",
    "def run_system_diagnostic():\n",
    "    \"\"\"Run comprehensive system diagnostic with fallback options\"\"\"\n",
    "    try:\n",
    "        import subprocess\n",
    "        result = subprocess.run([\n",
    "            sys.executable, \"scripts/comprehensive_system_diagnostic.py\", \"--quiet\"\n",
    "        ], capture_output=True, text=True, cwd=\".\", timeout=30)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"‚úÖ System diagnostic completed successfully\")\n",
    "            lines = result.stdout.strip().split('\\n')\n",
    "            \n",
    "            # Extract and display key health metrics\n",
    "            health_metrics = []\n",
    "            for line in lines:\n",
    "                if any(keyword in line for keyword in ['Health:', 'Status:', 'EXCELLENT', 'GOOD', 'passed', 'Score:']):\n",
    "                    health_metrics.append(line.strip())\n",
    "            \n",
    "            if health_metrics:\n",
    "                print(\"üìä System Health Metrics:\")\n",
    "                for metric in health_metrics[-5:]:  # Show last 5 relevant metrics\n",
    "                    print(f\"   {metric}\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è System diagnostic detected issues:\")\n",
    "            if result.stderr:\n",
    "                print(f\"   Error: {result.stderr.strip()}\")\n",
    "            return False\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"‚ö†Ô∏è System diagnostic timed out (taking longer than expected)\")\n",
    "        return False\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ö†Ô∏è System diagnostic script not found\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è System diagnostic error: {e}\")\n",
    "        return False\n",
    "\n",
    "diagnostic_success = run_system_diagnostic()\n",
    "\n",
    "# Enhanced manual system checks\n",
    "print(f\"\\nüîç Manual System Health Checks:\")\n",
    "\n",
    "# Check critical data directories\n",
    "data_dirs = {\n",
    "    'data/01_raw': 'Raw data storage',\n",
    "    'data/02_processed': 'Processed data cache', \n",
    "    'data/03_intermediate': 'Intermediate results',\n",
    "    'data/04_models': 'Model artifacts',\n",
    "    'data/05_output': 'Pipeline outputs'\n",
    "}\n",
    "\n",
    "for dir_path, description in data_dirs.items():\n",
    "    exists = Path(dir_path).exists()\n",
    "    if exists:\n",
    "        file_count = len(list(Path(dir_path).rglob(\"*\")))\n",
    "        print(f\"   ‚úÖ {dir_path} ({file_count} items) - {description}\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå {dir_path} - Missing! {description}\")\n",
    "\n",
    "# Check source code structure\n",
    "src_dirs = {\n",
    "    'src/pynucleus/pipeline': 'Pipeline components',\n",
    "    'src/pynucleus/rag': 'RAG system',\n",
    "    'src/pynucleus/integration': 'Integration modules',\n",
    "    'src/pynucleus/llm': 'LLM components'\n",
    "}\n",
    "\n",
    "print(f\"\\nüèóÔ∏è Source Code Structure:\")\n",
    "for dir_path, description in src_dirs.items():\n",
    "    exists = Path(dir_path).exists()\n",
    "    if exists:\n",
    "        py_files = len(list(Path(dir_path).glob(\"*.py\")))\n",
    "        print(f\"   ‚úÖ {dir_path} ({py_files} Python files) - {description}\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå {dir_path} - Missing! {description}\")\n",
    "\n",
    "# System environment check\n",
    "print(f\"\\nüêç Python Environment:\")\n",
    "print(f\"   ‚Ä¢ Python Version: {sys.version.split()[0]}\")\n",
    "print(f\"   ‚Ä¢ Working Directory: {Path.cwd()}\")\n",
    "print(f\"   ‚Ä¢ PyNucleus Path: {'‚úÖ Found' if src_path in sys.path else '‚ùå Not in path'}\")\n",
    "\n",
    "print(f\"\\nüéØ {'‚úÖ System diagnostic complete - All checks passed!' if diagnostic_success else '‚ö†Ô∏è System diagnostic complete - Some issues detected'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Detailed Pipeline Status Check...\n",
      "\n",
      "==================================================\n",
      "üìÅ Results Directory: data/05_output/results\n",
      "üìÑ CSV Files: 1\n",
      "\n",
      "üìã Existing Files:\n",
      "   ‚Ä¢ dev_simulation_config.csv (171 bytes)\n",
      "\n",
      "üîß Component Health:\n",
      "   ‚Ä¢ Pipeline Utils: ‚úÖ\n",
      "   ‚Ä¢ RAG Pipeline: ‚úÖ\n",
      "   ‚Ä¢ DWSIM Pipeline: ‚úÖ\n",
      "   ‚Ä¢ Config Manager: ‚úÖ\n",
      "   ‚Ä¢ DWSIM-RAG Integrator: ‚úÖ\n",
      "   ‚Ä¢ LLM Generator: ‚úÖ\n",
      "\n",
      "üîç Pipeline Component Status:\n",
      "   ‚Ä¢ RAG Pipeline: ‚ùå\n",
      "   ‚Ä¢ DWSIM Pipeline: ‚ùå\n",
      "   ‚Ä¢ Results Exporter: ‚ùå\n",
      "\n",
      "üîó Integration Status:\n",
      "   ‚Ä¢ Total RAG Chunks: 0\n",
      "   ‚Ä¢ Simulation Chunks: 0\n",
      "   ‚Ä¢ Integration Active: ‚ö™\n",
      "\n",
      "‚úÖ Status check complete!\n"
     ]
    }
   ],
   "source": [
    "# SECTION 1.3: Pipeline Status and Health Check\n",
    "# =============================================\n",
    "\n",
    "print(\"üìä Detailed Pipeline Status Check...\")\n",
    "\n",
    "try:\n",
    "    # Quick test with validation (this method exists)\n",
    "    test_results = pipeline.quick_test()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    \n",
    "    # Validate test_results\n",
    "    if test_results is None:\n",
    "        print(\"‚ùå Quick test returned None - pipeline may not be properly initialized\")\n",
    "        test_results = {\n",
    "            'results_dir': 'data/05_output/results',\n",
    "            'csv_files_count': 0,\n",
    "            'csv_files': []\n",
    "        }\n",
    "    \n",
    "    # Safely access results with fallbacks\n",
    "    results_dir = test_results.get('results_dir', 'data/05_output/results')\n",
    "    csv_files_count = test_results.get('csv_files_count', 0)\n",
    "    csv_files = test_results.get('csv_files', [])\n",
    "    \n",
    "    print(f\"üìÅ Results Directory: {results_dir}\")\n",
    "    print(f\"üìÑ CSV Files: {csv_files_count}\")\n",
    "    \n",
    "    if csv_files_count > 0:\n",
    "        print(\"\\nüìã Existing Files:\")\n",
    "        for file_info in csv_files:\n",
    "            if isinstance(file_info, dict):\n",
    "                name = file_info.get('name', 'Unknown')\n",
    "                size = file_info.get('size', 0)\n",
    "                print(f\"   ‚Ä¢ {name} ({size} bytes)\")\n",
    "            else:\n",
    "                print(f\"   ‚Ä¢ {file_info}\")\n",
    "    \n",
    "    # Component health check\n",
    "    print(f\"\\nüîß Component Health:\")\n",
    "    print(f\"   ‚Ä¢ Pipeline Utils: {'‚úÖ' if pipeline else '‚ùå'}\")\n",
    "    print(f\"   ‚Ä¢ RAG Pipeline: {'‚úÖ' if hasattr(pipeline, 'rag_pipeline') and pipeline.rag_pipeline else '‚ùå'}\")\n",
    "    print(f\"   ‚Ä¢ DWSIM Pipeline: {'‚úÖ' if hasattr(pipeline, 'dwsim_pipeline') and pipeline.dwsim_pipeline else '‚ùå'}\")\n",
    "    print(f\"   ‚Ä¢ Config Manager: {'‚úÖ' if 'config_manager' in locals() and config_manager else '‚ùå'}\")\n",
    "    print(f\"   ‚Ä¢ DWSIM-RAG Integrator: {'‚úÖ' if 'dwsim_rag_integrator' in locals() and dwsim_rag_integrator else '‚ùå'}\")\n",
    "    print(f\"   ‚Ä¢ LLM Generator: {'‚úÖ' if 'llm_generator' in locals() and llm_generator else '‚ùå'}\")\n",
    "    \n",
    "    # Additional pipeline status info\n",
    "    component_status = test_results.get('component_status', {})\n",
    "    print(f\"\\nüîç Pipeline Component Status:\")\n",
    "    print(f\"   ‚Ä¢ RAG Pipeline: {'‚úÖ' if component_status.get('rag_pipeline', False) else '‚ùå'}\")\n",
    "    print(f\"   ‚Ä¢ DWSIM Pipeline: {'‚úÖ' if component_status.get('dwsim_pipeline', False) else '‚ùå'}\")\n",
    "    print(f\"   ‚Ä¢ Results Exporter: {'‚úÖ' if component_status.get('exporter', False) else '‚ùå'}\")\n",
    "    \n",
    "    # Integration status\n",
    "    integration_enabled = test_results.get('integration_enabled', False)\n",
    "    rag_chunks = test_results.get('rag_chunks', 0)\n",
    "    simulation_chunks = test_results.get('simulation_chunks', 0)\n",
    "    \n",
    "    print(f\"\\nüîó Integration Status:\")\n",
    "    print(f\"   ‚Ä¢ Total RAG Chunks: {rag_chunks:,}\")\n",
    "    print(f\"   ‚Ä¢ Simulation Chunks: {simulation_chunks:,}\")\n",
    "    print(f\"   ‚Ä¢ Integration Active: {'‚úÖ' if integration_enabled else '‚ö™'}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Status check complete!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Status check error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    \n",
    "    # Provide troubleshooting tips\n",
    "    print(\"\\nüîß Troubleshooting Tips:\")\n",
    "    print(\"   1. Try restarting the notebook kernel\")\n",
    "    print(\"   2. Re-run Cell 1 to reinitialize components\")\n",
    "    print(\"   3. Check if all required directories exist\")\n",
    "    print(\"   4. Verify PyNucleus installation is complete\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## **SECTION 2: Enhanced Pipeline Configuration** üîß\n",
    "\n",
    "Advanced configuration management and template generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Advanced Configuration Management...\n",
      "üìã Existing Configuration Files: 3\n",
      "   ‚Ä¢ dev_simulation_config.csv\n",
      "   ‚Ä¢ dev_simulation_config.json\n",
      "   ‚Ä¢ perf_test.json\n",
      "‚úÖ JSON template created: configs/dev_simulation_config.json\n",
      "‚úÖ CSV template created: configs/dev_simulation_config.csv\n",
      "\n",
      "üìã JSON Template Preview:\n",
      "{\n",
      "  \"simulations\": [\n",
      "    {\n",
      "      \"case_name\": \"dev_test_case_1\",\n",
      "      \"temperature\": 350.0,\n",
      "      \"pressure\": 2.5,\n",
      "      \"feed_rate\": 100.0,\n",
      "      \"catalyst_type\": \"Pt/Al2O3\",\n",
      "      \"process_type\": \"distillation\"\n",
      "    },\n",
      "    {\n",
      "      \"case_name\": \"dev_test_case_2\",\n",
      "      \"temperature\": 375.0,\n",
      "      \"...\n",
      "\n",
      "üîÑ Template validation: 2 simulations loaded\n",
      "\n",
      "‚úÖ Configuration management ready!\n"
     ]
    }
   ],
   "source": [
    "# SECTION 2.1: Configuration Templates and Management\n",
    "# ===================================================\n",
    "\n",
    "print(\"üîß Advanced Configuration Management...\")\n",
    "\n",
    "# Create configuration templates\n",
    "try:\n",
    "    # List existing configuration files\n",
    "    existing_configs = config_manager.list_configs()\n",
    "    print(f\"üìã Existing Configuration Files: {len(existing_configs)}\")\n",
    "    for config_file in existing_configs:\n",
    "        print(f\"   ‚Ä¢ {config_file}\")\n",
    "    \n",
    "    # Create a sample configuration template\n",
    "    sample_config = {\n",
    "        \"simulations\": [\n",
    "            {\n",
    "                \"case_name\": \"dev_test_case_1\",\n",
    "                \"temperature\": 350.0,\n",
    "                \"pressure\": 2.5,\n",
    "                \"feed_rate\": 100.0,\n",
    "                \"catalyst_type\": \"Pt/Al2O3\",\n",
    "                \"process_type\": \"distillation\"\n",
    "            },\n",
    "            {\n",
    "                \"case_name\": \"dev_test_case_2\", \n",
    "                \"temperature\": 375.0,\n",
    "                \"pressure\": 3.0,\n",
    "                \"feed_rate\": 120.0,\n",
    "                \"catalyst_type\": \"Pd/C\",\n",
    "                \"process_type\": \"reaction\"\n",
    "            }\n",
    "        ],\n",
    "        \"metadata\": {\n",
    "            \"created_by\": \"Developer_Notebook\",\n",
    "            \"version\": \"1.0\",\n",
    "            \"description\": \"Development configuration template\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save JSON template\n",
    "    json_template_path = config_manager.save(sample_config, \"dev_simulation_config.json\")\n",
    "    print(f\"‚úÖ JSON template created: {json_template_path}\")\n",
    "    \n",
    "    # Save CSV template (will extract simulations data)\n",
    "    csv_template_path = config_manager.save(sample_config, \"dev_simulation_config.csv\")\n",
    "    print(f\"‚úÖ CSV template created: {csv_template_path}\")\n",
    "    \n",
    "    # Show template contents (first few lines)\n",
    "    if json_template_path.exists():\n",
    "        with open(json_template_path, 'r') as f:\n",
    "            content = f.read()[:300]\n",
    "            print(f\"\\nüìã JSON Template Preview:\")\n",
    "            print(content + \"...\" if len(content) >= 300 else content)\n",
    "    \n",
    "    # Test loading the configuration back\n",
    "    loaded_config = config_manager.load(\"dev_simulation_config.json\")\n",
    "    print(f\"\\nüîÑ Template validation: {len(loaded_config['simulations'])} simulations loaded\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Configuration error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n‚úÖ Configuration management ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Running Enhanced Pipeline for Advanced Development Testing...\n",
      "\n",
      "üìä This enhanced run includes:\n",
      "   ‚Ä¢ Document processing with real FAISS vector store\n",
      "   ‚Ä¢ DWSIM chemical process simulations\n",
      "   ‚Ä¢ Advanced integration and analysis\n",
      "   ‚Ä¢ Performance metrics and validation\n",
      "\n",
      "‚è≥ Please wait... Enhanced analysis may take 30-60 seconds.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to export RAG results: Object of type float32 is not JSON serializable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéâ Pipeline completed successfully in 14.3 seconds!\n",
      "\n",
      "üìä Detailed Results Analysis:\n",
      "   ‚Ä¢ RAG Document Queries: 3\n",
      "   ‚Ä¢ DWSIM Simulations: 3\n",
      "   ‚Ä¢ Export Files Generated: 1\n",
      "   ‚Ä¢ Total Processing Time: 14.3s\n",
      "\n",
      "üîó Advanced Integration:\n",
      "   ‚Ä¢ RAG pipeline connected to integrator\n",
      "   ‚Ä¢ Ready for enhanced analysis workflows\n",
      "   ‚Ä¢ Processing Rate: 0.42 items/second\n",
      "\n",
      "‚úÖ Pipeline data ready for advanced developer analysis\n",
      "\n",
      "‚úÖ Enhanced pipeline testing complete!\n"
     ]
    }
   ],
   "source": [
    "# SECTION 2.2: Run Enhanced Pipeline with Advanced Analytics\n",
    "# ==========================================================\n",
    "\n",
    "print(\"üöÄ Running Enhanced Pipeline for Advanced Development Testing...\")\n",
    "print(\"\\nüìä This enhanced run includes:\")\n",
    "print(\"   ‚Ä¢ Document processing with real FAISS vector store\")\n",
    "print(\"   ‚Ä¢ DWSIM chemical process simulations\")\n",
    "print(\"   ‚Ä¢ Advanced integration and analysis\")\n",
    "print(\"   ‚Ä¢ Performance metrics and validation\")\n",
    "print(\"\\n‚è≥ Please wait... Enhanced analysis may take 30-60 seconds.\\n\")\n",
    "\n",
    "# Enhanced pipeline execution with comprehensive error handling\n",
    "try:\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    # Execute core pipeline (matching Capstone Project pattern)\n",
    "    results = pipeline.run_complete_pipeline()\n",
    "    \n",
    "    if results:\n",
    "        duration = (datetime.now() - start_time).total_seconds()\n",
    "        print(f\"\\nüéâ Pipeline completed successfully in {duration:.1f} seconds!\")\n",
    "        \n",
    "        # Enhanced results analysis\n",
    "        print(f\"\\nüìä Detailed Results Analysis:\")\n",
    "        rag_count = len(results.get('rag_data', []))\n",
    "        dwsim_count = len(results.get('dwsim_data', []))\n",
    "        files_count = len(results.get('exported_files', []))\n",
    "        \n",
    "        print(f\"   ‚Ä¢ RAG Document Queries: {rag_count}\")\n",
    "        print(f\"   ‚Ä¢ DWSIM Simulations: {dwsim_count}\")\n",
    "        print(f\"   ‚Ä¢ Export Files Generated: {files_count}\")\n",
    "        print(f\"   ‚Ä¢ Total Processing Time: {results.get('duration', duration):.1f}s\")\n",
    "        \n",
    "        # Advanced integration setup (developer feature)\n",
    "        try:\n",
    "            # Set up integrator with pipeline data for advanced analysis\n",
    "            if hasattr(pipeline, 'rag_pipeline') and pipeline.rag_pipeline:\n",
    "                dwsim_rag_integrator.rag_pipeline = pipeline.rag_pipeline\n",
    "                print(\"\\nüîó Advanced Integration:\")\n",
    "                print(\"   ‚Ä¢ RAG pipeline connected to integrator\")\n",
    "                print(\"   ‚Ä¢ Ready for enhanced analysis workflows\")\n",
    "            \n",
    "            # Performance metrics\n",
    "            if rag_count > 0 and dwsim_count > 0:\n",
    "                processing_rate = (rag_count + dwsim_count) / duration\n",
    "                print(f\"   ‚Ä¢ Processing Rate: {processing_rate:.2f} items/second\")\n",
    "            \n",
    "        except Exception as integration_error:\n",
    "            print(f\"\\n‚ö†Ô∏è Integration setup warning: {integration_error}\")\n",
    "        \n",
    "        print(\"\\n‚úÖ Pipeline data ready for advanced developer analysis\")\n",
    "        \n",
    "        # Store results for next sections\n",
    "        global enhanced_pipeline_results\n",
    "        enhanced_pipeline_results = results\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Pipeline execution failed\")\n",
    "        print(\"üí° Check system initialization and try running Cell 1 again\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Enhanced pipeline error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    print(\"\\nüí° Troubleshooting tips:\")\n",
    "    print(\"   ‚Ä¢ Ensure all components were initialized successfully in Cell 1\")\n",
    "    print(\"   ‚Ä¢ Check that data directories exist and are accessible\")\n",
    "    print(\"   ‚Ä¢ Try restarting the kernel and re-running all cells\")\n",
    "\n",
    "print(\"\\n‚úÖ Enhanced pipeline testing complete!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## **SECTION 3: Advanced Analysis & Integration** üî¨\n",
    "\n",
    "DWSIM-RAG integration, financial analysis, and enhanced reporting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ Advanced DWSIM-RAG Integration Analysis...\n",
      "üìä Processing 3 DWSIM simulations...\n",
      "‚úÖ Enhanced integration complete:\n",
      "   ‚Ä¢ Integrated simulations: 3\n",
      "   ‚Ä¢ Export file: data/05_output/results/integrated_results_20250618_232806.json\n",
      "\n",
      "üìã Sample Analysis (First Simulation):\n",
      "   ‚Ä¢ Case: distillation_ethanol_water\n",
      "   üìä Performance Metrics:\n",
      "      ‚Ä¢ Conversion: 0.850\n",
      "      ‚Ä¢ Selectivity: 0.920\n",
      "      ‚Ä¢ Yield: 0.782\n",
      "      ‚Ä¢ Overall Performance: Good\n",
      "      ‚Ä¢ Efficiency Rating: High\n",
      "      ‚Ä¢ Temperature Rating: Suboptimal\n",
      "      ‚Ä¢ Pressure Rating: Optimal\n",
      "\n",
      "‚úÖ Advanced integration analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# SECTION 3.1: DWSIM-RAG Integration and Enhanced Analysis\n",
    "# ========================================================\n",
    "\n",
    "print(\"üî¨ Advanced DWSIM-RAG Integration Analysis...\")\n",
    "\n",
    "try:\n",
    "    # Get DWSIM results\n",
    "    dwsim_results = pipeline.dwsim_pipeline.get_results()\n",
    "    \n",
    "    if dwsim_results:\n",
    "        print(f\"üìä Processing {len(dwsim_results)} DWSIM simulations...\")\n",
    "        \n",
    "        # Perform enhanced integration\n",
    "        integrated_results = dwsim_rag_integrator.integrate_simulation_results(\n",
    "            dwsim_results, perform_rag_analysis=True\n",
    "        )\n",
    "        \n",
    "        # Export integrated results\n",
    "        integrated_export_file = dwsim_rag_integrator.export_integrated_results()\n",
    "        \n",
    "        print(f\"‚úÖ Enhanced integration complete:\")\n",
    "        print(f\"   ‚Ä¢ Integrated simulations: {len(integrated_results)}\")\n",
    "        print(f\"   ‚Ä¢ Export file: {integrated_export_file}\")\n",
    "        \n",
    "        # Show detailed analysis for first simulation\n",
    "        if integrated_results:\n",
    "            sample = integrated_results[0]\n",
    "            print(f\"\\nüìã Sample Analysis (First Simulation):\")\n",
    "            \n",
    "            # Safely access original simulation data\n",
    "            original_sim = sample.get('original_simulation', {})\n",
    "            print(f\"   ‚Ä¢ Case: {original_sim.get('case_name', 'Unknown')}\")\n",
    "            \n",
    "            # Performance metrics\n",
    "            perf_metrics = sample.get('performance_metrics', {})\n",
    "            if perf_metrics:\n",
    "                print(f\"   üìä Performance Metrics:\")\n",
    "                for key, value in perf_metrics.items():\n",
    "                    display_key = key.replace('_', ' ').title()\n",
    "                    if isinstance(value, (int, float)):\n",
    "                        if 'rate' in key.lower() or 'percentage' in key.lower():\n",
    "                            print(f\"      ‚Ä¢ {display_key}: {value:.1f}%\")\n",
    "                        elif isinstance(value, float):\n",
    "                            print(f\"      ‚Ä¢ {display_key}: {value:.3f}\")\n",
    "                        else:\n",
    "                            print(f\"      ‚Ä¢ {display_key}: {value}\")\n",
    "                    else:\n",
    "                        print(f\"      ‚Ä¢ {display_key}: {value}\")\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è No performance metrics available\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No DWSIM results available. Run Section 2.2 first.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Integration error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n‚úÖ Advanced integration analysis complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí∞ Advanced Financial Analysis and LLM Report Generation...\n",
      "üìÑ Generating LLM reports for 3 simulations...\n",
      "   ‚úÖ Report 1: llm_analysis_distillation_ethanol_water_20250618_232806.md\n",
      "   ‚úÖ Report 2: llm_analysis_methanol_synthesis_20250618_232806.md\n",
      "   ‚úÖ Report 3: llm_analysis_heat_exchanger_optimization_20250618_232806.md\n",
      "\n",
      "üí∞ Comprehensive Financial Metrics:\n",
      "   ‚Ä¢ Average Recovery Rate: 85.0%\n",
      "   ‚Ä¢ Estimated Daily Revenue: $997,050.00\n",
      "   ‚Ä¢ Estimated Daily Profit: $-2,950.00\n",
      "   ‚Ä¢ Return on Investment: -43.2%\n",
      "   ‚Ä¢ Financial Analysis File: data/05_output/reports/financial_analysis_20250618_232806.md\n",
      "\n",
      "üìÑ Generated Files:\n",
      "   ‚Ä¢ LLM Reports: 3 files\n",
      "   ‚Ä¢ Financial Analysis: 1 file\n",
      "\n",
      "‚úÖ Advanced analysis and reporting complete!\n"
     ]
    }
   ],
   "source": [
    "# SECTION 3.2: LLM Report Generation and Financial Analysis\n",
    "# =========================================================\n",
    "\n",
    "print(\"üí∞ Advanced Financial Analysis and LLM Report Generation...\")\n",
    "\n",
    "try:\n",
    "    if 'integrated_results' in locals() and integrated_results:\n",
    "        \n",
    "        # Generate LLM reports for all simulations\n",
    "        print(f\"üìÑ Generating LLM reports for {len(integrated_results)} simulations...\")\n",
    "        \n",
    "        llm_report_files = []\n",
    "        for i, result in enumerate(integrated_results):\n",
    "            try:\n",
    "                report_file = llm_generator.export_llm_ready_text(result)\n",
    "                llm_report_files.append(report_file)\n",
    "                print(f\"   ‚úÖ Report {i+1}: {Path(report_file).name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Report {i+1} failed: {e}\")\n",
    "        \n",
    "        # Generate comprehensive financial analysis\n",
    "        financial_file = llm_generator.export_financial_analysis(integrated_results)\n",
    "        metrics = llm_generator._calculate_key_metrics(integrated_results)\n",
    "        \n",
    "        print(f\"\\nüí∞ Comprehensive Financial Metrics:\")\n",
    "        print(f\"   ‚Ä¢ Average Recovery Rate: {metrics['avg_recovery']:.1f}%\")\n",
    "        print(f\"   ‚Ä¢ Estimated Daily Revenue: ${metrics['estimated_revenue']:,.2f}\")\n",
    "        print(f\"   ‚Ä¢ Estimated Daily Profit: ${metrics['net_profit']:,.2f}\")\n",
    "        print(f\"   ‚Ä¢ Return on Investment: {metrics['roi']:.1f}%\")\n",
    "        print(f\"   ‚Ä¢ Financial Analysis File: {financial_file}\")\n",
    "        \n",
    "        print(f\"\\nüìÑ Generated Files:\")\n",
    "        print(f\"   ‚Ä¢ LLM Reports: {len(llm_report_files)} files\")\n",
    "        print(f\"   ‚Ä¢ Financial Analysis: 1 file\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No integrated results available. Run Section 3.1 first.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå LLM/Financial analysis error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n‚úÖ Advanced analysis and reporting complete!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## **SECTION 4: LLM Development & DSPy Workflow** ü§ñ\n",
    "\n",
    "Advanced LLM model testing, DSPy integration, prompt engineering, and intelligent query development.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ LLM Development Environment & DSPy Workflow Initialization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM Runner initialized\n",
      "‚úÖ LLM Query Manager initialized\n",
      "‚ö†Ô∏è DSPy modules not available: cannot import name 'PyNucleusDSPyProgram' from 'pynucleus.llm.dspy_program' (/Users/mohammadalmusaiteer/PyNucleus-Model/src/pynucleus/llm/dspy_program.py)\n",
      "\n",
      "üîß Model Information:\n",
      "   ‚Ä¢ Model ID: Qwen/Qwen2.5-1.5B-Instruct\n",
      "   ‚Ä¢ Device: cpu\n",
      "   ‚Ä¢ Dtype: torch.float32\n",
      "   ‚Ä¢ Num Parameters: 1,543,714,304\n",
      "   ‚Ä¢ Memory: 5888.8 MB\n",
      "\n",
      "üìã Prompt System Test:\n",
      "   ‚Ä¢ Template rendering: ‚úÖ Success\n",
      "   ‚Ä¢ Prompt length: 108 characters\n",
      "   ‚Ä¢ Vocabulary Size: 151,665\n",
      "\n",
      "üß† DSPy Workflow Status:\n",
      "   ‚Ä¢ DSPy Available: ‚ùå\n",
      "   ‚Ä¢ Advanced DSPy workflows not available in this session\n",
      "\n",
      "‚úÖ LLM development environment ready!\n"
     ]
    }
   ],
   "source": [
    "# SECTION 4.1: LLM Model Testing, Initialization & DSPy Integration\n",
    "# ================================================================\n",
    "\n",
    "print(\"ü§ñ LLM Development Environment & DSPy Workflow Initialization...\")\n",
    "\n",
    "try:\n",
    "    # Initialize core LLM components\n",
    "    llm_runner = LLMRunner()\n",
    "    llm_query_manager = LLMQueryManager()\n",
    "    \n",
    "    print(f\"‚úÖ LLM Runner initialized\")\n",
    "    print(f\"‚úÖ LLM Query Manager initialized\")\n",
    "    \n",
    "    # Try to initialize DSPy components if available\n",
    "    dspy_available = False\n",
    "    try:\n",
    "        from pynucleus.llm.dspy_program import PyNucleusDSPyProgram\n",
    "        from pynucleus.llm.answer_engine import AnswerEngine\n",
    "        from pynucleus.llm.device_manager import DeviceManager\n",
    "        \n",
    "        # Initialize DSPy components\n",
    "        device_manager = DeviceManager()\n",
    "        answer_engine = AnswerEngine()\n",
    "        \n",
    "        print(f\"‚úÖ DSPy Program Module available\")\n",
    "        print(f\"‚úÖ Answer Engine initialized\")\n",
    "        print(f\"‚úÖ Device Manager initialized\")\n",
    "        \n",
    "        dspy_available = True\n",
    "        \n",
    "    except ImportError as dspy_error:\n",
    "        print(f\"‚ö†Ô∏è DSPy modules not available: {dspy_error}\")\n",
    "        dspy_available = False\n",
    "    except Exception as dspy_error:\n",
    "        print(f\"‚ö†Ô∏è DSPy initialization warning: {dspy_error}\")\n",
    "        dspy_available = False\n",
    "    \n",
    "    # Get model information\n",
    "    model_info = llm_runner.get_model_info()\n",
    "    print(f\"\\nüîß Model Information:\")\n",
    "    print(f\"   ‚Ä¢ Model ID: {model_info['model_id']}\")\n",
    "    \n",
    "    # Display available model metrics\n",
    "    for key, value in model_info.items():\n",
    "        if key not in ['model_id', 'error']:\n",
    "            if key == 'num_parameters' and isinstance(value, int):\n",
    "                print(f\"   ‚Ä¢ {key.replace('_', ' ').title()}: {value:,}\")\n",
    "            elif key == 'memory_footprint' and isinstance(value, int):\n",
    "                print(f\"   ‚Ä¢ Memory: {value / 1024 / 1024:.1f} MB\")\n",
    "            else:\n",
    "                print(f\"   ‚Ä¢ {key.replace('_', ' ').title()}: {value}\")\n",
    "    \n",
    "    # Check for model errors\n",
    "    if 'error' in model_info:\n",
    "        print(f\"   ‚ö†Ô∏è Model Info Error: {model_info['error']}\")\n",
    "    \n",
    "    # Test prompt system\n",
    "    test_prompt = llm_query_manager._create_general_query_prompt(\n",
    "        question=\"Test chemical process optimization query\",\n",
    "        context=\"You are a chemical engineering expert.\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüìã Prompt System Test:\")\n",
    "    print(f\"   ‚Ä¢ Template rendering: ‚úÖ Success\")\n",
    "    print(f\"   ‚Ä¢ Prompt length: {len(test_prompt)} characters\")\n",
    "    \n",
    "    # Test tokenizer if available\n",
    "    if hasattr(llm_runner, 'tokenizer') and llm_runner.tokenizer:\n",
    "        vocab_size = len(llm_runner.tokenizer)\n",
    "        print(f\"   ‚Ä¢ Vocabulary Size: {vocab_size:,}\")\n",
    "    \n",
    "    # DSPy workflow status\n",
    "    print(f\"\\nüß† DSPy Workflow Status:\")\n",
    "    print(f\"   ‚Ä¢ DSPy Available: {'‚úÖ' if dspy_available else '‚ùå'}\")\n",
    "    if dspy_available:\n",
    "        print(f\"   ‚Ä¢ Answer Engine: Ready for advanced query processing\")\n",
    "        try:\n",
    "            device_info = device_manager.get_device_info()\n",
    "            print(f\"   ‚Ä¢ Device Manager: {device_info}\")\n",
    "        except:\n",
    "            print(f\"   ‚Ä¢ Device Manager: Initialized\")\n",
    "    else:\n",
    "        print(f\"   ‚Ä¢ Advanced DSPy workflows not available in this session\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå LLM initialization error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n‚úÖ LLM development environment ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Advanced Prompt Engineering and Testing...\n",
      "üß™ Testing 3 prompt scenarios...\n",
      "\n",
      "üìã Scenario 1: Process Optimization\n",
      "   ‚úÖ Prompt rendered successfully (160 chars)\n",
      "   ‚úÖ LLM response generated (457 chars)\n",
      "   üìù Preview: To optimize a distillate column's efficiency, you should focus on several key factors:\n",
      "\n",
      "1. Column de...\n",
      "\n",
      "üìã Scenario 2: Safety Analysis\n",
      "   ‚úÖ Prompt rendered successfully (176 chars)\n",
      "   ‚úÖ LLM response generated (521 chars)\n",
      "   üìù Preview: 1. Proper Ventilation: All chemicals, gases and vapors should be ventilated to ensure that the conce...\n",
      "\n",
      "üìã Scenario 3: Economic Assessment\n",
      "   ‚úÖ Prompt rendered successfully (164 chars)\n",
      "   ‚úÖ LLM response generated (535 chars)\n",
      "   üìù Preview: Modular plant designs offer several significant economic advantages over traditional, site-specific ...\n",
      "\n",
      "‚úÖ Prompt engineering and testing complete!\n"
     ]
    }
   ],
   "source": [
    "# SECTION 4.2: Advanced Prompt Engineering and Testing\n",
    "# ====================================================\n",
    "\n",
    "print(\"üéØ Advanced Prompt Engineering and Testing...\")\n",
    "\n",
    "try:\n",
    "    # Test different prompt scenarios\n",
    "    test_scenarios = [\n",
    "        {\n",
    "            \"name\": \"Process Optimization\",\n",
    "            \"query\": \"How can we optimize the distillation column efficiency?\",\n",
    "            \"system\": \"You are a process optimization expert specializing in distillation systems.\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Safety Analysis\", \n",
    "            \"query\": \"What safety considerations are important for modular chemical plants?\",\n",
    "            \"system\": \"You are a chemical safety engineer with expertise in process hazard analysis.\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Economic Assessment\",\n",
    "            \"query\": \"Analyze the economic benefits of modular plant design.\",\n",
    "            \"system\": \"You are a chemical engineering economist specializing in plant design economics.\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(f\"üß™ Testing {len(test_scenarios)} prompt scenarios...\")\n",
    "    \n",
    "    for i, scenario in enumerate(test_scenarios):\n",
    "        print(f\"\\nüìã Scenario {i+1}: {scenario['name']}\")\n",
    "        \n",
    "        try:\n",
    "            # Render prompt\n",
    "            prompt = llm_query_manager._create_general_query_prompt(\n",
    "                question=scenario['query'],\n",
    "                context=scenario['system']\n",
    "            )\n",
    "            \n",
    "            print(f\"   ‚úÖ Prompt rendered successfully ({len(prompt)} chars)\")\n",
    "            \n",
    "            # Quick test with LLM (generate a short response) - FIXED: use generate_response\n",
    "            response_result = llm_runner.generate_response(\n",
    "                prompt=scenario['query'],\n",
    "                max_length=100,\n",
    "                temperature=0.7,\n",
    "                do_sample=True\n",
    "            )\n",
    "            \n",
    "            # Extract the actual response text\n",
    "            response_text = response_result.get('response', 'No response generated')\n",
    "            print(f\"   ‚úÖ LLM response generated ({len(response_text)} chars)\")\n",
    "            print(f\"   üìù Preview: {response_text[:100]}...\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Scenario {i+1} failed: {e}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Prompt engineering error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n‚úÖ Prompt engineering and testing complete!\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## **SECTION 5: Performance Analysis & Debug Tools** üîç\n",
    "\n",
    "Advanced performance benchmarking, debugging tools, and system optimization for developers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Performance Analysis and System Benchmarking...\n",
      "üß™ Running Performance Benchmarks...\n",
      "\n",
      "üìä Performance Benchmark Results:\n",
      "------------------------------------------------------------\n",
      "‚úÖ Pipeline Initialization           4.732s  -3282.0MB\n",
      "‚úÖ Configuration Template Creation    0.001s      0.1MB\n",
      "‚úÖ Quick Status Check                0.006s      1.2MB\n",
      "\n",
      "üíª Current System Resources:\n",
      "   ‚Ä¢ CPU Usage: 40.5%\n",
      "   ‚Ä¢ Memory Usage: 84.2%\n",
      "   ‚Ä¢ Available Memory: 2.5 GB\n",
      "\n",
      "‚úÖ Performance analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# SECTION 5.1: Performance Analysis and Benchmarking\n",
    "# ==================================================\n",
    "\n",
    "print(\"üìà Performance Analysis and System Benchmarking...\")\n",
    "\n",
    "import time\n",
    "import psutil\n",
    "import gc\n",
    "\n",
    "def measure_performance(func, name, *args, **kwargs):\n",
    "    \"\"\"Measure function performance\"\"\"\n",
    "    gc.collect()  # Clean memory before measurement\n",
    "    \n",
    "    start_time = time.time()\n",
    "    start_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB\n",
    "    \n",
    "    try:\n",
    "        result = func(*args, **kwargs)\n",
    "        success = True\n",
    "        error = None\n",
    "    except Exception as e:\n",
    "        result = None\n",
    "        success = False\n",
    "        error = str(e)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    end_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB\n",
    "    \n",
    "    return {\n",
    "        'name': name,\n",
    "        'duration': end_time - start_time,\n",
    "        'memory_used': end_memory - start_memory,\n",
    "        'success': success,\n",
    "        'error': error,\n",
    "        'result': result\n",
    "    }\n",
    "\n",
    "# Performance benchmarks\n",
    "benchmarks = []\n",
    "\n",
    "print(\"üß™ Running Performance Benchmarks...\")\n",
    "\n",
    "# Benchmark 1: Pipeline initialization\n",
    "bench1 = measure_performance(\n",
    "    lambda: PipelineUtils(results_dir=\"data/05_output/results\"),\n",
    "    \"Pipeline Initialization\"\n",
    ")\n",
    "benchmarks.append(bench1)\n",
    "\n",
    "# Benchmark 2: Configuration template creation\n",
    "bench2 = measure_performance(\n",
    "    lambda: config_manager.create_template_json(\"perf_test.json\"),\n",
    "    \"Configuration Template Creation\"\n",
    ")\n",
    "benchmarks.append(bench2)\n",
    "\n",
    "# Benchmark 3: Quick status check\n",
    "bench3 = measure_performance(\n",
    "    pipeline.quick_test,\n",
    "    \"Quick Status Check\"\n",
    ")\n",
    "benchmarks.append(bench3)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nüìä Performance Benchmark Results:\")\n",
    "print(\"-\" * 60)\n",
    "for bench in benchmarks:\n",
    "    status = \"‚úÖ\" if bench['success'] else \"‚ùå\"\n",
    "    print(f\"{status} {bench['name']:<30} {bench['duration']:>8.3f}s {bench['memory_used']:>8.1f}MB\")\n",
    "    if not bench['success']:\n",
    "        print(f\"   Error: {bench['error']}\")\n",
    "\n",
    "# System resource usage\n",
    "print(f\"\\nüíª Current System Resources:\")\n",
    "print(f\"   ‚Ä¢ CPU Usage: {psutil.cpu_percent():.1f}%\")\n",
    "print(f\"   ‚Ä¢ Memory Usage: {psutil.virtual_memory().percent:.1f}%\")\n",
    "print(f\"   ‚Ä¢ Available Memory: {psutil.virtual_memory().available / 1024 / 1024 / 1024:.1f} GB\")\n",
    "\n",
    "print(\"\\n‚úÖ Performance analysis complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Debug Tools and System Maintenance...\n",
      "üóëÔ∏è Running System Cleanup...\n",
      "   ‚Ä¢ Cleaned 0 temporary files\n",
      "\n",
      "üìã Checking Log Files...\n",
      "   ‚Ä¢ Found 1 log files:\n",
      "     - pynucleus_20250618_231539.log (2029 bytes, 0.2h old)\n",
      "\n",
      "üíæ Memory Cleanup...\n",
      "   ‚Ä¢ Garbage collection completed\n",
      "\n",
      "üìä Development Session Summary:\n",
      "   ‚Ä¢ Session Duration: 118.5 seconds\n",
      "   ‚Ä¢ Benchmarks Run: 3\n",
      "   ‚Ä¢ Components Tested: ‚úÖ\n",
      "\n",
      "‚úÖ Debug tools and cleanup complete!\n"
     ]
    }
   ],
   "source": [
    "# SECTION 5.2: Debug Tools and System Cleanup\n",
    "# ============================================\n",
    "\n",
    "print(\"üîß Debug Tools and System Maintenance...\")\n",
    "\n",
    "# System cleanup functions\n",
    "def cleanup_temp_files():\n",
    "    \"\"\"Remove temporary files\"\"\"\n",
    "    temp_patterns = [\"perf_test.json\", \"dev_simulation_config.*\"]\n",
    "    cleaned = 0\n",
    "    \n",
    "    for pattern in temp_patterns:\n",
    "        if \"*\" in pattern:\n",
    "            import glob\n",
    "            files = glob.glob(pattern)\n",
    "            for file in files:\n",
    "                try:\n",
    "                    Path(file).unlink()\n",
    "                    cleaned += 1\n",
    "                except:\n",
    "                    pass\n",
    "        else:\n",
    "            try:\n",
    "                if Path(pattern).exists():\n",
    "                    Path(pattern).unlink()\n",
    "                    cleaned += 1\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "def check_log_files():\n",
    "    \"\"\"Check system log files\"\"\"\n",
    "    log_dirs = [\"logs\", \"data/05_output/logs\"]\n",
    "    log_files = []\n",
    "    \n",
    "    for log_dir in log_dirs:\n",
    "        if Path(log_dir).exists():\n",
    "            for log_file in Path(log_dir).glob(\"*.log\"):\n",
    "                size = log_file.stat().st_size\n",
    "                log_files.append({\n",
    "                    'file': str(log_file),\n",
    "                    'size': size,\n",
    "                    'age': time.time() - log_file.stat().st_mtime\n",
    "                })\n",
    "    \n",
    "    return log_files\n",
    "\n",
    "# Run debug tools\n",
    "print(\"üóëÔ∏è Running System Cleanup...\")\n",
    "cleaned_files = cleanup_temp_files()\n",
    "print(f\"   ‚Ä¢ Cleaned {cleaned_files} temporary files\")\n",
    "\n",
    "print(\"\\nüìã Checking Log Files...\")\n",
    "log_files = check_log_files()\n",
    "if log_files:\n",
    "    print(f\"   ‚Ä¢ Found {len(log_files)} log files:\")\n",
    "    for log in log_files[-5:]:  # Show last 5\n",
    "        age_hours = log['age'] / 3600\n",
    "        print(f\"     - {Path(log['file']).name} ({log['size']} bytes, {age_hours:.1f}h old)\")\n",
    "else:\n",
    "    print(\"   ‚Ä¢ No log files found\")\n",
    "\n",
    "# Memory cleanup\n",
    "print(\"\\nüíæ Memory Cleanup...\")\n",
    "gc.collect()\n",
    "print(\"   ‚Ä¢ Garbage collection completed\")\n",
    "\n",
    "# Final status\n",
    "print(f\"\\nüìä Development Session Summary:\")\n",
    "if 'start_time' in locals():\n",
    "    print(f\"   ‚Ä¢ Session Duration: {(datetime.now() - start_time).total_seconds():.1f} seconds\")\n",
    "print(f\"   ‚Ä¢ Benchmarks Run: {len(benchmarks)}\")\n",
    "print(f\"   ‚Ä¢ Components Tested: {'‚úÖ' if all(b['success'] for b in benchmarks) else '‚ö†Ô∏è'}\")\n",
    "\n",
    "print(\"\\n‚úÖ Debug tools and cleanup complete!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## **üéØ Developer Notebook Summary**\n",
    "\n",
    "### **Enhanced Features Available:**\n",
    "\n",
    "üîß **System Diagnostics**\n",
    "- Advanced health checks with fallback options\n",
    "- Comprehensive directory and file validation\n",
    "- Real-time system resource monitoring\n",
    "\n",
    "üìä **Enhanced Pipeline Integration**\n",
    "- Aligned with Capstone Project patterns\n",
    "- Advanced integration workflows\n",
    "- Performance metrics and validation\n",
    "\n",
    "ü§ñ **LLM & DSPy Development**\n",
    "- Model testing and initialization\n",
    "- DSPy workflow integration (when available)\n",
    "- Advanced prompt engineering tools\n",
    "\n",
    "üî¨ **Advanced Analytics**\n",
    "- DWSIM-RAG integration\n",
    "- Financial analysis and reporting\n",
    "- Comprehensive result validation\n",
    "\n",
    "‚ö° **Performance Tools**\n",
    "- Benchmarking and optimization\n",
    "- Memory management and cleanup\n",
    "- Debug tools and troubleshooting\n",
    "\n",
    "### **Development Workflow:**\n",
    "\n",
    "1. **Initialize** ‚Üí Run Cells 1-3 for system setup and diagnostics\n",
    "2. **Configure** ‚Üí Use Cells 4-6 for advanced pipeline configuration\n",
    "3. **Analyze** ‚Üí Execute Cells 7-9 for integration and analytics\n",
    "4. **Develop** ‚Üí Leverage Cells 10-12 for LLM and DSPy development\n",
    "5. **Optimize** ‚Üí Use Cells 13-15 for performance analysis and debugging\n",
    "\n",
    "### **Next Steps for Developers:**\n",
    "\n",
    "- **Extend DSPy Integration**: Develop custom DSPy programs for domain-specific tasks\n",
    "- **Performance Optimization**: Use benchmark results to optimize pipeline performance\n",
    "- **Custom Analytics**: Build on the integration framework for specialized analysis\n",
    "- **Advanced Configurations**: Create domain-specific configuration templates\n",
    "\n",
    "---\n",
    "\n",
    "**üí° For production deployment**, ensure all diagnostic checks pass and review performance metrics before scaling.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
