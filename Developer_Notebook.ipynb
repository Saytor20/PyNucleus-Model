{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# **PyNucleus Developer Notebook** ğŸ› ï¸\n",
        "\n",
        "## **Advanced Development Environment**\n",
        "\n",
        "This notebook contains advanced features, diagnostics, and development tools for PyNucleus.\n",
        "\n",
        "### **ğŸ”§ Developer Features:**\n",
        "- **System Diagnostics**: Comprehensive health checks and validation\n",
        "- **Enhanced Pipeline**: Advanced configuration and integration\n",
        "- **LLM Development**: Prompt engineering and model testing\n",
        "- **Performance Analysis**: Detailed metrics and benchmarking\n",
        "- **Configuration Management**: Custom templates and settings\n",
        "- **Debug Tools**: Logging, tracing, and error analysis\n",
        "\n",
        "### **ğŸ“‹ Notebook Sections:**\n",
        "1. **System Initialization & Diagnostics** (Cells 1-3)\n",
        "2. **Enhanced Pipeline Configuration** (Cells 4-6)\n",
        "3. **Advanced Analysis & Integration** (Cells 7-9)\n",
        "4. **LLM Development & Testing** (Cells 10-12)\n",
        "5. **Performance & Debugging** (Cells 13-15)\n",
        "6. **Version Control & Maintenance** (Cells 16-18)\n",
        "\n",
        "---\n",
        "**âš ï¸ Warning**: This notebook is intended for developers and advanced users. For basic usage, use `Capstone Project.ipynb`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”§ PyNucleus Developer Environment - Starting Initialization...\n",
            "ğŸ“… Session started: 2025-06-13 18:05:16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: token_utils not available, using fallback\n",
            "âœ… All PyNucleus modules imported successfully\n",
            "ğŸ”§ Setting up RAG imports...\n",
            "Warning: wikipedia package not available. Wikipedia scraping disabled.\n",
            "âœ… RAG imports ready!\n",
            "ğŸ”§ Setting up DWSIM imports...\n",
            "âœ… DWSIM modules imported successfully\n",
            "ğŸ“ Results directory: data/05_output/results\n",
            "ğŸ”§ Pipeline Utils initialized with results dir: data/05_output/results\n",
            "ğŸ”— DWSIM-RAG integration enabled\n",
            "âœ… Core components initialized\n",
            "ğŸ¯ Ready for development and testing!\n"
          ]
        }
      ],
      "source": [
        "# SECTION 1: System Initialization & Diagnostics\n",
        "# ===============================================\n",
        "\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import importlib\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"ğŸ”§ PyNucleus Developer Environment - Starting Initialization...\")\n",
        "print(f\"ğŸ“… Session started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "# Add src to Python path\n",
        "src_path = str(Path().resolve() / \"src\")\n",
        "if src_path not in sys.path:\n",
        "    sys.path.insert(0, src_path)\n",
        "\n",
        "# Import all PyNucleus components\n",
        "try:\n",
        "    from pynucleus.pipeline import RAGPipeline, DWSIMPipeline, ResultsExporter, PipelineUtils\n",
        "    from pynucleus.integration.config_manager import ConfigManager\n",
        "    from pynucleus.integration.dwsim_rag_integrator import DWSIMRAGIntegrator\n",
        "    from pynucleus.integration.llm_output_generator import LLMOutputGenerator\n",
        "    from pynucleus.llm import LLMRunner\n",
        "    from pynucleus.llm.query_llm import LLMQueryManager, quick_ask_llm\n",
        "    \n",
        "    print(\"âœ… All PyNucleus modules imported successfully\")\n",
        "    \n",
        "    # Initialize components\n",
        "    pipeline = PipelineUtils(results_dir=\"data/05_output/results\")\n",
        "    config_manager = ConfigManager(config_dir=\"configs\")\n",
        "    dwsim_rag_integrator = DWSIMRAGIntegrator(\n",
        "        rag_pipeline=None,  # Will be set after pipeline initialization\n",
        "        results_dir=\"data/05_output/results\"\n",
        "    )\n",
        "    llm_generator = LLMOutputGenerator(results_dir=\"data/05_output/llm_reports\")\n",
        "    \n",
        "    print(\"âœ… Core components initialized\")\n",
        "    print(\"ğŸ¯ Ready for development and testing!\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Initialization error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ” Running Comprehensive System Diagnostic...\n",
            "âœ… System diagnostic completed successfully\n",
            "   ğŸŸ¢ SYSTEM HEALTH: 100.0% - EXCELLENT\n",
            "\n",
            "ğŸ” Manual System Checks:\n",
            "   âœ… data/01_raw\n",
            "   âœ… data/02_processed\n",
            "   âœ… data/03_intermediate\n",
            "   âœ… data/04_models\n",
            "   âœ… data/05_output\n",
            "   âœ… src/pynucleus/pipeline\n",
            "   âœ… src/pynucleus/rag\n",
            "   âœ… src/pynucleus/integration\n",
            "   âœ… src/pynucleus/llm\n",
            "\n",
            "ğŸ¯ System diagnostic complete!\n"
          ]
        }
      ],
      "source": [
        "# SECTION 1.2: Comprehensive System Diagnostic\n",
        "# ============================================\n",
        "\n",
        "print(\"ğŸ” Running Comprehensive System Diagnostic...\")\n",
        "\n",
        "try:\n",
        "    # Run system diagnostic\n",
        "    import subprocess\n",
        "    result = subprocess.run([\n",
        "        sys.executable, \"scripts/comprehensive_system_diagnostic.py\", \"--quiet\"\n",
        "    ], capture_output=True, text=True, cwd=\".\")\n",
        "    \n",
        "    if result.returncode == 0:\n",
        "        print(\"âœ… System diagnostic completed successfully\")\n",
        "        # Extract key metrics from output\n",
        "        lines = result.stdout.strip().split('\\n')\n",
        "        for line in lines[-10:]:  # Show last 10 lines for summary\n",
        "            if any(keyword in line for keyword in ['Health:', 'Status:', 'EXCELLENT', 'GOOD', 'passed']):\n",
        "                print(f\"   {line}\")\n",
        "    else:\n",
        "        print(\"âš ï¸ System diagnostic issues detected:\")\n",
        "        print(result.stderr)\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Could not run system diagnostic: {e}\")\n",
        "    print(\"ğŸ’¡ Continuing with manual checks...\")\n",
        "\n",
        "# Manual system checks\n",
        "print(\"\\nğŸ” Manual System Checks:\")\n",
        "\n",
        "# Check data directories\n",
        "data_dirs = ['data/01_raw', 'data/02_processed', 'data/03_intermediate', 'data/04_models', 'data/05_output']\n",
        "for dir_path in data_dirs:\n",
        "    exists = Path(dir_path).exists()\n",
        "    print(f\"   {'âœ…' if exists else 'âŒ'} {dir_path}\")\n",
        "\n",
        "# Check src structure\n",
        "src_dirs = ['src/pynucleus/pipeline', 'src/pynucleus/rag', 'src/pynucleus/integration', 'src/pynucleus/llm']\n",
        "for dir_path in src_dirs:\n",
        "    exists = Path(dir_path).exists()\n",
        "    print(f\"   {'âœ…' if exists else 'âŒ'} {dir_path}\")\n",
        "\n",
        "print(\"\\nğŸ¯ System diagnostic complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Š Detailed Pipeline Status Check...\n",
            "\n",
            "ğŸ”§ PyNucleus Pipeline Status\n",
            "============================================================\n",
            "âš™ï¸ Configuration:\n",
            "   Results Directory: data/05_output/results\n",
            "   LLM Output Directory: data/05_output/llm_reports\n",
            "   DWSIM Integration: âœ… Enabled\n",
            "\n",
            "ğŸ“¦ Components:\n",
            "   RAG Pipeline: âœ… Ready\n",
            "   DWSIM Pipeline: âœ… Ready\n",
            "   Results Exporter: âœ… Ready\n",
            "\n",
            "ğŸ“Š RAG Pipeline Status:\n",
            "==================================================\n",
            "âŒ Error: Statistics file not found\n",
            "\n",
            "ğŸ”— Integration Capabilities:\n",
            "   ğŸ“„ Document Processing: âœ… Available\n",
            "   ğŸ”¬ Simulation Integration: âœ… Available\n",
            "   ğŸ¤– LLM Querying: âœ… Enhanced (docs + sims)\n",
            "============================================================\n",
            "\n",
            "==================================================\n",
            "ğŸ§ª Quick Pipeline Test\n",
            "------------------------------\n",
            "ğŸ“š RAG: 0 chunks available\n",
            "ğŸ”— Integration: âšª Documents only\n",
            "ğŸ”¬ DWSIM: 0 simulations\n",
            "ğŸ“ Output: 0 CSV files\n",
            "âŒ Status check error: 'results_dir'\n",
            "\n",
            "âœ… Status check complete!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/var/folders/9z/fhqbcx0d6sqc_273srv0dv300000gn/T/ipykernel_45112/506855941.py\", line 14, in <module>\n",
            "    print(f\"ğŸ“ Results Directory: {test_results['results_dir']}\")\n",
            "                                   ~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
            "KeyError: 'results_dir'\n"
          ]
        }
      ],
      "source": [
        "# SECTION 1.3: Pipeline Status and Health Check\n",
        "# =============================================\n",
        "\n",
        "print(\"ğŸ“Š Detailed Pipeline Status Check...\")\n",
        "\n",
        "try:\n",
        "    # Pipeline component status\n",
        "    pipeline.print_pipeline_status()\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    \n",
        "    # Quick test\n",
        "    test_results = pipeline.quick_test()\n",
        "    print(f\"ğŸ“ Results Directory: {test_results['results_dir']}\")\n",
        "    print(f\"ğŸ“„ CSV Files: {test_results['csv_files_count']}\")\n",
        "    \n",
        "    if test_results['csv_files_count'] > 0:\n",
        "        print(\"\\nğŸ“‹ Existing Files:\")\n",
        "        for file_info in test_results['csv_files']:\n",
        "            print(f\"   â€¢ {file_info['name']} ({file_info['size']} bytes)\")\n",
        "    \n",
        "    # Component health\n",
        "    print(f\"\\nğŸ”§ Component Health:\")\n",
        "    print(f\"   â€¢ Pipeline Utils: {'âœ…' if hasattr(pipeline, 'rag_pipeline') else 'âš ï¸'}\")\n",
        "    print(f\"   â€¢ Config Manager: {'âœ…' if config_manager else 'âŒ'}\")\n",
        "    print(f\"   â€¢ DWSIM-RAG Integrator: {'âœ…' if dwsim_rag_integrator else 'âŒ'}\")\n",
        "    print(f\"   â€¢ LLM Generator: {'âœ…' if llm_generator else 'âŒ'}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Status check error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"\\nâœ… Status check complete!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "\n",
        "## **SECTION 2: Enhanced Pipeline Configuration** ğŸ”§\n",
        "\n",
        "Advanced configuration management and template generation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”§ Advanced Configuration Management...\n",
            "âœ… Pydantic template created: configs/dev_simulation_config.json\n",
            "âŒ Configuration error: dict contains fields not in fieldnames: 'catalyst_loading'\n",
            "\n",
            "âœ… Configuration management ready!\n"
          ]
        }
      ],
      "source": [
        "# SECTION 2.1: Configuration Templates and Management\n",
        "# ===================================================\n",
        "\n",
        "print(\"ğŸ”§ Advanced Configuration Management...\")\n",
        "\n",
        "# Create configuration templates\n",
        "try:\n",
        "    # Generate JSON and CSV templates\n",
        "    json_template = config_manager.create_template_json(\"dev_simulation_config.json\", verbose=True)\n",
        "    csv_template = config_manager.create_template_csv(\"dev_simulation_config.csv\", verbose=True)\n",
        "    \n",
        "    print(f\"âœ… Configuration templates created:\")\n",
        "    print(f\"   â€¢ JSON: {json_template}\")\n",
        "    print(f\"   â€¢ CSV: {csv_template}\")\n",
        "    \n",
        "    # Show template contents (first few lines)\n",
        "    if Path(json_template).exists():\n",
        "        with open(json_template, 'r') as f:\n",
        "            content = f.read()[:300]\n",
        "            print(f\"\\nğŸ“‹ JSON Template Preview:\")\n",
        "            print(content + \"...\" if len(content) >= 300 else content)\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Configuration error: {e}\")\n",
        "\n",
        "print(\"\\nâœ… Configuration management ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pynucleus.integration.dwsim_data_integrator:DWSIMDataIntegrator initialized with output: data/05_output\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ Running Enhanced Pipeline for Development Testing...\n",
            "ğŸš€ Running complete PyNucleus pipeline...\n",
            "ğŸ—‘ï¸ RAG results cleared.\n",
            "ğŸ—‘ï¸ DWSIM results cleared.\n",
            "ğŸ”¬ Step 1: Running DWSIM simulations...\n",
            "ğŸ”¬ Starting DWSIM Simulations...\n",
            "ğŸ“‹ Running 5 simulation cases...\n",
            "\n",
            "ğŸ§ª Case 1/5: distillation_ethanol_water\n",
            "   âœ… Success - Duration: 0.00s\n",
            "\n",
            "ğŸ§ª Case 2/5: reactor_methane_combustion\n",
            "   âœ… Success - Duration: 0.00s\n",
            "\n",
            "ğŸ§ª Case 3/5: heat_exchanger_steam\n",
            "   âœ… Success - Duration: 0.00s\n",
            "\n",
            "ğŸ§ª Case 4/5: absorber_co2_capture\n",
            "   âœ… Success - Duration: 0.00s\n",
            "\n",
            "ğŸ§ª Case 5/5: crystallizer_salt\n",
            "   âœ… Success - Duration: 0.00s\n",
            "\n",
            "ğŸ“Š Simulation Summary:\n",
            "   â€¢ Successful simulations: 5/5\n",
            "   â€¢ Failed simulations: 0/5\n",
            "ğŸ“Š DWSIM Statistics:\n",
            "   â€¢ Total Simulations: 5\n",
            "   â€¢ Success Rate: 100.0%\n",
            "   â€¢ Average Duration: 0.00s\n",
            "\n",
            "ğŸ“š Step 2: Running RAG pipeline with DWSIM integration...\n",
            "ğŸ“š Starting RAG Pipeline...\n",
            "Step 1: Processing source documents...\n",
            "â„¹ The 'data/01_raw/source_docs' directory is empty. Nothing to process.\n",
            "\n",
            "Step 2: Scraping Wikipedia articles...\n",
            "ğŸ” Starting Wikipedia article search for 5 keywords...\n",
            "â–¶ï¸  Searching for: modular design\n",
            "âŒ  Error processing modular design: name 'quote' is not defined\n",
            "â–¶ï¸  Searching for: software architecture\n",
            "âŒ  Error processing software architecture: name 'quote' is not defined\n",
            "â–¶ï¸  Searching for: system design\n",
            "âŒ  Error processing system design: name 'quote' is not defined\n",
            "â–¶ï¸  Searching for: industrial design\n",
            "âŒ  Error processing industrial design: name 'quote' is not defined\n",
            "â–¶ï¸  Searching for: supply chain\n",
            "âŒ  Error processing supply chain: name 'quote' is not defined\n",
            "\n",
            "âœ¨ Article scraping complete!\n",
            "\n",
            "Step 3: Processing and chunking documents...\n",
            "ğŸ“° Found 0 Wikipedia articles\n",
            "ğŸ“„ Found 0 converted documents\n",
            "âš ï¸ No documents found to process\n",
            "âš ï¸ No chunks to save\n",
            "\n",
            "Step 4: Integrating DWSIM simulation data...\n",
            "   âš ï¸ No DWSIM simulation results found - skipping integration\n",
            "\n",
            "Step 5: Building FAISS vector store...\n",
            "=== FAISS VectorDB Analysis ===\n",
            "Started: 2025-06-13 18:05:23\n",
            "âŒ Pipeline error: name 'HuggingFaceEmbeddings' is not defined\n",
            "âŒ Pipeline execution failed\n",
            "\n",
            "âœ… Enhanced pipeline testing complete!\n"
          ]
        }
      ],
      "source": [
        "# SECTION 2.2: Run Enhanced Pipeline with Full Analysis\n",
        "# =====================================================\n",
        "\n",
        "print(\"ğŸš€ Running Enhanced Pipeline for Development Testing...\")\n",
        "\n",
        "# Run complete pipeline with detailed logging\n",
        "try:\n",
        "    start_time = datetime.now()\n",
        "    \n",
        "    # Execute pipeline\n",
        "    results = pipeline.run_complete_pipeline()\n",
        "    \n",
        "    if results:\n",
        "        duration = (datetime.now() - start_time).total_seconds()\n",
        "        print(f\"\\nğŸ‰ Pipeline completed in {duration:.1f} seconds!\")\n",
        "        \n",
        "        # Detailed results analysis\n",
        "        print(f\"\\nğŸ“Š Detailed Results:\")\n",
        "        print(f\"   â€¢ RAG Queries: {len(results.get('rag_data', []))}\")\n",
        "        print(f\"   â€¢ DWSIM Simulations: {len(results.get('dwsim_data', []))}\")\n",
        "        print(f\"   â€¢ Export Files: {len(results.get('exported_files', []))}\")\n",
        "        \n",
        "        # Set up integrator with pipeline data\n",
        "        if hasattr(pipeline, 'rag_pipeline'):\n",
        "            dwsim_rag_integrator.rag_pipeline = pipeline.rag_pipeline\n",
        "        \n",
        "        print(\"âœ… Pipeline data ready for enhanced analysis\")\n",
        "        \n",
        "    else:\n",
        "        print(\"âŒ Pipeline execution failed\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Enhanced pipeline error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"\\nâœ… Enhanced pipeline testing complete!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "\n",
        "## **SECTION 3: Advanced Analysis & Integration** ğŸ”¬\n",
        "\n",
        "DWSIM-RAG integration, financial analysis, and enhanced reporting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”¬ Advanced DWSIM-RAG Integration Analysis...\n",
            "ğŸ“Š Processing 5 DWSIM simulations...\n",
            "âœ… Enhanced 5 simulations with RAG insights\n",
            "âœ… Enhanced integration complete:\n",
            "   â€¢ Integrated simulations: 5\n",
            "   â€¢ Export file: data/05_output/results/integrated_dwsim_rag_results_20250613_180523.json\n",
            "\\nğŸ“‹ Sample Analysis (First Simulation):\n",
            "   â€¢ Case: distillation_ethanol_water\n",
            "   â€¢ Performance: Good\n",
            "   â€¢ Efficiency: High\n",
            "âŒ Integration error: 'recovery_rate'\n",
            "\\nâœ… Advanced integration analysis complete!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/var/folders/9z/fhqbcx0d6sqc_273srv0dv300000gn/T/ipykernel_45112/1448265353.py\", line 32, in <module>\n",
            "    print(f\"   â€¢ Recovery Rate: {sample['performance_metrics']['recovery_rate']:.1f}%\")\n",
            "                                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
            "KeyError: 'recovery_rate'\n"
          ]
        }
      ],
      "source": [
        "# SECTION 3.1: DWSIM-RAG Integration and Enhanced Analysis\n",
        "# ========================================================\n",
        "\n",
        "print(\"ğŸ”¬ Advanced DWSIM-RAG Integration Analysis...\")\n",
        "\n",
        "try:\n",
        "    # Get DWSIM results\n",
        "    dwsim_results = pipeline.dwsim_pipeline.get_results()\n",
        "    \n",
        "    if dwsim_results:\n",
        "        print(f\"ğŸ“Š Processing {len(dwsim_results)} DWSIM simulations...\")\n",
        "        \n",
        "        # Perform enhanced integration\n",
        "        integrated_results = dwsim_rag_integrator.integrate_simulation_results(\n",
        "            dwsim_results, perform_rag_analysis=True\n",
        "        )\n",
        "        \n",
        "        # Export integrated results\n",
        "        integrated_export_file = dwsim_rag_integrator.export_integrated_results()\n",
        "        \n",
        "        print(f\"âœ… Enhanced integration complete:\")\n",
        "        print(f\"   â€¢ Integrated simulations: {len(integrated_results)}\")\n",
        "        print(f\"   â€¢ Export file: {integrated_export_file}\")\n",
        "        \n",
        "        # Show detailed analysis for first simulation\n",
        "        if integrated_results:\n",
        "            sample = integrated_results[0]\n",
        "            print(f\"\\\\nğŸ“‹ Sample Analysis (First Simulation):\")\n",
        "            print(f\"   â€¢ Case: {sample['original_simulation']['case_name']}\")\n",
        "            print(f\"   â€¢ Performance: {sample['performance_metrics']['overall_performance']}\")\n",
        "            print(f\"   â€¢ Efficiency: {sample['performance_metrics']['efficiency_rating']}\")\n",
        "            print(f\"   â€¢ Recovery Rate: {sample['performance_metrics']['recovery_rate']:.1f}%\")\n",
        "            \n",
        "            if 'rag_insights' in sample:\n",
        "                print(f\"   â€¢ RAG Insights: {len(sample['rag_insights'])} knowledge items\")\n",
        "        \n",
        "    else:\n",
        "        print(\"âš ï¸ No DWSIM results available. Run Section 2.2 first.\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Integration error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"\\\\nâœ… Advanced integration analysis complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ’° Advanced Financial Analysis and LLM Report Generation...\n",
            "ğŸ“„ Generating LLM reports for 5 simulations...\n",
            "   âœ… Report 1: distillation_ethanol_water_summary.md\n",
            "   âœ… Report 2: reactor_methane_combustion_summary.md\n",
            "   âœ… Report 3: heat_exchanger_steam_summary.md\n",
            "   âœ… Report 4: absorber_co2_capture_summary.md\n",
            "   âœ… Report 5: crystallizer_salt_summary.md\n",
            "\\nğŸ’° Comprehensive Financial Metrics:\n",
            "   â€¢ Average Recovery Rate: 82.5%\n",
            "   â€¢ Estimated Daily Revenue: $148,500.00\n",
            "   â€¢ Estimated Daily Profit: $58,500.00\n",
            "   â€¢ Return on Investment: 6.5%\n",
            "   â€¢ Financial Analysis File: data/05_output/llm_reports/financial_analysis_20250613_180523.csv\n",
            "\\nğŸ“Š Performance Summary:\n",
            "   â€¢ High Performance Simulations: 5/5\n",
            "   â€¢ High Efficiency Rate: 100.0%\n",
            "\\nğŸ“„ Generated Files:\n",
            "   â€¢ LLM Reports: 5 files\n",
            "   â€¢ Financial Analysis: 1 file\n",
            "\\nâœ… Advanced analysis and reporting complete!\n"
          ]
        }
      ],
      "source": [
        "# SECTION 3.2: LLM Report Generation and Financial Analysis\n",
        "# =========================================================\n",
        "\n",
        "print(\"ğŸ’° Advanced Financial Analysis and LLM Report Generation...\")\n",
        "\n",
        "try:\n",
        "    if 'integrated_results' in locals() and integrated_results:\n",
        "        \n",
        "        # Generate LLM reports for all simulations\n",
        "        print(f\"ğŸ“„ Generating LLM reports for {len(integrated_results)} simulations...\")\n",
        "        \n",
        "        llm_report_files = []\n",
        "        for i, result in enumerate(integrated_results):\n",
        "            try:\n",
        "                report_file = llm_generator.export_llm_ready_text(result)\n",
        "                llm_report_files.append(report_file)\n",
        "                print(f\"   âœ… Report {i+1}: {Path(report_file).name}\")\n",
        "            except Exception as e:\n",
        "                print(f\"   âŒ Report {i+1} failed: {e}\")\n",
        "        \n",
        "        # Generate comprehensive financial analysis\n",
        "        financial_file = llm_generator.export_financial_analysis(integrated_results)\n",
        "        metrics = llm_generator._calculate_key_metrics(integrated_results)\n",
        "        \n",
        "        print(f\"\\\\nğŸ’° Comprehensive Financial Metrics:\")\n",
        "        print(f\"   â€¢ Average Recovery Rate: {metrics['avg_recovery']:.1f}%\")\n",
        "        print(f\"   â€¢ Estimated Daily Revenue: ${metrics['estimated_revenue']:,.2f}\")\n",
        "        print(f\"   â€¢ Estimated Daily Profit: ${metrics['net_profit']:,.2f}\")\n",
        "        print(f\"   â€¢ Return on Investment: {metrics['roi']:.1f}%\")\n",
        "        print(f\"   â€¢ Financial Analysis File: {financial_file}\")\n",
        "        \n",
        "        # Performance summary\n",
        "        print(f\"\\\\nğŸ“Š Performance Summary:\")\n",
        "        good_performance = sum(1 for r in integrated_results \n",
        "                             if r['performance_metrics']['overall_performance'] == 'Good')\n",
        "        print(f\"   â€¢ High Performance Simulations: {good_performance}/{len(integrated_results)}\")\n",
        "        \n",
        "        avg_efficiency = sum(1 for r in integrated_results \n",
        "                           if r['performance_metrics']['efficiency_rating'] == 'High') / len(integrated_results)\n",
        "        print(f\"   â€¢ High Efficiency Rate: {avg_efficiency:.1%}\")\n",
        "        \n",
        "        print(f\"\\\\nğŸ“„ Generated Files:\")\n",
        "        print(f\"   â€¢ LLM Reports: {len(llm_report_files)} files\")\n",
        "        print(f\"   â€¢ Financial Analysis: 1 file\")\n",
        "        \n",
        "    else:\n",
        "        print(\"âš ï¸ No integrated results available. Run Section 3.1 first.\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"âŒ LLM/Financial analysis error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"\\\\nâœ… Advanced analysis and reporting complete!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "\n",
        "## **SECTION 4: LLM Development & Testing** ğŸ¤–\n",
        "\n",
        "LLM model testing, prompt engineering, and query development.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¤– LLM Development Environment Initialization...\n",
            "Loading tokenizer for gpt2...\n",
            "Loading model gpt2 on cpu...\n",
            "Model loaded successfully on cpu\n",
            "Loading tokenizer for gpt2...\n",
            "Loading model gpt2 on cpu...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pynucleus.llm.query_llm:Template environment set up with directory: /Users/mohammadalmusaiteer/PyNucleus-Model/prompts\n",
            "INFO:pynucleus.llm.query_llm:LLMQueryManager initialized with model: gpt2, max_tokens: 2048\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully on cpu\n",
            "âœ… LLM Runner initialized\n",
            "âœ… LLM Query Manager initialized\n",
            "   â€¢ Template directory: /Users/mohammadalmusaiteer/PyNucleus-Model/prompts\n",
            "   â€¢ Template exists: True\n",
            "\\nğŸ”§ Model Information:\n",
            "   â€¢ Model ID: gpt2\n",
            "   â€¢ Vocabulary Size: 50,257\n",
            "   â€¢ Device: cpu\n",
            "\\nğŸ“‹ Prompt System Test:\n",
            "   â€¢ Template rendering: âœ… Success\n",
            "   â€¢ Prompt length: 289 characters\n",
            "\\nâœ… LLM development environment ready!\n"
          ]
        }
      ],
      "source": [
        "# SECTION 4.1: LLM Model Testing and Initialization\n",
        "# =================================================\n",
        "\n",
        "print(\"ğŸ¤– LLM Development Environment Initialization...\")\n",
        "\n",
        "try:\n",
        "    # Initialize LLM components\n",
        "    llm_runner = LLMRunner()\n",
        "    llm_query_manager = LLMQueryManager(max_tokens=2048)\n",
        "    \n",
        "    # Test LLM functionality\n",
        "    print(f\"âœ… LLM Runner initialized\")\n",
        "    print(f\"âœ… LLM Query Manager initialized\")\n",
        "    print(f\"   â€¢ Template directory: {llm_query_manager.template_dir}\")\n",
        "    print(f\"   â€¢ Template exists: {llm_query_manager.template_dir.exists()}\")\n",
        "    \n",
        "    # Get model information\n",
        "    model_info = llm_runner.get_model_info()\n",
        "    print(f\"\\\\nğŸ”§ Model Information:\")\n",
        "    print(f\"   â€¢ Model ID: {model_info['model_id']}\")\n",
        "    print(f\"   â€¢ Vocabulary Size: {model_info['vocab_size']:,}\")\n",
        "    print(f\"   â€¢ Device: {model_info['device']}\")\n",
        "    \n",
        "    # Test basic prompt rendering\n",
        "    test_prompt = llm_query_manager.render_prompt(\n",
        "        user_query=\"Test chemical process optimization query\",\n",
        "        system_message=\"You are a chemical engineering expert.\"\n",
        "    )\n",
        "    \n",
        "    print(f\"\\\\nğŸ“‹ Prompt System Test:\")\n",
        "    print(f\"   â€¢ Template rendering: âœ… Success\")\n",
        "    print(f\"   â€¢ Prompt length: {len(test_prompt)} characters\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ LLM initialization error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"\\\\nâœ… LLM development environment ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¯ Advanced Prompt Engineering and Testing...\n",
            "ğŸ§ª Testing 3 prompt scenarios...\n",
            "\\nğŸ“‹ Scenario 1: Process Optimization\n",
            "   âœ… Prompt rendered successfully (341 chars)\n",
            "   âœ… LLM response generated (180 chars)\n",
            "   ğŸ“ Preview: This is a tough one. The distillation column efficiency is a function of the amount of water vapor t...\n",
            "\\nğŸ“‹ Scenario 2: Safety Analysis\n",
            "   âœ… Prompt rendered successfully (357 chars)\n",
            "   âœ… LLM response generated (201 chars)\n",
            "   ğŸ“ Preview: The safety considerations for modular chemical plants are as follows:\n",
            "\n",
            "-Safety considerations are no...\n",
            "\\nğŸ“‹ Scenario 3: Economic Assessment\n",
            "   âœ… Prompt rendered successfully (345 chars)\n",
            "   âœ… LLM response generated (202 chars)\n",
            "   ğŸ“ Preview: The modular system was developed by a group of researchers at the University of California, Berkeley...\n",
            "\\nğŸ” Running Prompt System Validation...\n",
            "Warning: token_utils not available, using fallback\n",
            "âš ï¸ Prompt system module not available for validation\n",
            "\\nâœ… Prompt engineering and testing complete!\n"
          ]
        }
      ],
      "source": [
        "# SECTION 4.2: Advanced Prompt Engineering and Testing\n",
        "# ====================================================\n",
        "\n",
        "print(\"ğŸ¯ Advanced Prompt Engineering and Testing...\")\n",
        "\n",
        "try:\n",
        "    # Test different prompt scenarios\n",
        "    test_scenarios = [\n",
        "        {\n",
        "            \"name\": \"Process Optimization\",\n",
        "            \"query\": \"How can we optimize the distillation column efficiency?\",\n",
        "            \"system\": \"You are a process optimization expert specializing in distillation systems.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Safety Analysis\", \n",
        "            \"query\": \"What safety considerations are important for modular chemical plants?\",\n",
        "            \"system\": \"You are a chemical safety engineer with expertise in process hazard analysis.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Economic Assessment\",\n",
        "            \"query\": \"Analyze the economic benefits of modular plant design.\",\n",
        "            \"system\": \"You are a chemical engineering economist specializing in plant design economics.\"\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    print(f\"ğŸ§ª Testing {len(test_scenarios)} prompt scenarios...\")\n",
        "    \n",
        "    for i, scenario in enumerate(test_scenarios):\n",
        "        print(f\"\\\\nğŸ“‹ Scenario {i+1}: {scenario['name']}\")\n",
        "        \n",
        "        try:\n",
        "            # Render prompt\n",
        "            prompt = llm_query_manager.render_prompt(\n",
        "                user_query=scenario['query'],\n",
        "                system_message=scenario['system']\n",
        "            )\n",
        "            \n",
        "            print(f\"   âœ… Prompt rendered successfully ({len(prompt)} chars)\")\n",
        "            \n",
        "            # Quick test with LLM (generate a short response)\n",
        "            response = llm_runner.ask(\n",
        "                scenario['query'],\n",
        "                max_length=50,\n",
        "                temperature=0.7,\n",
        "                do_sample=True\n",
        "            )\n",
        "            \n",
        "            print(f\"   âœ… LLM response generated ({len(response)} chars)\")\n",
        "            print(f\"   ğŸ“ Preview: {response[:100]}...\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"   âŒ Scenario {i+1} failed: {e}\")\n",
        "    \n",
        "    # Test prompt system validation\n",
        "    print(f\"\\\\nğŸ” Running Prompt System Validation...\")\n",
        "    try:\n",
        "        # Import prompt system if available\n",
        "        from src.pynucleus.llm.prompt_system import PyNucleusPromptSystem\n",
        "        \n",
        "        prompt_system = PyNucleusPromptSystem(template_dir=\"prompts\")\n",
        "        validation_result = prompt_system.validate_prompts()\n",
        "        \n",
        "        print(\"âœ… Prompt system validation completed\")\n",
        "        \n",
        "    except ImportError:\n",
        "        print(\"âš ï¸ Prompt system module not available for validation\")\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Prompt validation error: {e}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Prompt engineering error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"\\\\nâœ… Prompt engineering and testing complete!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "\n",
        "## **SECTION 5: Performance & Debugging** ğŸ”\n",
        "\n",
        "Performance analysis, debugging tools, and system optimization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“ˆ Performance Analysis and System Benchmarking...\n",
            "ğŸ§ª Running Performance Benchmarks...\n",
            "ğŸ”§ Setting up RAG imports...\n",
            "Warning: wikipedia package not available. Wikipedia scraping disabled.\n",
            "âœ… RAG imports ready!\n",
            "ğŸ”§ Setting up DWSIM imports...\n",
            "âœ… DWSIM modules imported successfully\n",
            "ğŸ“ Results directory: data/05_output/results\n",
            "ğŸ”§ Pipeline Utils initialized with results dir: data/05_output/results\n",
            "ğŸ”— DWSIM-RAG integration enabled\n",
            "ğŸ§ª Quick Pipeline Test\n",
            "------------------------------\n",
            "ğŸ“š RAG: 0 chunks available\n",
            "ğŸ”— Integration: âšª Documents only\n",
            "ğŸ“Š DWSIM Statistics:\n",
            "   â€¢ Total Simulations: 5\n",
            "   â€¢ Success Rate: 100.0%\n",
            "   â€¢ Average Duration: 0.00s\n",
            "ğŸ”¬ DWSIM: 5 simulations\n",
            "ğŸ“ Output: 0 CSV files\n",
            "\n",
            "ğŸ“Š Performance Benchmark Results:\n",
            "------------------------------------------------------------\n",
            "âœ… Pipeline Initialization           0.004s      0.0MB\n",
            "âœ… Configuration Template Creation    0.001s      0.0MB\n",
            "âœ… Quick Status Check                0.001s      0.0MB\n",
            "\n",
            "ğŸ’» Current System Resources:\n",
            "   â€¢ CPU Usage: 34.9%\n",
            "   â€¢ Memory Usage: 83.3%\n",
            "   â€¢ Available Memory: 2.7 GB\n",
            "\n",
            "âœ… Performance analysis complete!\n"
          ]
        }
      ],
      "source": [
        "# SECTION 5.1: Performance Analysis and Benchmarking\n",
        "# ==================================================\n",
        "\n",
        "print(\"ğŸ“ˆ Performance Analysis and System Benchmarking...\")\n",
        "\n",
        "import time\n",
        "import psutil\n",
        "import gc\n",
        "\n",
        "def measure_performance(func, name, *args, **kwargs):\n",
        "    \"\"\"Measure function performance\"\"\"\n",
        "    gc.collect()  # Clean memory before measurement\n",
        "    \n",
        "    start_time = time.time()\n",
        "    start_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB\n",
        "    \n",
        "    try:\n",
        "        result = func(*args, **kwargs)\n",
        "        success = True\n",
        "        error = None\n",
        "    except Exception as e:\n",
        "        result = None\n",
        "        success = False\n",
        "        error = str(e)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    end_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB\n",
        "    \n",
        "    return {\n",
        "        'name': name,\n",
        "        'duration': end_time - start_time,\n",
        "        'memory_used': end_memory - start_memory,\n",
        "        'success': success,\n",
        "        'error': error,\n",
        "        'result': result\n",
        "    }\n",
        "\n",
        "# Performance benchmarks\n",
        "benchmarks = []\n",
        "\n",
        "print(\"ğŸ§ª Running Performance Benchmarks...\")\n",
        "\n",
        "# Benchmark 1: Pipeline initialization\n",
        "bench1 = measure_performance(\n",
        "    lambda: PipelineUtils(results_dir=\"data/05_output/results\"),\n",
        "    \"Pipeline Initialization\"\n",
        ")\n",
        "benchmarks.append(bench1)\n",
        "\n",
        "# Benchmark 2: Configuration template creation\n",
        "bench2 = measure_performance(\n",
        "    lambda: config_manager.create_template_json(\"perf_test.json\"),\n",
        "    \"Configuration Template Creation\"\n",
        ")\n",
        "benchmarks.append(bench2)\n",
        "\n",
        "# Benchmark 3: Quick status check\n",
        "bench3 = measure_performance(\n",
        "    pipeline.quick_test,\n",
        "    \"Quick Status Check\"\n",
        ")\n",
        "benchmarks.append(bench3)\n",
        "\n",
        "# Display results\n",
        "print(f\"\\nğŸ“Š Performance Benchmark Results:\")\n",
        "print(\"-\" * 60)\n",
        "for bench in benchmarks:\n",
        "    status = \"âœ…\" if bench['success'] else \"âŒ\"\n",
        "    print(f\"{status} {bench['name']:<30} {bench['duration']:>8.3f}s {bench['memory_used']:>8.1f}MB\")\n",
        "    if not bench['success']:\n",
        "        print(f\"   Error: {bench['error']}\")\n",
        "\n",
        "# System resource usage\n",
        "print(f\"\\nğŸ’» Current System Resources:\")\n",
        "print(f\"   â€¢ CPU Usage: {psutil.cpu_percent():.1f}%\")\n",
        "print(f\"   â€¢ Memory Usage: {psutil.virtual_memory().percent:.1f}%\")\n",
        "print(f\"   â€¢ Available Memory: {psutil.virtual_memory().available / 1024 / 1024 / 1024:.1f} GB\")\n",
        "\n",
        "print(\"\\nâœ… Performance analysis complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”§ Debug Tools and System Maintenance...\n",
            "ğŸ—‘ï¸ Running System Cleanup...\n",
            "   â€¢ Cleaned 0 temporary files\n",
            "\n",
            "ğŸ“‹ Checking Log Files...\n",
            "   â€¢ Found 26 log files:\n",
            "     - robust_validation_20250611_213509.log (11059 bytes, 44.5h old)\n",
            "     - system_validation_20250611_215704.log (11803 bytes, 44.1h old)\n",
            "     - system_validation_20250611_220221.log (11166 bytes, 44.0h old)\n",
            "     - system_validation_20250611_215649.log (10672 bytes, 44.1h old)\n",
            "     - system_validation_20250612_163805.log (11866 bytes, 25.5h old)\n",
            "\n",
            "ğŸ’¾ Memory Cleanup...\n",
            "   â€¢ Garbage collection completed\n",
            "\n",
            "ğŸ“Š Development Session Summary:\n",
            "   â€¢ Session Duration: 4.0 seconds\n",
            "   â€¢ Benchmarks Run: 3\n",
            "   â€¢ Components Tested: âœ…\n",
            "\n",
            "âœ… Debug tools and cleanup complete!\n"
          ]
        }
      ],
      "source": [
        "# SECTION 5.2: Debug Tools and System Cleanup\n",
        "# ============================================\n",
        "\n",
        "print(\"ğŸ”§ Debug Tools and System Maintenance...\")\n",
        "\n",
        "# System cleanup functions\n",
        "def cleanup_temp_files():\n",
        "    \"\"\"Remove temporary files\"\"\"\n",
        "    temp_patterns = [\"perf_test.json\", \"dev_simulation_config.*\"]\n",
        "    cleaned = 0\n",
        "    \n",
        "    for pattern in temp_patterns:\n",
        "        if \"*\" in pattern:\n",
        "            import glob\n",
        "            files = glob.glob(pattern)\n",
        "            for file in files:\n",
        "                try:\n",
        "                    Path(file).unlink()\n",
        "                    cleaned += 1\n",
        "                except:\n",
        "                    pass\n",
        "        else:\n",
        "            try:\n",
        "                if Path(pattern).exists():\n",
        "                    Path(pattern).unlink()\n",
        "                    cleaned += 1\n",
        "            except:\n",
        "                pass\n",
        "    \n",
        "    return cleaned\n",
        "\n",
        "def check_log_files():\n",
        "    \"\"\"Check system log files\"\"\"\n",
        "    log_dirs = [\"logs\", \"data/05_output/logs\"]\n",
        "    log_files = []\n",
        "    \n",
        "    for log_dir in log_dirs:\n",
        "        if Path(log_dir).exists():\n",
        "            for log_file in Path(log_dir).glob(\"*.log\"):\n",
        "                size = log_file.stat().st_size\n",
        "                log_files.append({\n",
        "                    'file': str(log_file),\n",
        "                    'size': size,\n",
        "                    'age': time.time() - log_file.stat().st_mtime\n",
        "                })\n",
        "    \n",
        "    return log_files\n",
        "\n",
        "# Run debug tools\n",
        "print(\"ğŸ—‘ï¸ Running System Cleanup...\")\n",
        "cleaned_files = cleanup_temp_files()\n",
        "print(f\"   â€¢ Cleaned {cleaned_files} temporary files\")\n",
        "\n",
        "print(\"\\nğŸ“‹ Checking Log Files...\")\n",
        "log_files = check_log_files()\n",
        "if log_files:\n",
        "    print(f\"   â€¢ Found {len(log_files)} log files:\")\n",
        "    for log in log_files[-5:]:  # Show last 5\n",
        "        age_hours = log['age'] / 3600\n",
        "        print(f\"     - {Path(log['file']).name} ({log['size']} bytes, {age_hours:.1f}h old)\")\n",
        "else:\n",
        "    print(\"   â€¢ No log files found\")\n",
        "\n",
        "# Memory cleanup\n",
        "print(\"\\nğŸ’¾ Memory Cleanup...\")\n",
        "gc.collect()\n",
        "print(\"   â€¢ Garbage collection completed\")\n",
        "\n",
        "# Final status\n",
        "print(f\"\\nğŸ“Š Development Session Summary:\")\n",
        "print(f\"   â€¢ Session Duration: {(datetime.now() - start_time).total_seconds():.1f} seconds\")\n",
        "print(f\"   â€¢ Benchmarks Run: {len(benchmarks)}\")\n",
        "print(f\"   â€¢ Components Tested: {'âœ…' if all(b['success'] for b in benchmarks) else 'âš ï¸'}\")\n",
        "\n",
        "print(\"\\nâœ… Debug tools and cleanup complete!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "\n",
        "## **SECTION 6: Version Control & Maintenance** ğŸ“š\n",
        "\n",
        "Optional version control, documentation updates, and system maintenance tools.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”§ Version control tools ready (uncomment to use)\n",
            "ğŸ’¡ Manual operations available:\n"
          ]
        }
      ],
      "source": [
        "# SECTION 6.1: Version Control and Documentation\n",
        "# ===============================================\n",
        "# Uncomment and run these cells for version control operations\n",
        "\n",
        "# from datetime import datetime\n",
        "# import subprocess\n",
        "\n",
        "# def update_github():\n",
        "#     \"\"\"Update GitHub repository with changes\"\"\"\n",
        "#     print(\"ğŸ“¦ Starting GitHub update...\")\n",
        "#     \n",
        "#     try:\n",
        "#         # Add all changes\n",
        "#         subprocess.run([\"git\", \"add\", \".\"], check=True)\n",
        "#         print(\"   âœ… Files added to staging\")\n",
        "#         \n",
        "#         # Commit with timestamp\n",
        "#         commit_msg = f\"Developer update: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
        "#         subprocess.run([\"git\", \"commit\", \"-m\", commit_msg], check=True)\n",
        "#         print(\"   âœ… Changes committed\")\n",
        "#         \n",
        "#         # Push to origin\n",
        "#         subprocess.run([\"git\", \"push\", \"origin\", \"main\"], check=True)\n",
        "#         print(\"   âœ… Changes pushed to GitHub\")\n",
        "#         \n",
        "#         return True\n",
        "#         \n",
        "#     except subprocess.CalledProcessError as e:\n",
        "#         print(f\"   âŒ Git operation failed: {e}\")\n",
        "#         return False\n",
        "\n",
        "# def log_development_session():\n",
        "#     \"\"\"Log this development session\"\"\"\n",
        "#     log_file = \"update_log.txt\"\n",
        "#     \n",
        "#     with open(log_file, \"a\") as f:\n",
        "#         timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "#         f.write(f\"\\n{timestamp}: Developer session - System testing and validation\\n\")\n",
        "#     \n",
        "#     print(f\"âœ… Development session logged to {log_file}\")\n",
        "\n",
        "# # Uncomment to run version control operations:\n",
        "# # log_development_session()\n",
        "# # update_github()\n",
        "\n",
        "print(\"ğŸ”§ Version control tools ready (uncomment to use)\")\n",
        "print(\"ğŸ’¡ Manual operations available:\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "\n",
        "## **Developer Notebook Complete!** ğŸ‰\n",
        "\n",
        "### **Summary of Available Features:**\n",
        "\n",
        "#### **ğŸ”§ System Development:**\n",
        "- Comprehensive system diagnostics and health checks\n",
        "- Performance benchmarking and resource monitoring\n",
        "- Advanced configuration management\n",
        "- Debug tools and system cleanup\n",
        "\n",
        "#### **ğŸ”¬ Advanced Analysis:**\n",
        "- Enhanced DWSIM-RAG integration\n",
        "- Financial analysis and ROI calculations\n",
        "- LLM report generation with custom templates\n",
        "- Performance metrics and optimization insights\n",
        "\n",
        "#### **ğŸ¤– LLM Development:**\n",
        "- Model testing and initialization\n",
        "- Prompt engineering and validation\n",
        "- Multi-scenario testing\n",
        "- Template system development\n",
        "\n",
        "#### **ğŸ“Š Monitoring & Debugging:**\n",
        "- Real-time performance monitoring\n",
        "- Memory usage analysis\n",
        "- Log file management\n",
        "- System resource tracking\n",
        "\n",
        "#### **ğŸ“š Maintenance Tools:**\n",
        "- Version control integration\n",
        "- Development session logging\n",
        "- Temporary file cleanup\n",
        "- Documentation updates\n",
        "\n",
        "---\n",
        "\n",
        "### **For Production Use:**\n",
        "- Use `Capstone Project.ipynb` for simple user interface\n",
        "- Run `scripts/comprehensive_system_diagnostic.py` for health checks\n",
        "- Check `docs/` folder for complete documentation\n",
        "\n",
        "### **Next Steps:**\n",
        "1. Run comprehensive system diagnostic\n",
        "2. Test individual components as needed\n",
        "3. Use performance benchmarks for optimization\n",
        "4. Develop custom configurations for specific use cases\n",
        "\n",
        "**ğŸ¯ PyNucleus Developer Environment Ready!**\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
