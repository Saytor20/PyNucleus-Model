{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":15,"metadata":{"id":"pxJK6GpyVui7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5226a217-cf79-4a78-a44b-c52cb3c7471c","executionInfo":{"status":"ok","timestamp":1748912493983,"user_tz":240,"elapsed":1096,"user":{"displayName":"Mohammad A.","userId":"15199683412159334052"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Commented out IPython magic to ensure Python compatibility.\n","from google.colab import drive,userdata\n","import os\n","from datetime import datetime\n","\n","drive.mount('/content/drive')\n","notebook_drive_path = \"/content/drive/MyDrive/PyNucleus Project/Capstone Project.ipynb\"\n","notebook_filename_in_repo = \"Capstone Project.ipynb\"\n","log_filename = \"update_log.txt\"\n","\n","# GitHub details\n","GITHUB_USERNAME = userdata.get('GITHUB_USERNAME')\n","GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n","REPOSITORY_NAME = 'PyNucleus-Model'\n","REPO_PATH = f\"/content/drive/MyDrive/{REPOSITORY_NAME}\"\n"]},{"cell_type":"code","source":["# --- CLONE REPOSITORY OR SYNC IF IT EXISTS ---\n","if not os.path.exists(REPO_PATH):\n","    print(f\"Cloning {REPOSITORY_NAME} repository into your Google Drive...\")\n","    # Clone directly into the full REPO_PATH\n","    !git clone {repository_url} {REPO_PATH}\n","else:\n","    print(\"Repository already exists in Drive. Syncing with GitHub...\")\n","    # If it exists, we don't need to do anything here,\n","    # because the commands after this block will handle it.\n","\n","# --- NAVIGATE INTO REPO, PULL, & CONFIGURE ---\n","# This ensures we are in the right place, regardless of if we just cloned or not.\n","%cd {REPO_PATH}\n","print(\"Pulling latest changes to ensure we are up-to-date...\")\n","!git pull\n","\n","print(\"\\nConfiguring Git user for this session...\")\n","!git config user.name \"{GITHUB_USERNAME}\"\n","!git config user.email \"{GITHUB_USERNAME}@users.noreply.github.com\"\n","\n","print(f\"\\n Setup complete. You are ready to work. Current directory: {os.getcwd()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qqy1ABswnFgQ","executionInfo":{"status":"ok","timestamp":1748912495224,"user_tz":240,"elapsed":1236,"user":{"displayName":"Mohammad A.","userId":"15199683412159334052"}},"outputId":"285ce2b1-d4e5-40c6-db51-958e54efc6bd"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Repository already exists in Drive. Syncing with GitHub...\n","/content/drive/MyDrive/PyNucleus-Model\n","Pulling latest changes to ensure we are up-to-date...\n","Already up to date.\n","\n","Configuring Git user for this session...\n","\n"," Setup complete. You are ready to work. Current directory: /content/drive/MyDrive/PyNucleus-Model\n"]}]},{"cell_type":"code","source":["# --- Installation Cell (Run this ONCE per session) ---\n","print(\"Installing all required packages...\")\n","\n","# Core LangChain and Community Packages\n","!pip install -q langchain langchain-core langchain-community langchain-text-splitters\n","\n","# Document Loading & Processing (Unstructured handles many file types including OCR)\n","!pip install -q \"unstructured[local-inference]\"\n","\n","# LLM & ML Libraries\n","!pip install -q transformers accelerate bitsandbytes torch sentence-transformers\n","\n","# Vector Stores\n","!pip install -q chromadb faiss-cpu # faiss-gpu if you have a Pro Colab with a good GPU\n","\n","# Data Handling & Utilities\n","!pip install -q pandas numpy tqdm PyYAML\n","\n","print(\"All packages installed successfully.\")"],"metadata":{"id":"DfNy6HlnOsXc","colab":{"base_uri":"https://localhost:8080/"},"outputId":"51efdc08-30af-4f82-e974-9d92786b5b93"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Installing all required packages...\n"]}]},{"cell_type":"code","source":["# --- Core Utilities & File Handling ---\n","import getpass\n","import yaml # Make sure PyYAML is installed\n","from pathlib import Path\n","\n","# --- Data Handling & Progress Bars ---\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","\n","# --- Document Loading ---\n","# UnstructuredFileLoader is now in langchain_community\n","from langchain_community.document_loaders import UnstructuredFileLoader\n","# For future testing of more specific loaders:\n","# from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader\n","\n","# --- OCR Libraries ---\n","# No direct imports needed here if using UnstructuredFileLoader with local-inference,\n","# as it handles OCR internally.\n","# You would only import these for a manual OCR process:\n","# import pytesseract\n","# from pdf2image import convert_from_path\n","# from PIL import Image\n","\n","# --- Core ML & LLM Libraries ---\n","import torch\n","import transformers\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","import bitsandbytes\n","import accelerate # Often used with transformers\n","\n","# --- Vector Stores & Embeddings ---\n","# Using ChromaDB as the primary vector store.\n","import chromadb\n","from langchain_community.vectorstores import Chroma # Chroma is now in langchain_community\n","from langchain_community.embeddings import HuggingFaceEmbeddings # Embeddings are also in langchain_community\n","# For future testing of a high-performance alternative:\n","# import faiss\n","# from langchain_community.vectorstores import FAISS\n","\n","# --- RAG/Agent Frameworks ---\n","# Core LangChain components\n","import langchain\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.output_parsers import StrOutputParser\n","# For future testing of an alternative RAG-focused toolkit:\n","# from llama_index.core import SimpleDirectoryReader, VectorStoreIndex"],"metadata":{"id":"BPyfUDJoDjgn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Data Ingestion and Preprocessing for RAG**"],"metadata":{"id":"OL-SmhSQQ_21"}},{"cell_type":"code","source":[],"metadata":{"id":"I69992m0RE82"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# This is the last cell of the code"],"metadata":{"id":"hISFF6TUEB_H"}},{"cell_type":"code","source":["\n","# --- CREATE/UPDATE THE LOG FILE ---\n","# This will add a new line to your log file with the current date and time.\n","log_message = f\"Notebook saved on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n","with open(log_filename, \"a\") as f:\n","    f.write(log_message + \"\\n\")\n","print(f\"Updated '{log_filename}'\")\n","\n","# --- COPY YOUR NOTEBOOK FROM DRIVE INTO THE REPO ---\n","print(f\"Copying '{notebook_filename_in_repo}' from Google Drive...\")\n","!cp \"{notebook_drive_path}\" \"{notebook_filename_in_repo}\"\n","\n","# --- ADD, COMMIT, AND PUSH BOTH FILES ---\n","print(\"Staging files for commit...\")\n","# Add BOTH the notebook and the log file to Git\n","!git add \"{notebook_filename_in_repo}\"\n","!git add \"{log_filename}\"\n","\n","# Create a commit message\n","commit_message = f\"Update project notebook and log file - {datetime.now().strftime('%Y-%m-%d')}\"\n","print(f\"Committing with message: '{commit_message}'\")\n","!git commit -m \"{commit_message}\"\n","\n","print(\"\\nPushing changes to GitHub...\")\n","!git push origin main\n","\n","print(\"\\n SUCCESS! Your notebook and log file have been updated on GitHub.\")"],"metadata":{"id":"tjThfmG7EDzG"},"execution_count":null,"outputs":[]}]}