{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21621,
     "status": "ok",
     "timestamp": 1748965189264,
     "user": {
      "displayName": "Mohammad A.",
      "userId": "15199683412159334052"
     },
     "user_tz": 240
    },
    "id": "pxJK6GpyVui7",
    "outputId": "5fcaf74f-4292-4847-fb37-57d1c0d9a971"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# from datetime import datetime\n",
    "# from dotenv import load_dotenv\n",
    "# #\n",
    "# # #--------Google Drive Integration--------#\n",
    "# # # from google.colab import drive, userdata\n",
    "# # # This gives Colab access to your files in Google Drive.\n",
    "# # # drive.mount('/content/drive')\n",
    "# # # 'GITHUB_USERNAME' and 'GITHUB_TOKEN' saved as secrets in Colab.\n",
    "# # GITHUB_USERNAME = userdata.get('GITHUB_USERNAME')\n",
    "# # GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n",
    "# # REPOSITORY_NAME = 'PyNucleus-Model' # Your repository name\n",
    "# # NOTEBOOK_DRIVE_PATH = \"/content/drive/MyDrive/PyNucleus Project/Capstone Project.ipynb\"\n",
    "# #\n",
    "# #\n",
    "# # #--------Cursor Integration--------#\n",
    "# # # Load environment variables from .env file\n",
    "# load_dotenv()\n",
    "# #\n",
    "# # # Get GitHub credentials from environment variables\n",
    "# GITHUB_USERNAME = os.getenv('GITHUB_USERNAME')\n",
    "# GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')\n",
    "# #\n",
    "# # # Print to verify the variables are loaded (remove this in production)\n",
    "# print(f\"Username: {GITHUB_USERNAME}\")\n",
    "# print(f\"Token: {GITHUB_TOKEN[:4]}...\") # Only print first 4 chars of token for security\n",
    "# #\n",
    "# # Repository information\n",
    "# REPOSITORY_NAME = 'PyNucleus-Model'\n",
    "# NOTEBOOK_REPO_FILENAME = \"Capstone Project.ipynb\"\n",
    "# LOG_FILENAME = \"update_log.txt\"\n",
    "\n",
    "# # Pull latest changes from GitHub\n",
    "# print(\"Pulling latest changes from GitHub...\")\n",
    "# !git pull https://{GITHUB_TOKEN}@github.com/{GITHUB_USERNAME}/{REPOSITORY_NAME}.git main\n",
    "\n",
    "# print(\"Repository is up to date!\")\n",
    "\n",
    "# # Log start time\n",
    "# with open(\"update_log.txt\", \"a\") as f:\n",
    "#     f.write(f\" {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}: Log Update\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84DXL9QuH0Tx"
   },
   "source": [
    "# **Data Ingestion and Preprocessing for RAG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Testing imports...\n",
      "✅ scrape_wikipedia_article imported successfully\n",
      "🚀 All imports ready!\n",
      "\n",
      "Step 1: Processing source documents...\n",
      "--- 📄 Starting processing for 5 file(s) in '/Users/mohammadalmusaiteer/PyNucleus-Model/source_documents' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   0%|          | 0/5 [00:00<?, ?it/s]WARNING: libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "WARNING: libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ▶ Processing: Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.docx\n",
      "   • Success! Saved to: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      " ▶ Processing: mcp_basics.txt\n",
      "   • Success! Saved to: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/mcp_basics.txt\n",
      " ▶ Processing: feasibility_factors.txt\n",
      "   • Success! Saved to: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/feasibility_factors.txt\n",
      " ▶ Processing: Bist_Madan.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  80%|████████  | 4/5 [00:00<00:00,  9.12it/s]WARNING: libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "Processing files: 100%|██████████| 5/5 [00:00<00:00, 11.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   • Success! Saved to: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/Bist_Madan.txt\n",
      " ▶ Processing: sample_document.txt\n",
      "   • Success! Saved to: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/sample_document.txt\n",
      "\n",
      " All files processed.\n",
      "\n",
      "Step 2: Scraping Wikipedia articles...\n",
      "🔍 Starting Wikipedia article search for 5 keywords...\n",
      "▶️  Searching for: modular design\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_modular_design.txt\n",
      "▶️  Searching for: software architecture\n",
      "✅  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_software_architecture.txt\n",
      "▶️  Searching for: system design\n",
      "✅  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_system_design.txt\n",
      "▶️  Searching for: industrial design\n",
      "✅  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_industrial_design.txt\n",
      "▶️  Searching for: supply chain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_supply_chain.txt\n",
      "\n",
      "✨ Article scraping complete!\n",
      "\n",
      "Step 3: Processing and chunking documents...\n",
      "📰 Found 5 Wikipedia articles\n",
      "📄 Found 5 converted documents\n",
      "📋 Total documents loaded: 10\n",
      "✂️ Split into 846 chunks\n",
      "\n",
      "✅ Successfully saved chunked data to /Users/mohammadalmusaiteer/PyNucleus-Model/converted_chunked_data/:\n",
      "  • chunked_data_full.json - Complete data with metadata\n",
      "  • chunked_data_stats.json - Statistical analysis\n",
      "  • chunked_data_content.txt - Human-readable content\n",
      "\n",
      "\n",
      "Step 4: Building and evaluating FAISS vector store...\n",
      "=== FAISS VectorDB Analysis ===\n",
      "Started: 2025-06-10 12:53:39\n",
      "Loaded 846 documents from /Users/mohammadalmusaiteer/PyNucleus-Model/converted_chunked_data/chunked_data_full.json\n",
      "Embedding device → cpu   | dim=384\n",
      "Docs indexed : 846\n",
      "Index file   : /Users/mohammadalmusaiteer/PyNucleus-Model/chunk_reports/pynucleus_mcp.faiss\n",
      "Embeds .pkl  : /Users/mohammadalmusaiteer/PyNucleus-Model/chunk_reports/embeddings.pkl\n",
      "\n",
      "-- Files in chunk_reports/ --\n",
      "  · faiss_analysis_20250610_011713.txt\n",
      "  · faiss_analysis_20250610_125339.txt\n",
      "  · embeddings.pkl\n",
      "  · faiss_analysis_20250610_012518.txt\n",
      "  · faiss_analysis_20250610_011345.txt\n",
      "  · faiss_analysis_20250610_125131.txt\n",
      "  · pynucleus_mcp.faiss\n",
      "  · faiss_analysis_20250610_011731.txt\n",
      "  · faiss_analysis_20250610_124413.txt\n",
      "\n",
      "=== Evaluation (Recall@3) ===\n",
      "Q: what are the benefits of modular design  ✓   top-score=0.4110\n",
      "Q: how does modular design work in vehicles ✓   top-score=0.3477\n",
      "\n",
      "Recall@3: 2/2  →  100.0%\n",
      "\n",
      "FAISS log → /Users/mohammadalmusaiteer/PyNucleus-Model/chunk_reports/faiss_analysis_20250610_125339.txt\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "from core_modules.rag import config\n",
    "\n",
    "# Clear any cached imports to ensure we get the latest versions\n",
    "modules_to_reload = [\n",
    "    'core_modules.rag.wiki_scraper',\n",
    "    'core_modules.rag.document_processor', \n",
    "    'core_modules.rag.data_chunking',\n",
    "    'core_modules.rag.vector_store'\n",
    "]\n",
    "\n",
    "for module_name in modules_to_reload:\n",
    "    if module_name in sys.modules:\n",
    "        importlib.reload(sys.modules[module_name])\n",
    "\n",
    "sys.path.append(os.path.abspath('.'))\n",
    "\n",
    "# Project module imports\n",
    "from core_modules.rag.document_processor import process_documents\n",
    "from core_modules.rag.wiki_scraper import scrape_wikipedia_articles\n",
    "from core_modules.rag.data_chunking import load_and_chunk_files, save_chunked_data\n",
    "from core_modules.rag.vector_store import FAISSDBManager, _load_docs \n",
    "from core_modules.rag.performance_analyzer import PerformanceAnalyzer\n",
    "from core_modules.rag import config\n",
    "\n",
    "# Test the import to make sure it works\n",
    "print(\"🔧 Testing imports...\")\n",
    "try:\n",
    "    from core_modules.rag.wiki_scraper import scrape_wikipedia_article\n",
    "    print(\"✅ scrape_wikipedia_article imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Import error: {e}\")\n",
    "\n",
    "print(\"🚀 All imports ready!\\n\")\n",
    "\n",
    "# Step 1: Process source documents (PDF, DOCX, etc.)\n",
    "print(\"Step 1: Processing source documents...\")\n",
    "process_documents()\n",
    "\n",
    "# Step 2: Scrape Wikipedia articles\n",
    "print(\"\\nStep 2: Scraping Wikipedia articles...\")\n",
    "scrape_wikipedia_articles()\n",
    "\n",
    "# Step 3: Process and chunk all documents\n",
    "print(\"\\nStep 3: Processing and chunking documents...\")\n",
    "chunked_docs = load_and_chunk_files()\n",
    "save_chunked_data(chunked_docs)\n",
    "\n",
    "# Step 4: Build and evaluate the FAISS vector store\n",
    "print(\"\\nStep 4: Building and evaluating FAISS vector store...\")   \n",
    "\n",
    "GROUND_TRUTH = config.GROUND_TRUTH_DATA\n",
    "JSON_PATH = str(config.FULL_JSON_PATH)\n",
    "\n",
    "f_mgr = FAISSDBManager()\n",
    "f_docs = _load_docs(JSON_PATH, f_mgr.log)\n",
    "f_mgr.build(f_docs)\n",
    "f_mgr.evaluate(GROUND_TRUTH)\n",
    "print(f\"\\nFAISS log → {f_mgr.log_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Testing diverse queries...\n",
      "\n",
      "=== FAISS VectorDB Analysis ===\n",
      "Started: 2025-06-10 12:55:36\n",
      "Loaded 846 documents from /Users/mohammadalmusaiteer/PyNucleus-Model/converted_chunked_data/chunked_data_full.json\n",
      "Embedding device → cpu   | dim=384\n",
      "Docs indexed : 846\n",
      "Index file   : /Users/mohammadalmusaiteer/PyNucleus-Model/chunk_reports/pynucleus_mcp.faiss\n",
      "Embeds .pkl  : /Users/mohammadalmusaiteer/PyNucleus-Model/chunk_reports/embeddings.pkl\n",
      "\n",
      "-- Files in chunk_reports/ --\n",
      "  · faiss_analysis_20250610_011713.txt\n",
      "  · faiss_analysis_20250610_125339.txt\n",
      "  · embeddings.pkl\n",
      "  · faiss_analysis_20250610_012518.txt\n",
      "  · faiss_analysis_20250610_011345.txt\n",
      "  · faiss_analysis_20250610_125131.txt\n",
      "  · pynucleus_mcp.faiss\n",
      "  · faiss_analysis_20250610_125536.txt\n",
      "  · faiss_analysis_20250610_011731.txt\n",
      "  · faiss_analysis_20250610_124413.txt\n",
      "=== Query Results ===\n",
      "\n",
      "\n",
      "📝 Query: What are the key challenges in implementing modular chemical plants?\n",
      "\n",
      "Top 3 Results:\n",
      "\n",
      "1. Score: 0.5875\n",
      "   Source: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      "   Content: Overall Extent: Modular chemical plants have a moderate to high potential to lower several critical economic and infrastructural barriers to African chemical industrialization. Their most significant ...\n",
      "\n",
      "2. Score: 0.6000\n",
      "   Source: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      "   Content: To provide a clearer comparative context, Table 1 summarizes the key characteristics, advantages, and disadvantages of modular versus conventional chemical plant construction approaches.\n",
      "\n",
      "Table 1: Com...\n",
      "\n",
      "3. Score: 0.6108\n",
      "   Source: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      "   Content: These case studies, while varied in scope and detail, collectively demonstrate growing interest and application of modular process plants in developing countries across diverse chemical sub-sectors. T...\n",
      "\n",
      "📝 Query: How does supply chain management affect modular design?\n",
      "\n",
      "Top 3 Results:\n",
      "\n",
      "1. Score: 0.7411\n",
      "   Source: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_modular_design.txt\n",
      "   Content: Modular design, or modularity in design, is a design principle that subdivides a system into smaller parts called modules (such as modular process skids), which can be independently created, modified,...\n",
      "\n",
      "2. Score: 0.7464\n",
      "   Source: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_supply_chain.txt\n",
      "   Content: According to an industrial engineering study which looked at a process for Design for Supply Chain (DFSC), since the product design imposes multiple requirements on the supply chain, then once a produ...\n",
      "\n",
      "3. Score: 0.8460\n",
      "   Source: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_modular_design.txt\n",
      "   Content: Modularity offers benefits such as reduction in cost (customization can be limited to a portion of the system, rather than needing an overhaul of the entire system), interoperability, shorter learning...\n",
      "\n",
      "📝 Query: What are the economic benefits of modular construction?\n",
      "\n",
      "Top 3 Results:\n",
      "\n",
      "1. Score: 0.5366\n",
      "   Source: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_modular_design.txt\n",
      "   Content: Many misconceptions are held regarding modular buildings.[4] In reality modular construction is a viable method of construction for quick turnaround and fast growing companies. Industries that would b...\n",
      "\n",
      "2. Score: 0.6558\n",
      "   Source: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_modular_design.txt\n",
      "   Content: Modularity offers benefits such as reduction in cost (customization can be limited to a portion of the system, rather than needing an overhaul of the entire system), interoperability, shorter learning...\n",
      "\n",
      "3. Score: 0.6602\n",
      "   Source: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_modular_design.txt\n",
      "   Content: systems can create significant competitive advantage in markets.  A true modular system does not need to rely on product cycles to adapt its functionality to the current market state.  Properly design...\n",
      "\n",
      "📝 Query: How does software architecture relate to modular design?\n",
      "\n",
      "Top 3 Results:\n",
      "\n",
      "1. Score: 0.4339\n",
      "   Source: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_modular_design.txt\n",
      "   Content: Modular design, or modularity in design, is a design principle that subdivides a system into smaller parts called modules (such as modular process skids), which can be independently created, modified,...\n",
      "\n",
      "2. Score: 0.6026\n",
      "   Source: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_software_architecture.txt\n",
      "   Content: Software architecture design is commonly juxtaposed with software application design. Whilst application design focuses on the design of the processes and data supporting the required functionality (t...\n",
      "\n",
      "3. Score: 0.6121\n",
      "   Source: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_modular_design.txt\n",
      "   Content: significantly higher than a platform system and requires experts in design and product strategy during the conception phase of system development. That phase must anticipate the directions and levels ...\n",
      "\n",
      "📝 Query: What are the environmental impacts of modular manufacturing?\n",
      "\n",
      "Top 3 Results:\n",
      "\n",
      "1. Score: 0.7035\n",
      "   Source: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      "   Content: (PDF) Modular Manufacturing Processes: Status, Challenges and Opportunities, accessed May 26, 2025, https://www.researchgate.net/publication/318513414_Modular_Manufacturing_Processes_Status_Challenges...\n",
      "\n",
      "2. Score: 0.7424\n",
      "   Source: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      "   Content: Modular Construction, Advantages and Challenges - Real Projectives, accessed May 26, 2025, https://realprojectives.com/the-advantages-and-challenges-of-modular-construction/\n",
      "\n",
      "www.aiche.org, accessed M...\n",
      "\n",
      "3. Score: 0.7768\n",
      "   Source: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      "   Content: 1.2.\tSignificance and Contribution of the Study\n",
      "\n",
      "This study’s contribution is its focused and systematic exploration of how modularization can address the specific constraints of chemical manufacturin...\n",
      "\n",
      "=== Chunking Statistics ===\n",
      "Total Chunks: 846\n",
      "Average Chunk Size: 375.2 characters\n",
      "Number of Sources: 10\n",
      "\n",
      "Chunks per Source:\n",
      "  • Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt: 311 chunks\n",
      "  • Bist_Madan.txt: 296 chunks\n",
      "  • wikipedia_supply_chain.txt: 72 chunks\n",
      "  • wikipedia_industrial_design.txt: 62 chunks\n",
      "  • wikipedia_software_architecture.txt: 59 chunks\n",
      "  • wikipedia_modular_design.txt: 34 chunks\n",
      "  • wikipedia_system_design.txt: 7 chunks\n",
      "  • mcp_basics.txt: 2 chunks\n",
      "  • feasibility_factors.txt: 2 chunks\n",
      "  • sample_document.txt: 1 chunks\n"
     ]
    }
   ],
   "source": [
    "# Test diverse queries\n",
    "print(\"🔍 Testing diverse queries...\\n\")\n",
    "\n",
    "test_queries = [\n",
    "    \"What are the key challenges in implementing modular chemical plants?\",\n",
    "    \"How does supply chain management affect modular design?\",\n",
    "    \"What are the economic benefits of modular construction?\",\n",
    "    \"How does software architecture relate to modular design?\",\n",
    "    \"What are the environmental impacts of modular manufacturing?\"\n",
    "]\n",
    "\n",
    "# Create a new FAISS manager instance\n",
    "f_mgr = FAISSDBManager()\n",
    "f_docs = _load_docs(str(config.FULL_JSON_PATH), f_mgr.log)\n",
    "\n",
    "# Build the index\n",
    "f_mgr.build(f_docs)\n",
    "\n",
    "# Test each query\n",
    "print(\"=== Query Results ===\\n\")\n",
    "for query in test_queries:\n",
    "    print(f\"\\n📝 Query: {query}\")\n",
    "    results = f_mgr.search(query, k=3)\n",
    "    \n",
    "    print(\"\\nTop 3 Results:\")\n",
    "    for i, (doc, score) in enumerate(results, 1):\n",
    "        print(f\"\\n{i}. Score: {score:.4f}\")\n",
    "        print(f\"   Source: {doc.metadata.get('source', 'Unknown')}\")\n",
    "        print(f\"   Content: {doc.page_content[:200]}...\")\n",
    "\n",
    "# Analyze chunking statistics\n",
    "print(\"\\n=== Chunking Statistics ===\")\n",
    "print(f\"Total Chunks: {len(f_docs)}\")\n",
    "print(f\"Average Chunk Size: {sum(len(doc.page_content) for doc in f_docs) / len(f_docs):.1f} characters\")\n",
    "print(f\"Number of Sources: {len(set(doc.metadata.get('source') for doc in f_docs))}\")\n",
    "\n",
    "# Distribution of chunks per source\n",
    "source_counts = {}\n",
    "for doc in f_docs:\n",
    "    source = doc.metadata.get('source', 'Unknown')\n",
    "    source_counts[source] = source_counts.get(source, 0) + 1\n",
    "\n",
    "print(\"\\nChunks per Source:\")\n",
    "for source, count in sorted(source_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  • {source.split('/')[-1]}: {count} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Running DWSIM Quick Demo...\n",
      "🔧 Starting DWSIM simulation workflow...\n",
      "❌ Unexpected error: No module named 'System'\n",
      "\n",
      "💡 To use DWSIM integration:\n",
      "   1. Install DWSIM on your system\n",
      "   2. Set DWSIM_DLL_PATH environment variable\n",
      "   3. Place a .dwsim file in examples/ directory\n",
      "   4. Run: run_dwsim_simulation('your_file.dwsim')\n"
     ]
    }
   ],
   "source": [
    "# DWSIM Simulation - Simple Function Calls\n",
    "from dwsim_workflow import run_dwsim_simulation, quick_dwsim_demo\n",
    "\n",
    "# One-line demo - runs the entire DWSIM workflow\n",
    "quick_dwsim_demo()\n",
    "\n",
    "# Or run a custom simulation:\n",
    "# csv_path = run_dwsim_simulation(\"my_plant.dwsim\", \"results/my_streams.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hISFF6TUEB_H"
   },
   "source": [
    "# This is the last cell of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:50:23.979205Z",
     "start_time": "2025-06-04T16:50:22.863275Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1610,
     "status": "ok",
     "timestamp": 1748965317848,
     "user": {
      "displayName": "Mohammad A.",
      "userId": "15199683412159334052"
     },
     "user_tz": 240
    },
    "id": "tjThfmG7EDzG",
    "outputId": "c0e3a16d-87b8-4a04-ec34-d92e7264e169"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 7699006] Update: Adding all files to repository\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 31 files changed, 4145 insertions(+), 3974 deletions(-)\n",
      " create mode 100644 core_modules/config.py\n",
      " create mode 100644 core_modules/rag/config.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enumerating objects: 85, done.\n",
      "Counting objects: 100% (85/85), done.\n",
      "Delta compression using up to 8 threads\n",
      "Compressing objects: 100% (43/43), done.\n",
      "Writing objects: 100% (45/45), 67.91 KiB | 6.17 MiB/s, done.\n",
      "Total 45 (delta 25), reused 0 (delta 0), pack-reused 0 (from 0)\n",
      "remote: Resolving deltas: 100% (25/25), completed with 24 local objects.\u001b[K\n",
      "remote: \u001b[1;33mwarning\u001b[m: See https://gh.io/lfs for more information.\u001b[K\n",
      "remote: \u001b[1;33mwarning\u001b[m: File vector_db/embeddings.pkl is 87.16 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB\u001b[K\n",
      "remote: \u001b[1;33mwarning\u001b[m: GH001: Large files detected. You may want to try Git Large File Storage - https://git-lfs.github.com.\u001b[K\n",
      "To https://github.com/Saytor20/PyNucleus-Model.git\n",
      "   142560f..7699006  main -> main\n",
      "All files pushed to GitHub successfully!\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Log end time\n",
    "with open(\"update_log.txt\", \"a\") as f:\n",
    "    f.write(f\"\\n {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} changes made and pushed to origin main\\n\")\n",
    "\n",
    "# Simple GitHub update function\n",
    "def update_github():\n",
    "    !git add .\n",
    "    !git commit -m \"Update: Adding all files to repository\"\n",
    "    !git push origin main\n",
    "    print(\"All files pushed to GitHub successfully!\")\n",
    "\n",
    "# To use it, just run:\n",
    "update_github()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
