{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from datetime import datetime\n",
    "# from dotenv import load_dotenv\n",
    "# #\n",
    "# # #--------Google Drive Integration--------#\n",
    "# # # from google.colab import drive, userdata\n",
    "# # # This gives Colab access to your files in Google Drive.\n",
    "# # # drive.mount('/content/drive')\n",
    "# # # 'GITHUB_USERNAME' and 'GITHUB_TOKEN' saved as secrets in Colab.\n",
    "# # GITHUB_USERNAME = userdata.get('GITHUB_USERNAME')\n",
    "# # GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n",
    "# # REPOSITORY_NAME = 'PyNucleus-Model' # Your repository name\n",
    "# # NOTEBOOK_DRIVE_PATH = \"/content/drive/MyDrive/PyNucleus Project/Capstone Project.ipynb\"\n",
    "# #\n",
    "# #\n",
    "# # #--------Cursor Integration--------#\n",
    "# # # Load environment variables from .env file\n",
    "# load_dotenv()\n",
    "# #\n",
    "# # # Get GitHub credentials from environment variables\n",
    "# GITHUB_USERNAME = os.getenv('GITHUB_USERNAME')\n",
    "# GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')\n",
    "# #\n",
    "# # # Print to verify the variables are loaded (remove this in production)\n",
    "# print(f\"Username: {GITHUB_USERNAME}\")\n",
    "# print(f\"Token: {GITHUB_TOKEN[:4]}...\") # Only print first 4 chars of token for security\n",
    "# #\n",
    "# # Repository information\n",
    "# REPOSITORY_NAME = 'PyNucleus-Model'\n",
    "# NOTEBOOK_REPO_FILENAME = \"Capstone Project.ipynb\"\n",
    "# LOG_FILENAME = \"update_log.txt\"\n",
    "\n",
    "# # Pull latest changes from GitHub\n",
    "# print(\"Pulling latest changes from GitHub...\")\n",
    "# !git pull https://{GITHUB_TOKEN}@github.com/{GITHUB_USERNAME}/{REPOSITORY_NAME}.git main\n",
    "\n",
    "# print(\"Repository is up to date!\")\n",
    "\n",
    "# # Log start time\n",
    "# with open(\"update_log.txt\", \"a\") as f:\n",
    "#     f.write(f\" {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}: Log Update\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21621,
     "status": "ok",
     "timestamp": 1748965189264,
     "user": {
      "displayName": "Mohammad A.",
      "userId": "15199683412159334052"
     },
     "user_tz": 240
    },
    "id": "pxJK6GpyVui7",
    "outputId": "5fcaf74f-4292-4847-fb37-57d1c0d9a971"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PyNucleus Model - Pipeline Ready!\n",
      " Available Components:\n",
      "   â€¢ RAGPipeline - Document processing and retrieval\n",
      "   â€¢ DWSIMPipeline - Chemical process simulation\n",
      "   â€¢ ResultsExporter - CSV export functionality\n",
      "   â€¢ PipelineUtils - Complete pipeline orchestration\n"
     ]
    }
   ],
   "source": [
    "# PyNucleus Model - Setup and Imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to Python path\n",
    "src_path = str(Path().resolve() / \"src\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "# Import PyNucleus Pipeline modules\n",
    "from pynucleus.pipeline import RAGPipeline, DWSIMPipeline, ResultsExporter, PipelineUtils\n",
    "from pynucleus.integration.config_manager import ConfigManager\n",
    "from pynucleus.integration.dwsim_rag_integrator import DWSIMRAGIntegrator\n",
    "from pynucleus.integration.llm_output_generator import LLMOutputGenerator\n",
    "\n",
    "\n",
    "print(\" PyNucleus Model - Pipeline Ready!\")\n",
    "print(\" Available Components:\")\n",
    "print(\"   â€¢ RAGPipeline - Document processing and retrieval\")\n",
    "print(\"   â€¢ DWSIMPipeline - Chemical process simulation\") \n",
    "print(\"   â€¢ ResultsExporter - CSV export functionality\")\n",
    "print(\"   â€¢ PipelineUtils - Complete pipeline orchestration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84DXL9QuH0Tx"
   },
   "source": [
    "# **PyNucleus Model - Complete Pipeline**\n",
    "\n",
    "This notebook contains the complete PyNucleus model pipeline with separate sections for:\n",
    "1. **Data Ingestion and Preprocessing for RAG** \n",
    "2. **DWSIM Integration and Simulation**\n",
    "3. **Results Export to CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Setting up RAG imports...\n",
      "âœ… RAG imports ready!\n",
      "ğŸ”§ Setting up DWSIM imports...\n",
      "âœ… DWSIM modules imported successfully\n",
      "ğŸ“ Results directory: data/05_output/results\n",
      "ğŸ”§ Pipeline Utils initialized with results dir: data/05_output/results\n",
      "ğŸ”— DWSIM-RAG integration enabled\n",
      "\n",
      "ğŸ”§ Pipeline Initialized!\n",
      "Available Functions:\n",
      "   â€¢ pipeline.run_complete_pipeline() - Run everything\n",
      "   â€¢ pipeline.run_rag_only() - RAG pipeline only\n",
      "   â€¢ pipeline.run_dwsim_only() - DWSIM simulations only\n",
      "   â€¢ pipeline.quick_test() - Verify status\n",
      "   â€¢ pipeline.view_results_summary() - View results\n",
      "   â€¢ pipeline.print_pipeline_status() - Detailed status\n",
      "   â€¢ pipeline.clean_all_results() - Clean all data\n"
     ]
    }
   ],
   "source": [
    "# Initialize Pipeline Components\n",
    "pipeline = PipelineUtils(results_dir=\"data/05_output/results\")\n",
    "\n",
    "\n",
    "print(\"\\nğŸ”§ Pipeline Initialized!\")\n",
    "print(\"Available Functions:\")\n",
    "print(\"   â€¢ pipeline.run_complete_pipeline() - Run everything\")\n",
    "print(\"   â€¢ pipeline.run_rag_only() - RAG pipeline only\")  \n",
    "print(\"   â€¢ pipeline.run_dwsim_only() - DWSIM simulations only\")\n",
    "print(\"   â€¢ pipeline.quick_test() - Verify status\")\n",
    "print(\"   â€¢ pipeline.view_results_summary() - View results\")\n",
    "print(\"   â€¢ pipeline.print_pipeline_status() - Detailed status\")\n",
    "print(\"   â€¢ pipeline.clean_all_results() - Clean all data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Running complete PyNucleus pipeline...\n",
      "ğŸ—‘ï¸ RAG results cleared.\n",
      "ğŸ—‘ï¸ DWSIM results cleared.\n",
      "ğŸ”¬ Step 1: Running DWSIM simulations...\n",
      "ğŸ”¬ Starting DWSIM Simulations...\n",
      "ğŸ“‹ Running 5 simulation cases...\n",
      "\n",
      "ğŸ§ª Case 1/5: distillation_ethanol_water\n",
      "   âœ… Success - Duration: 0.00s\n",
      "\n",
      "ğŸ§ª Case 2/5: reactor_methane_combustion\n",
      "   âœ… Success - Duration: 0.00s\n",
      "\n",
      "ğŸ§ª Case 3/5: heat_exchanger_steam\n",
      "   âœ… Success - Duration: 0.00s\n",
      "\n",
      "ğŸ§ª Case 4/5: absorber_co2_capture\n",
      "   âœ… Success - Duration: 0.00s\n",
      "\n",
      "ğŸ§ª Case 5/5: crystallizer_salt\n",
      "   âœ… Success - Duration: 0.00s\n",
      "\n",
      "ğŸ“Š Simulation Summary:\n",
      "   â€¢ Successful simulations: 5/5\n",
      "   â€¢ Failed simulations: 0/5\n",
      "ğŸ“Š DWSIM Statistics:\n",
      "   â€¢ Total Simulations: 5\n",
      "   â€¢ Success Rate: 100.0%\n",
      "   â€¢ Average Duration: 0.00s\n",
      "\n",
      "ğŸ“š Step 2: Running RAG pipeline with DWSIM integration...\n",
      "ğŸ“š Starting RAG Pipeline...\n",
      "Step 1: Processing source documents...\n",
      "--- ğŸ“„ Starting processing for 4 file(s) in '/Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/source_documents' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " â–¶ Processing: Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.docx\n",
      "   â€¢ Success! Saved to: /Users/mohammadalmusaiteer/PyNucleus-Model/data/02_processed/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      " â–¶ Processing: mcp_basics.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:unstructured:libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "Processing files:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.45it/s]WARNING:unstructured:libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   â€¢ Success! Saved to: /Users/mohammadalmusaiteer/PyNucleus-Model/data/02_processed/converted_to_txt/mcp_basics.txt\n",
      " â–¶ Processing: feasibility_factors.txt\n",
      "   â€¢ Success! Saved to: /Users/mohammadalmusaiteer/PyNucleus-Model/data/02_processed/converted_to_txt/feasibility_factors.txt\n",
      " â–¶ Processing: Bist_Madan.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   â€¢ Success! Saved to: /Users/mohammadalmusaiteer/PyNucleus-Model/data/02_processed/converted_to_txt/Bist_Madan.txt\n",
      "\n",
      " All files processed.\n",
      "\n",
      "Step 2: Scraping Wikipedia articles...\n",
      "ğŸ” Starting Wikipedia article search for 5 keywords...\n",
      "â–¶ï¸  Searching for: modular design\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ…  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_modular_design.txt\n",
      "â–¶ï¸  Searching for: software architecture\n",
      "âœ…  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_software_architecture.txt\n",
      "â–¶ï¸  Searching for: system design\n",
      "âœ…  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_system_design.txt\n",
      "â–¶ï¸  Searching for: industrial design\n",
      "âœ…  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_industrial_design.txt\n",
      "â–¶ï¸  Searching for: supply chain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pynucleus.integration.dwsim_data_integrator:DWSIMDataIntegrator initialized with output: data/05_output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ…  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_supply_chain.txt\n",
      "\n",
      "âœ¨ Article scraping complete!\n",
      "\n",
      "Step 3: Processing and chunking documents...\n",
      "ğŸ“° Found 5 Wikipedia articles\n",
      "ğŸ“„ Found 4 converted documents\n",
      "ğŸ“‹ Total documents loaded: 9\n",
      "âœ‚ï¸ Split into 845 chunks\n",
      "\n",
      "âœ… Successfully saved chunked data to /Users/mohammadalmusaiteer/PyNucleus-Model/data/03_intermediate/converted_chunked_data/:\n",
      "  â€¢ chunked_data_full.json - Complete data with metadata\n",
      "  â€¢ chunked_data_stats.json - Statistical analysis\n",
      "  â€¢ chunked_data_content.txt - Human-readable content\n",
      "\n",
      "\n",
      "Step 4: Integrating DWSIM simulation data...\n",
      "   âš ï¸ No DWSIM simulation results found - skipping integration\n",
      "\n",
      "Step 5: Building FAISS vector store...\n",
      "=== FAISS VectorDB Analysis ===\n",
      "Started: 2025-06-11 21:19:50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 845 documents from /Users/mohammadalmusaiteer/PyNucleus-Model/data/03_intermediate/converted_chunked_data/chunked_data_full.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:faiss.loader:Loading faiss.\n",
      "INFO:faiss.loader:Successfully loaded faiss.\n",
      "INFO:faiss:Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding device â†’ cpu   | dim=384\n",
      "Docs indexed : 845\n",
      "Index file   : /Users/mohammadalmusaiteer/PyNucleus-Model/data/04_models/chunk_reports/pynucleus_mcp.faiss\n",
      "Embeds .pkl  : /Users/mohammadalmusaiteer/PyNucleus-Model/data/04_models/chunk_reports/embeddings.pkl\n",
      "\n",
      "-- Files in chunk_reports/ --\n",
      "  Â· embeddings.pkl\n",
      "  Â· faiss_analysis_20250611_211950.txt\n",
      "  Â· pynucleus_mcp.faiss\n",
      "\n",
      "=== Evaluation (Recall@3) ===\n",
      "Q: what are the benefits of modular design  âœ“   top-score=0.4110\n",
      "Q: how does modular design work in vehicles âœ“   top-score=0.3477\n",
      "\n",
      "Recall@3: 2/2  â†’  100.0%\n",
      "âœ… RAG Pipeline completed! FAISS log â†’ /Users/mohammadalmusaiteer/PyNucleus-Model/data/04_models/chunk_reports/faiss_analysis_20250611_211950.txt\n",
      "ğŸ” Testing RAG queries...\n",
      "\n",
      "ğŸ“ Query: What are the key challenges in implementing modular chemical plants?\n",
      "   1. Score: 0.5875 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/data/02_processed/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      "   2. Score: 0.6000 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/data/02_processed/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      "   3. Score: 0.6108 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/data/02_processed/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      "\n",
      "ğŸ“ Query: How does supply chain management affect modular design?\n",
      "   1. Score: 0.7411 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_modular_design.txt\n",
      "   2. Score: 0.7464 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_supply_chain.txt\n",
      "   3. Score: 0.8460 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_modular_design.txt\n",
      "\n",
      "ğŸ“ Query: What are the economic benefits of modular construction?\n",
      "   1. Score: 0.5366 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_modular_design.txt\n",
      "   2. Score: 0.6558 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_modular_design.txt\n",
      "   3. Score: 0.6602 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_modular_design.txt\n",
      "\n",
      "ğŸ“ Query: How does software architecture relate to modular design?\n",
      "   1. Score: 0.4339 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_modular_design.txt\n",
      "   2. Score: 0.6026 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_software_architecture.txt\n",
      "   3. Score: 0.6121 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_modular_design.txt\n",
      "\n",
      "ğŸ“ Query: What are the environmental impacts of modular manufacturing?\n",
      "   1. Score: 0.7035 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/data/02_processed/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      "   2. Score: 0.7424 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/data/02_processed/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      "   3. Score: 0.7768 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/data/02_processed/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      "âœ… Query testing completed! 15 results collected.\n",
      "\n",
      "ğŸ’¾ Step 3: Exporting results...\n",
      "\n",
      "ğŸ’¾ Exporting DWSIM simulation results...\n",
      "âœ… DWSIM results exported: data/05_output/results/dwsim_simulation_results.csv\n",
      "   ğŸ“Š 5 simulation results exported\n",
      "   ğŸ“‹ Columns: Case Name, Type, Components, Status, Performance Metrics\n",
      "âœ… DWSIM summary exported: data/05_output/results/dwsim_summary.csv\n",
      "\n",
      "ğŸ‰ Export completed successfully!\n",
      "ğŸ“ All results saved in: data/05_output/results\n",
      "ğŸ“ˆ Files created:\n",
      "   â€¢ dwsim_simulation_results.csv (914 bytes)\n",
      "   â€¢ dwsim_summary.csv (360 bytes)\n",
      "âœ… Complete pipeline finished in 13.4 seconds!\n",
      "\n",
      "ğŸ‰ Pipeline completed in 13.4 seconds!\n",
      "ğŸ“Š RAG Results: 15 queries processed\n",
      "ğŸ”¬ DWSIM Results: 5 simulations completed\n",
      "ğŸ“ Exported Files: 2 CSV files created\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# SECTION 1: COMPLETE PIPELINE - Run Everything (Basic Mode)\n",
    "\"\"\"This section is the basic pipeline which covers \n",
    "- Runs standard RAG + DWSIM + CSV Export\n",
    "- Output: Basic CSV files with simulation results\n",
    "- For: Regular users who need standard functionality \"\"\"\n",
    "# ========================================\n",
    "\n",
    "# Run the complete pipeline (RAG + DWSIM + Export)\n",
    "results = pipeline.run_complete_pipeline()\n",
    "\n",
    "# Display results summary\n",
    "if results:\n",
    "    print(f\"\\nğŸ‰ Pipeline completed in {results['duration']:.1f} seconds!\")\n",
    "    print(f\"ğŸ“Š RAG Results: {len(results['rag_data'])} queries processed\")\n",
    "    print(f\"ğŸ”¬ DWSIM Results: {len(results['dwsim_data'])} simulations completed\")\n",
    "    print(f\"ğŸ“ Exported Files: {len(results['exported_files'])} CSV files created\")\n",
    "else:\n",
    "    print(\"âŒ Pipeline execution failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ========================================\n",
    "# # OPTIONAL: INDIVIDUAL PIPELINE COMPONENTS\n",
    "# # ========================================\n",
    "\n",
    "# # Option 1: Run only RAG Pipeline\n",
    "# print(\"ğŸ“š RAG Only Pipeline:\")\n",
    "# rag_results = pipeline.run_rag_only()\n",
    "# if rag_results:\n",
    "#     print(f\"   âœ… {len(rag_results['rag_data'])} RAG queries processed\")\n",
    "\n",
    "# print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# # Option 2: Run only DWSIM Simulations  \n",
    "# print(\"ğŸ”¬ DWSIM Only Pipeline:\")\n",
    "# dwsim_results = pipeline.run_dwsim_only()\n",
    "# if dwsim_results:\n",
    "#     print(f\"   âœ… {len(dwsim_results['dwsim_data'])} DWSIM simulations completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ========================================\n",
    "# # OPTIONAL: View Results & Status (After Running Pipelines)\n",
    "# # ========================================\n",
    "\n",
    "# # View pipeline status\n",
    "# pipeline.print_pipeline_status()\n",
    "\n",
    "# print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# # View results summary\n",
    "# pipeline.view_results_summary()\n",
    "\n",
    "# print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# # Quick test\n",
    "# test_results = pipeline.quick_test()\n",
    "# print(f\"âœ… Quick test completed! Found {test_results['csv_files_count']} CSV files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# OPTIONAL: CLEANUP AND RESET (Optional)\n",
    "# ========================================\n",
    "# Uncomment the lines below if you need to clean up results:\n",
    "\n",
    "# Clean up and reset (optional - removes all previous results)\n",
    "# pipeline.clean_all_results()\n",
    "\n",
    "# print(\"âœ… PyNucleus Pipeline is ready!\")\n",
    "# print(\"ğŸ“‹ Usage Guide:\")\n",
    "# print(\"   â€¢ Section 1: Run complete pipeline (RAG + DWSIM + Export)\")\n",
    "# print(\"   â€¢ Section 2: Individual components (commented out)\")\n",
    "# print(\"   â€¢ Section 3: Utility functions (status, summary, test)\")\n",
    "# print(\"   â€¢ Enhanced Pipeline: Advanced configuration, integration, LLM output\")\n",
    "# print(\"   â€¢ Enhanced Features: Configuration, Integration, LLM Output\")\n",
    "# print(\"\\nğŸ”„ Run any cell multiple times to re-execute components\")\n",
    "# print(\"ğŸ“ All results automatically saved as CSV files in data/05_output/results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# OPTION A: Run Individual Components (Alternative to Section 1)\n",
    "# ========================================\n",
    "# Uncomment ONLY the lines you want to run:\n",
    "\n",
    "# Option A1: Complete pipeline (same as Section 1)\n",
    "# results = pipeline.run_complete_pipeline()\n",
    "\n",
    "# Option A2: Individual components only\n",
    "# rag_results = pipeline.run_rag_only()        # RAG documents only\n",
    "# dwsim_results = pipeline.run_dwsim_only()    # DWSIM simulations only"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# **ENHANCED PIPELINE - Advanced Features**\n",
    "\n",
    "This section contains enhanced capabilities for advanced users:\n",
    "\n",
    "1. **Enhanced Pipeline Initialization** (Cell 10) - Initialize advanced components FIRST\n",
    "2. **Configurable DWSIM Simulations** (Cell 11) - JSON/CSV configuration files\n",
    "3. **DWSIM-RAG Integration** (Cell 12) - Enhanced analysis with knowledge insights  \n",
    "4. **LLM-Ready Outputs** (Cell 13) - Text summaries with enhanced feed conditions\n",
    "5. **Production Analytics** (Cell 14) - Recovery rates, ROI, and profit analysis\n",
    "\n",
    "**âš ï¸ CRITICAL: Execute cells in this exact order for enhanced features to work:**\n",
    "**1. Cell 10 (Enhanced Pipeline Initialization) FIRST**\n",
    "**2. Cell 11 (Configuration Templates)**  \n",
    "**3. Cell 12 (DWSIM-RAG Integration)**\n",
    "**4. Cell 13 (LLM-Ready Output with Enhanced Feed Conditions)**\n",
    "**5. Cell 14 (Custom Simulations)**\n",
    "\n",
    "Results are automatically exported to data/05_output/ subdirectories:\n",
    "â€¢ Regular results: data/05_output/results/\n",
    "â€¢ LLM reports: data/05_output/llm_reports/\n",
    "â€¢ Configuration templates: configs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Initializing Enhanced Pipeline Components...\n",
      "âœ… Enhanced Pipeline Ready: Configuration, Integration, LLM Output\n",
      "âœ… LLM reports will be saved to: data/05_output/llm_reports/\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# ENHANCED PIPELINE - Initialize Advanced Features\n",
    "\"\"\"PREREQUISITE: Run Section 1 (Complete Pipeline) first!\n",
    "This section adds advanced capabilities ON TOP OF the basic pipeline:\n",
    "â€¢ Financial analysis with ROI calculations\n",
    "â€¢ LLM-ready reports and summaries  \n",
    "â€¢ DWSIM-RAG integration with enhanced analytics\n",
    "â€¢ Custom configuration templates\"\"\"\n",
    "# ========================================\n",
    "\n",
    "print(\"ğŸ”§ Initializing Enhanced Pipeline Components...\")\n",
    "\n",
    "try:\n",
    "    # Force reload modules to get latest version (fixes notebook caching)\n",
    "    import importlib\n",
    "    \n",
    "    # Clear any cached modules\n",
    "    modules_to_reload = [\n",
    "        'pynucleus.integration.config_manager',\n",
    "        'pynucleus.integration.dwsim_rag_integrator', \n",
    "        'pynucleus.integration.llm_output_generator'\n",
    "    ]\n",
    "    \n",
    "    for module_name in modules_to_reload:\n",
    "        if module_name in sys.modules:\n",
    "            importlib.reload(sys.modules[module_name])\n",
    "    \n",
    "    config_manager = ConfigManager(config_dir=\"configs\")\n",
    "    dwsim_rag_integrator = DWSIMRAGIntegrator(\n",
    "    rag_pipeline=pipeline.rag_pipeline if hasattr(pipeline, 'rag_pipeline') else None,\n",
    "    results_dir=\"data/05_output/results\"\n",
    "    )\n",
    "    llm_generator = LLMOutputGenerator(results_dir=\"data/05_output/llm_reports\")\n",
    "\n",
    "    print(\"âœ… Enhanced Pipeline Ready: Configuration, Integration, LLM Output\")\n",
    "    print(f\"âœ… LLM reports will be saved to: {llm_generator.results_dir}/\")\n",
    "    enhanced_available = True\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Enhanced features not available: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    enhanced_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Pydantic template created: configs/simulation_config_template.json\n",
      "âœ… Template created: configs/simulation_config_template.csv\n",
      "âœ… Configuration templates created:\n",
      "   JSON: configs/simulation_config_template.json\n",
      "   CSV: configs/simulation_config_template.csv\n"
     ]
    }
   ],
   "source": [
    "# ENHANCED PIPELINE STEP 2: Configuration Templates\n",
    "if 'enhanced_available' in locals() and enhanced_available:\n",
    "    json_template = config_manager.create_template_json(\"simulation_config_template.json\", verbose=True)\n",
    "    csv_template = config_manager.create_template_csv(\"simulation_config_template.csv\", verbose=True)\n",
    "    \n",
    "    print(\"âœ… Configuration templates created:\")\n",
    "    print(f\"   JSON: {json_template}\")\n",
    "    print(f\"   CSV: {csv_template}\")\n",
    "else:\n",
    "    print(\"âŒ Enhanced configuration not available\")\n",
    "    print(\"âš ï¸ Run Cell 10 (Enhanced Pipeline Initialization) first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Enhanced 5 simulations with RAG insights\n",
      "âœ… Enhanced Analysis Complete:\n",
      "   Simulations: 5\n",
      "   Performance: Good\n",
      "   Efficiency: High\n",
      "   Results: data/05_output/results/integrated_dwsim_rag_results_20250611_212019.json\n"
     ]
    }
   ],
   "source": [
    "# ENHANCED PIPELINE STEP 3: DWSIM-RAG Integration with Enhanced Analytics\n",
    "if 'enhanced_available' in locals() and enhanced_available:\n",
    "    dwsim_results = pipeline.dwsim_pipeline.get_results()\n",
    "    \n",
    "    if dwsim_results:\n",
    "        # Perform integration\n",
    "        integrated_results = dwsim_rag_integrator.integrate_simulation_results(\n",
    "            dwsim_results, perform_rag_analysis=True\n",
    "        )\n",
    "        \n",
    "        # Export results\n",
    "        integrated_export_file = dwsim_rag_integrator.export_integrated_results()\n",
    "        \n",
    "        # Show key metrics only\n",
    "        if integrated_results:\n",
    "            sample = integrated_results[0]\n",
    "            print(f\"âœ… Enhanced Analysis Complete:\")\n",
    "            print(f\"   Simulations: {len(integrated_results)}\")\n",
    "            print(f\"   Performance: {sample['performance_metrics']['overall_performance']}\")\n",
    "            print(f\"   Efficiency: {sample['performance_metrics']['efficiency_rating']}\")\n",
    "            print(f\"   Results: {integrated_export_file}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ No DWSIM results available\")\n",
    "else:\n",
    "    print(\"âŒ Enhanced integration not available\")\n",
    "    print(\"âš ï¸ Run Cell 10 (Enhanced Pipeline Initialization) first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Running enhanced LLM output generation with detailed feed conditions...\n",
      "âœ… Analysis Reports Generated:\n",
      "   LLM Summaries: 5 files created\n",
      "     â€¢ data/05_output/llm_reports/distillation_ethanol_water_summary.md\n",
      "     â€¢ data/05_output/llm_reports/reactor_methane_combustion_summary.md\n",
      "     â€¢ data/05_output/llm_reports/heat_exchanger_steam_summary.md\n",
      "     â€¢ data/05_output/llm_reports/absorber_co2_capture_summary.md\n",
      "     â€¢ data/05_output/llm_reports/crystallizer_salt_summary.md\n",
      "   Financial Analysis: data/05_output/llm_reports/financial_analysis_20250611_212021.csv\n",
      "\n",
      "ğŸ’° Key Financial Metrics:\n",
      "   Recovery Rate: 82.5%\n",
      "   Daily Revenue: $148,500.00\n",
      "   Daily Profit: $58,500.00\n",
      "   ROI: 6.5%\n"
     ]
    }
   ],
   "source": [
    "# ENHANCED PIPELINE STEP 4: LLM-Ready Output with Enhanced Feed Conditions\n",
    "if 'enhanced_available' in locals() and enhanced_available and 'integrated_results' in locals():\n",
    "    print(\"ğŸ”„ Running enhanced LLM output generation with detailed feed conditions...\")\n",
    "    # Generate LLM summary for each simulation using Jinja2 template\n",
    "    llm_ready_files = []\n",
    "    for i, result in enumerate(integrated_results):\n",
    "        # Template uses original_simulation.case_name, no need to add simulation_name\n",
    "        llm_file = llm_generator.export_llm_ready_text(result)\n",
    "        llm_ready_files.append(llm_file)\n",
    "    \n",
    "    # Export financial analysis and show metrics\n",
    "    financial_file = llm_generator.export_financial_analysis(integrated_results)\n",
    "    metrics = llm_generator._calculate_key_metrics(integrated_results)\n",
    "    \n",
    "    print(f\"âœ… Analysis Reports Generated:\")\n",
    "    print(f\"   LLM Summaries: {len(llm_ready_files)} files created\")\n",
    "    for llm_file in llm_ready_files:\n",
    "        print(f\"     â€¢ {llm_file}\")\n",
    "    print(f\"   Financial Analysis: {financial_file}\")\n",
    "    print(f\"\\nğŸ’° Key Financial Metrics:\")\n",
    "    print(f\"   Recovery Rate: {metrics['avg_recovery']:.1f}%\")\n",
    "    print(f\"   Daily Revenue: ${metrics['estimated_revenue']:,.2f}\")\n",
    "    print(f\"   Daily Profit: ${metrics['net_profit']:,.2f}\")\n",
    "    print(f\"   ROI: {metrics['roi']:.1f}%\")\n",
    "    \n",
    "elif 'enhanced_available' in locals() and enhanced_available:\n",
    "    print(\"âŒ Run Cell 12 (DWSIM-RAG Integration) first to generate integrated_results\")\n",
    "else:\n",
    "    print(\"âŒ Enhanced LLM output not available\")\n",
    "    print(\"âš ï¸ Run Cell 10 (Enhanced Pipeline Initialization) first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prompt system initialized - Template loaded from: /Users/mohammadalmusaiteer/PyNucleus-Model/prompts\n",
      "âœ… Prompt system loaded successfully!\n",
      "ğŸ“š Available functions:\n",
      "   â€¢ create_prompt(question, system_msg=None, context=None, **kwargs)\n",
      "   â€¢ demo_prompts() - Show example prompts\n",
      "   â€¢ validate_prompts() - Test system functionality\n",
      "   â€¢ integrate_pynucleus_results(results) - Generate from simulation data\n",
      "   â€¢ save_prompt(prompt, filename) - Save to file\n",
      "ğŸ§ª PyNucleus Prompt System Demo\n",
      "==================================================\n",
      "\n",
      "ğŸ“‹ Example 1: Process Troubleshooting\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "\n",
      "\n",
      "<SYSTEM>\n",
      "You are an expert chemical process engineer specializing in distillation optimization.\n",
      "\n",
      "CONSTRAINTS:\n",
      "Consider safety protocols, environmental regulations, and cost-effectiveness in all recommendations.\n",
      "\n",
      "OUTPUT FORMAT:\n",
      "Provide response as: 1) Potential causes (ranked by probability), 2) D...\n",
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "ğŸ“‹ Example 2: Safety Analysis\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "\n",
      "\n",
      "<SYSTEM>\n",
      "You are a chemical safety engineer with expertise in process hazard analysis.\n",
      "\n",
      "CONSTRAINTS:\n",
      "Follow OSHA standards and chemical industry best practices.\n",
      "\n",
      "OUTPUT FORMAT:\n",
      "Structure as: Risk Assessment, Safety Systems, Emergency Procedures, Compliance Requirements.\n",
      "</SYSTEM>\n",
      "\n",
      "\n",
      "<CONTEXT>\n",
      "A ne...\n",
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "ğŸ“‹ Example 3: Process Optimization\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "\n",
      "\n",
      "<SYSTEM>\n",
      "You are a process optimization consultant specializing in energy efficiency and cost reduction.\n",
      "\n",
      "OUTPUT FORMAT:\n",
      "Present as: Current Analysis, Optimization Opportunities, Implementation Plan, Expected ROI.\n",
      "</SYSTEM>\n",
      "\n",
      "\n",
      "<CONTEXT>\n",
      "A chemical plant wants to reduce energy consumption in their ...\n",
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ” Running Template Validation Tests...\n",
      "==================================================\n",
      "âœ… Test 1 (Minimal Input): Passed\n",
      "âœ… Test 2 (Complete Input): Passed\n",
      "âœ… Test 3 (Section Structure): Passed\n",
      "==================================================\n",
      "ğŸ‰ All validation tests passed!\n",
      "\n",
      "ğŸ“‹ Example Prompt:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "\n",
      "\n",
      "<SYSTEM>\n",
      "You are an expert chemical process engineer.\n",
      "\n",
      "CONSTRAINTS:\n",
      "Safety first, cost-effective solutions\n",
      "\n",
      "OUTPUT FORMAT:\n",
      "Provide a structured response with causes and solutions.\n",
      "</SYSTEM>\n",
      "\n",
      "\n",
      "<CONT...\n",
      "\n",
      "âœ… Prompt system ready!\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# JINJA2 PROMPT TEMPLATE SYSTEM\n",
    "# ========================================\n",
    "\n",
    "# Simple one-line integration\n",
    "exec(open('prompts/notebook_integration.py').read())\n",
    "\n",
    "# Quick demo and validation\n",
    "demo_prompts()\n",
    "validate_prompts()\n",
    "\n",
    "# Example usage\n",
    "prompt = create_prompt(\n",
    "    question=\"What troubleshooting steps would you recommend for a distillation column showing efficiency issues?\",\n",
    "    system_msg=\"You are an expert chemical process engineer.\",\n",
    "    context=\"A distillation column is showing efficiency issues.\",\n",
    "    constraints=\"Safety first, cost-effective solutions\",\n",
    "    format_instructions=\"Provide a structured response with causes and solutions.\"\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ“‹ Example Prompt:\")\n",
    "print(\"â”€\" * 30)\n",
    "print(prompt[:200] + \"...\" if len(prompt) > 200 else prompt)\n",
    "\n",
    "print(\"\\nâœ… Prompt system ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer for gpt2...\n",
      "Loading model gpt2 on cpu...\n",
      "Model loaded successfully on cpu\n",
      "Model: gpt2, Vocab: 50257\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "\n",
    "from src.pynucleus.llm import LLMRunner\n",
    "\n",
    "# Initialize with default model (gpt2)\n",
    "runner = LLMRunner()\n",
    "\n",
    "# Generate text with custom parameters\n",
    "response = runner.ask(\n",
    "    \"The future of artificial intelligence\",\n",
    "    max_length=50,\n",
    "    temperature=0.7,\n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "# Get model information\n",
    "info = runner.get_model_info()\n",
    "print(f\"Model: {info['model_id']}, Vocab: {info['vocab_size']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: token_utils not available, using fallback\n",
      "ğŸ”§ Using updated LLM Query Manager with /prompts directory...\n",
      "Loading tokenizer for gpt2...\n",
      "Loading model gpt2 on cpu...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.pynucleus.llm.query_llm:Template environment set up with directory: /Users/mohammadalmusaiteer/PyNucleus-Model/prompts\n",
      "INFO:src.pynucleus.llm.query_llm:LLMQueryManager initialized with model: gpt2, max_tokens: 2048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully on cpu\n",
      "âœ… Template directory: /Users/mohammadalmusaiteer/PyNucleus-Model/prompts\n",
      "âœ… Template exists: True\n",
      "âœ… Template rendering successful!\n",
      "ğŸ“‹ Sample rendered prompt structure:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "<SYSTEM>\n",
      "You are a helpful assistant.</SYSTEM>\n",
      "\n",
      "<CONTEXT>No additional context provided.</CONTEXT>\n",
      "\n",
      "<QUESTION>\n",
      "Test query for prompt system validation\n",
      "</QUESTION>\n",
      "\n",
      "Please provide a comprehensive and accurate response based on the information provided above.\n",
      "<ANSWER>\n",
      "</ANSWER> \n",
      "\n",
      "ğŸ‰ LLM Query Manager is now using the correct /prompts directory!\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# LLM Query Manager - Working Examples (FIXED)\n",
    "# ========================================\n",
    "\n",
    "# Force reload the module to get latest changes\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "# Reload the module to pick up template directory changes\n",
    "if 'src.pynucleus.llm.query_llm' in sys.modules:\n",
    "    importlib.reload(sys.modules['src.pynucleus.llm.query_llm'])\n",
    "\n",
    "from src.pynucleus.llm.query_llm import LLMQueryManager, quick_ask_llm\n",
    "\n",
    "print(\"ğŸ”§ Using updated LLM Query Manager with /prompts directory...\")\n",
    "\n",
    "# Initialize manager\n",
    "manager = LLMQueryManager(max_tokens=2048)\n",
    "\n",
    "print(f\"âœ… Template directory: {manager.template_dir}\")\n",
    "print(f\"âœ… Template exists: {manager.template_dir.exists()}\")\n",
    "\n",
    "# For demonstration purposes, let's create a simple test\n",
    "test_prompt = manager.render_prompt(\n",
    "    user_query=\"Test query for prompt system validation\",\n",
    "    system_message=\"You are a helpful assistant.\"\n",
    ")\n",
    "\n",
    "print(\"âœ… Template rendering successful!\")\n",
    "print(\"ğŸ“‹ Sample rendered prompt structure:\")\n",
    "print(\"â”€\" * 50)\n",
    "print(test_prompt[:300] + \"...\" if len(test_prompt) > 300 else test_prompt)\n",
    "\n",
    "print(\"\\nğŸ‰ LLM Query Manager is now using the correct /prompts directory!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ========================================\n",
    "# # VERSION CONTROL (Optional - For Maintainers Only)\n",
    "# # ========================================\n",
    "# # Uncomment the lines below if you need to update the repository:\n",
    "\n",
    "# from datetime import datetime\n",
    "\n",
    "# # Log end time\n",
    "# with open(\"update_log.txt\", \"a\") as f:\n",
    "#     f.write(f\"\\n {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} changes made and pushed to origin main\\n\")\n",
    "\n",
    "# # Simple GitHub update function\n",
    "# def update_github():\n",
    "#     print(\" Starting GitHub update...\")\n",
    "#     !git add .\n",
    "#     print(\" Files added to staging\")\n",
    "#     !git commit -m \"Update: $(date +'%Y-%m-%d %H:%M:%S')\"\n",
    "#     print(\" Changes committed\")\n",
    "#     !git push origin main\n",
    "#     print(\" Changes pushed to GitHub successfully!\")\n",
    "\n",
    "# # To use it, just run:\n",
    "# update_github()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
