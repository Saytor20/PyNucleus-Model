{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from datetime import datetime\n",
    "# from dotenv import load_dotenv\n",
    "# #\n",
    "# # #--------Google Drive Integration--------#\n",
    "# # # from google.colab import drive, userdata\n",
    "# # # This gives Colab access to your files in Google Drive.\n",
    "# # # drive.mount('/content/drive')\n",
    "# # # 'GITHUB_USERNAME' and 'GITHUB_TOKEN' saved as secrets in Colab.\n",
    "# # GITHUB_USERNAME = userdata.get('GITHUB_USERNAME')\n",
    "# # GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n",
    "# # REPOSITORY_NAME = 'PyNucleus-Model' # Your repository name\n",
    "# # NOTEBOOK_DRIVE_PATH = \"/content/drive/MyDrive/PyNucleus Project/Capstone Project.ipynb\"\n",
    "# #\n",
    "# #\n",
    "# # #--------Cursor Integration--------#\n",
    "# # # Load environment variables from .env file\n",
    "# load_dotenv()\n",
    "# #\n",
    "# # # Get GitHub credentials from environment variables\n",
    "# GITHUB_USERNAME = os.getenv('GITHUB_USERNAME')\n",
    "# GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')\n",
    "# #\n",
    "# # # Print to verify the variables are loaded (remove this in production)\n",
    "# print(f\"Username: {GITHUB_USERNAME}\")\n",
    "# print(f\"Token: {GITHUB_TOKEN[:4]}...\") # Only print first 4 chars of token for security\n",
    "# #\n",
    "# # Repository information\n",
    "# REPOSITORY_NAME = 'PyNucleus-Model'\n",
    "# NOTEBOOK_REPO_FILENAME = \"Capstone Project.ipynb\"\n",
    "# LOG_FILENAME = \"update_log.txt\"\n",
    "\n",
    "# # Pull latest changes from GitHub\n",
    "# print(\"Pulling latest changes from GitHub...\")\n",
    "# !git pull https://{GITHUB_TOKEN}@github.com/{GITHUB_USERNAME}/{REPOSITORY_NAME}.git main\n",
    "\n",
    "# print(\"Repository is up to date!\")\n",
    "\n",
    "# # Log start time\n",
    "# with open(\"update_log.txt\", \"a\") as f:\n",
    "#     f.write(f\" {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}: Log Update\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21621,
     "status": "ok",
     "timestamp": 1748965189264,
     "user": {
      "displayName": "Mohammad A.",
      "userId": "15199683412159334052"
     },
     "user_tz": 240
    },
    "id": "pxJK6GpyVui7",
    "outputId": "5fcaf74f-4292-4847-fb37-57d1c0d9a971"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PyNucleus Model - Pipeline Ready!\n",
      " Available Components:\n",
      "   ‚Ä¢ RAGPipeline - Document processing and retrieval\n",
      "   ‚Ä¢ DWSIMPipeline - Chemical process simulation\n",
      "   ‚Ä¢ ResultsExporter - CSV export functionality\n",
      "   ‚Ä¢ PipelineUtils - Complete pipeline orchestration\n"
     ]
    }
   ],
   "source": [
    "# PyNucleus Model - Setup and Imports\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append(os.path.abspath('.'))\n",
    "\n",
    "# Import PyNucleus Pipeline modules\n",
    "from core_modules.pipeline import RAGPipeline, DWSIMPipeline, ResultsExporter, PipelineUtils\n",
    "\n",
    "print(\" PyNucleus Model - Pipeline Ready!\")\n",
    "print(\" Available Components:\")\n",
    "print(\"   ‚Ä¢ RAGPipeline - Document processing and retrieval\")\n",
    "print(\"   ‚Ä¢ DWSIMPipeline - Chemical process simulation\") \n",
    "print(\"   ‚Ä¢ ResultsExporter - CSV export functionality\")\n",
    "print(\"   ‚Ä¢ PipelineUtils - Complete pipeline orchestration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84DXL9QuH0Tx"
   },
   "source": [
    "# **PyNucleus Model - Complete Pipeline**\n",
    "\n",
    "This notebook contains the complete PyNucleus model pipeline with separate sections for:\n",
    "1. **Data Ingestion and Preprocessing for RAG** \n",
    "2. **DWSIM Integration and Simulation**\n",
    "3. **Results Export to CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Pipeline Components\n",
    "pipeline = PipelineUtils()\n",
    "\n",
    "print(\"\\nüîß Pipeline Initialized!\")\n",
    "print(\"Available Functions:\")\n",
    "print(\"   ‚Ä¢ pipeline.run_complete_pipeline() - Run everything\")\n",
    "print(\"   ‚Ä¢ pipeline.run_rag_only() - RAG pipeline only\")  \n",
    "print(\"   ‚Ä¢ pipeline.run_dwsim_only() - DWSIM simulations only\")\n",
    "print(\"   ‚Ä¢ pipeline.quick_test() - Verify status\")\n",
    "print(\"   ‚Ä¢ pipeline.view_results_summary() - View results\")\n",
    "print(\"   ‚Ä¢ pipeline.print_pipeline_status() - Detailed status\")\n",
    "print(\"   ‚Ä¢ pipeline.clean_all_results() - Clean all data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Running complete PyNucleus pipeline...\n",
      "üóëÔ∏è RAG results cleared.\n",
      "üóëÔ∏è DWSIM results cleared.\n",
      "üìö Starting RAG Pipeline...\n",
      "Step 1: Processing source documents...\n",
      "--- üìÑ Starting processing for 5 file(s) in '/Users/mohammadalmusaiteer/PyNucleus-Model/source_documents' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   0%|          | 0/5 [00:00<?, ?it/s]WARNING: libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "WARNING: libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ‚ñ∂ Processing: Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.docx\n",
      "   ‚Ä¢ Success! Saved to: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      " ‚ñ∂ Processing: mcp_basics.txt\n",
      "   ‚Ä¢ Success! Saved to: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/mcp_basics.txt\n",
      " ‚ñ∂ Processing: feasibility_factors.txt\n",
      "   ‚Ä¢ Success! Saved to: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/feasibility_factors.txt\n",
      " ‚ñ∂ Processing: Bist_Madan.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00,  8.79it/s]WARNING: libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "Processing files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 10.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚Ä¢ Success! Saved to: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/Bist_Madan.txt\n",
      " ‚ñ∂ Processing: sample_document.txt\n",
      "   ‚Ä¢ Success! Saved to: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/sample_document.txt\n",
      "\n",
      " All files processed.\n",
      "\n",
      "Step 2: Scraping Wikipedia articles...\n",
      "üîç Starting Wikipedia article search for 5 keywords...\n",
      "‚ñ∂Ô∏è  Searching for: modular design\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_modular_design.txt\n",
      "‚ñ∂Ô∏è  Searching for: software architecture\n",
      "‚úÖ  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_software_architecture.txt\n",
      "‚ñ∂Ô∏è  Searching for: system design\n",
      "‚úÖ  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_system_design.txt\n",
      "‚ñ∂Ô∏è  Searching for: industrial design\n",
      "‚úÖ  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_industrial_design.txt\n",
      "‚ñ∂Ô∏è  Searching for: supply chain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_supply_chain.txt\n",
      "\n",
      "‚ú® Article scraping complete!\n",
      "\n",
      "Step 3: Processing and chunking documents...\n",
      "üì∞ Found 5 Wikipedia articles\n",
      "üìÑ Found 5 converted documents\n",
      "üìã Total documents loaded: 10\n",
      "‚úÇÔ∏è Split into 846 chunks\n",
      "\n",
      "‚úÖ Successfully saved chunked data to /Users/mohammadalmusaiteer/PyNucleus-Model/converted_chunked_data/:\n",
      "  ‚Ä¢ chunked_data_full.json - Complete data with metadata\n",
      "  ‚Ä¢ chunked_data_stats.json - Statistical analysis\n",
      "  ‚Ä¢ chunked_data_content.txt - Human-readable content\n",
      "\n",
      "\n",
      "Step 4: Building FAISS vector store...\n",
      "=== FAISS VectorDB Analysis ===\n",
      "Started: 2025-06-10 16:07:26\n",
      "Loaded 846 documents from /Users/mohammadalmusaiteer/PyNucleus-Model/converted_chunked_data/chunked_data_full.json\n",
      "Embedding device ‚Üí cpu   | dim=384\n",
      "Docs indexed : 846\n",
      "Index file   : /Users/mohammadalmusaiteer/PyNucleus-Model/chunk_reports/pynucleus_mcp.faiss\n",
      "Embeds .pkl  : /Users/mohammadalmusaiteer/PyNucleus-Model/chunk_reports/embeddings.pkl\n",
      "\n",
      "-- Files in chunk_reports/ --\n",
      "  ¬∑ embeddings.pkl\n",
      "  ¬∑ pynucleus_mcp.faiss\n",
      "  ¬∑ faiss_analysis_20250610_160726.txt\n",
      "\n",
      "=== Evaluation (Recall@3) ===\n",
      "Q: what are the benefits of modular design  ‚úì   top-score=0.4110\n",
      "Q: how does modular design work in vehicles ‚úì   top-score=0.3477\n",
      "\n",
      "Recall@3: 2/2  ‚Üí  100.0%\n",
      "‚úÖ RAG Pipeline completed! FAISS log ‚Üí /Users/mohammadalmusaiteer/PyNucleus-Model/chunk_reports/faiss_analysis_20250610_160726.txt\n",
      "üîç Testing RAG queries...\n",
      "\n",
      "üìù Query: What are the key challenges in implementing modular chemical plants?\n",
      "   1. Score: 0.5875 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      "   2. Score: 0.6000 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      "   3. Score: 0.6108 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      "\n",
      "üìù Query: How does supply chain management affect modular design?\n",
      "   1. Score: 0.7411 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_modular_design.txt\n",
      "   2. Score: 0.7464 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_supply_chain.txt\n",
      "   3. Score: 0.8460 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_modular_design.txt\n",
      "\n",
      "üìù Query: What are the economic benefits of modular construction?\n",
      "   1. Score: 0.5366 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_modular_design.txt\n",
      "   2. Score: 0.6558 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_modular_design.txt\n",
      "   3. Score: 0.6602 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_modular_design.txt\n",
      "\n",
      "üìù Query: How does software architecture relate to modular design?\n",
      "   1. Score: 0.4339 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_modular_design.txt\n",
      "   2. Score: 0.6026 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_software_architecture.txt\n",
      "   3. Score: 0.6121 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_modular_design.txt\n",
      "\n",
      "üìù Query: What are the environmental impacts of modular manufacturing?\n",
      "   1. Score: 0.7035 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      "   2. Score: 0.7424 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      "   3. Score: 0.7768 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      "‚úÖ Query testing completed! 15 results collected.\n",
      "üìä RAG Statistics:\n",
      "   ‚Ä¢ Total Chunks: 846\n",
      "   ‚Ä¢ Average Chunk Size: 375.2 characters\n",
      "   ‚Ä¢ Number of Sources: 10\n",
      "üî¨ Starting DWSIM Simulations...\n",
      "üìã Running 5 simulation cases...\n",
      "\n",
      "üß™ Case 1/5: distillation_ethanol_water\n",
      "   ‚úÖ Success - Duration: 0.00s\n",
      "\n",
      "üß™ Case 2/5: reactor_methane_combustion\n",
      "   ‚úÖ Success - Duration: 0.00s\n",
      "\n",
      "üß™ Case 3/5: heat_exchanger_steam\n",
      "   ‚úÖ Success - Duration: 0.00s\n",
      "\n",
      "üß™ Case 4/5: absorber_co2_capture\n",
      "   ‚úÖ Success - Duration: 0.00s\n",
      "\n",
      "üß™ Case 5/5: crystallizer_salt\n",
      "   ‚úÖ Success - Duration: 0.00s\n",
      "\n",
      "üìä Simulation Summary:\n",
      "   ‚Ä¢ Successful simulations: 5/5\n",
      "   ‚Ä¢ Failed simulations: 0/5\n",
      "üìä DWSIM Statistics:\n",
      "   ‚Ä¢ Total Simulations: 5\n",
      "   ‚Ä¢ Success Rate: 100.0%\n",
      "   ‚Ä¢ Average Duration: 0.00s\n",
      "\n",
      "üíæ Exporting all results to CSV files...\n",
      "‚úÖ RAG results exported: results/rag_query_results.csv\n",
      "   üìä 15 query results exported\n",
      "‚úÖ DWSIM results exported: results/dwsim_simulation_results.csv\n",
      "   üìä 5 simulation results exported\n",
      "‚úÖ Statistics exported: results/rag_statistics.csv\n",
      "‚úÖ Statistics exported: results/dwsim_statistics.csv\n",
      "‚úÖ Pipeline summary exported: results/pipeline_summary.csv\n",
      "\n",
      "üéâ Export completed successfully!\n",
      "üìÅ All results saved in: results\n",
      "üìà Files created:\n",
      "   ‚Ä¢ rag_query_results.csv (12,340 bytes)\n",
      "   ‚Ä¢ dwsim_simulation_results.csv (1,539 bytes)\n",
      "   ‚Ä¢ rag_statistics.csv (95 bytes)\n",
      "   ‚Ä¢ dwsim_statistics.csv (136 bytes)\n",
      "   ‚Ä¢ pipeline_summary.csv (288 bytes)\n",
      "‚úÖ Complete pipeline finished in 24.7 seconds!\n",
      "\n",
      "üéâ Pipeline completed in 24.7 seconds!\n",
      "üìä RAG Results: 15 queries processed\n",
      "üî¨ DWSIM Results: 5 simulations completed\n",
      "üìÅ Exported Files: 5 CSV files created\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# SECTION 1: COMPLETE PIPELINE - Run Everything\n",
    "# ========================================\n",
    "\n",
    "# Run the complete pipeline (RAG + DWSIM + Export)\n",
    "results = pipeline.run_complete_pipeline()\n",
    "\n",
    "# Display results summary\n",
    "if results:\n",
    "    print(f\"\\nüéâ Pipeline completed in {results['duration']:.1f} seconds!\")\n",
    "    print(f\"üìä RAG Results: {len(results['rag_data'])} queries processed\")\n",
    "    print(f\"üî¨ DWSIM Results: {len(results['dwsim_data'])} simulations completed\")\n",
    "    print(f\"üìÅ Exported Files: {len(results['exported_files'])} CSV files created\")\n",
    "else:\n",
    "    print(\"‚ùå Pipeline execution failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# SECTION 2: INDIVIDUAL PIPELINE COMPONENTS\n",
    "# ========================================\n",
    "\n",
    "# Option 1: Run only RAG Pipeline\n",
    "print(\"üìö RAG Only Pipeline:\")\n",
    "rag_results = pipeline.run_rag_only()\n",
    "if rag_results:\n",
    "    print(f\"   ‚úÖ {len(rag_results['rag_data'])} RAG queries processed\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Option 2: Run only DWSIM Simulations  \n",
    "print(\"üî¨ DWSIM Only Pipeline:\")\n",
    "dwsim_results = pipeline.run_dwsim_only()\n",
    "if dwsim_results:\n",
    "    print(f\"   ‚úÖ {len(dwsim_results['dwsim_data'])} DWSIM simulations completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# SECTION 3: UTILITY FUNCTIONS\n",
    "# ========================================\n",
    "\n",
    "# View pipeline status\n",
    "pipeline.print_pipeline_status()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# View results summary\n",
    "pipeline.view_results_summary()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Quick test\n",
    "test_results = pipeline.quick_test()\n",
    "print(f\"‚úÖ Quick test completed! Found {test_results['csv_files_count']} CSV files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# SECTION 4: SIMPLE FUNCTION CALLS\n",
    "# ========================================\n",
    "\n",
    "print(\"üéØ Simple Function Calls for Easy Testing:\")\n",
    "print()\n",
    "\n",
    "# Individual Component Access\n",
    "print(\"üìö Access individual components:\")\n",
    "print(\"   ‚Ä¢ rag = pipeline.rag_pipeline\")\n",
    "print(\"   ‚Ä¢ dwsim = pipeline.dwsim_pipeline\") \n",
    "print(\"   ‚Ä¢ exporter = pipeline.exporter\")\n",
    "print()\n",
    "\n",
    "# Custom Simulations\n",
    "print(\"üß™ Run custom simulations:\")\n",
    "custom_case = {\n",
    "    \"name\": \"custom_test\",\n",
    "    \"type\": \"reactor\", \n",
    "    \"components\": [\"hydrogen\", \"nitrogen\"],\n",
    "    \"description\": \"Custom ammonia synthesis reactor\"\n",
    "}\n",
    "\n",
    "print(f\"Running custom simulation: {custom_case['name']}\")\n",
    "custom_result = pipeline.dwsim_pipeline.run_single_simulation(custom_case)\n",
    "if custom_result:\n",
    "    print(f\"   ‚úÖ Custom simulation completed: {custom_result['success']}\")\n",
    "\n",
    "print()\n",
    "print(\"üìÅ All results automatically saved as CSV files in ./results/ directory\")\n",
    "print(\"üîÑ Run any cell again to re-execute that specific pipeline component\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up and reset (optional)\n",
    "# pipeline.clean_all_results()  # Uncomment to clean all previous results\n",
    "\n",
    "print(\" PyNucleus Pipeline is ready!\")\n",
    "print(\" Use the functions above to run different parts of the pipeline\")\n",
    "print(\" All results are automatically exported to CSV files\")\n",
    "print(\" You can run any cell multiple times to re-execute components\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete pipeline\n",
    "results = pipeline.run_complete_pipeline()\n",
    "\n",
    "# Individual components\n",
    "rag_results = pipeline.run_rag_only()\n",
    "dwsim_results = pipeline.run_dwsim_only()\n",
    "\n",
    "# Utilities\n",
    "pipeline.quick_test()\n",
    "pipeline.view_results_summary()\n",
    "pipeline.print_pipeline_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the last step in the code for version control purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Starting GitHub update for branch: Main-+-RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Files added to staging\n",
      "[main 556c75b] Update: 2025-06-10 16:18:36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 43 files changed, 5396 insertions(+), 763 deletions(-)\n",
      " delete mode 100644 chunk_reports/faiss_analysis_20250610_011345.txt\n",
      " delete mode 100644 chunk_reports/faiss_analysis_20250610_011713.txt\n",
      " delete mode 100644 chunk_reports/faiss_analysis_20250610_011731.txt\n",
      " delete mode 100644 chunk_reports/faiss_analysis_20250610_012518.txt\n",
      " create mode 100644 core_modules/pipeline/__init__.py\n",
      " create mode 100644 core_modules/pipeline/pipeline_dwsim.py\n",
      " create mode 100644 core_modules/pipeline/pipeline_export.py\n",
      " create mode 100644 core_modules/pipeline/pipeline_rag.py\n",
      " create mode 100644 core_modules/pipeline/pipeline_utils.py\n",
      " delete mode 100644 docker_config/Dockerfile\n",
      " delete mode 100644 docker_config/docker-compose.yml\n",
      " create mode 100644 dwsim_rag_integration/README.md\n",
      " create mode 100644 dwsim_rag_integration/__init__.py\n",
      " create mode 100644 dwsim_rag_integration/config/Dockerfile.dwsim-service\n",
      " create mode 100644 dwsim_rag_integration/config/__init__.py\n",
      " create mode 100644 dwsim_rag_integration/config/docker-compose.yml\n",
      " create mode 100644 dwsim_rag_integration/core/__init__.py\n",
      " create mode 100644 dwsim_rag_integration/core/enhanced_dwsim_bridge.py\n",
      " create mode 100644 dwsim_rag_integration/examples/__init__.py\n",
      " create mode 100644 dwsim_rag_integration/examples/demo.py\n",
      " create mode 100644 dwsim_rag_integration/examples/test_simulation.dwsim\n",
      " create mode 100644 dwsim_rag_integration/requirements.txt\n",
      " create mode 100644 dwsim_rag_integration/service/__init__.py\n",
      " create mode 100644 dwsim_rag_integration/service/dwsim_service_client.py\n",
      " create mode 100644 dwsim_rag_integration/service/enhanced_dwsim_service.py\n",
      " delete mode 100644 dwsim_workflow.py\n",
      " create mode 100644 project_info/DWSIM_CLEANUP_SUMMARY.md\n",
      " create mode 100644 project_info/LOCAL_TESTING_REPORT.md\n",
      " create mode 100644 results/dwsim_simulation_results.csv\n",
      " create mode 100644 results/dwsim_statistics.csv\n",
      " create mode 100644 results/pipeline_summary.csv\n",
      " create mode 100644 results/rag_query_results.csv\n",
      " create mode 100644 results/rag_statistics.csv\n",
      " create mode 100644 scripts/demo_dwsim_docker.py\n",
      " delete mode 100644 vector_db/embeddings.pkl\n",
      " delete mode 100644 vector_db/pynucleus_mcp.faiss/index.faiss\n",
      " delete mode 100644 vector_db/pynucleus_mcp.faiss/index.pkl\n",
      "üíæ Changes committed\n",
      "error: src refspec Main-+-RAG does not match any\n",
      "\u001b[31merror: failed to push some refs to 'https://github.com/Saytor20/PyNucleus-Model.git'\n",
      "\u001b[m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Changes pushed to GitHub branch 'Main-+-RAG' successfully!\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Log end time\n",
    "with open(\"update_log.txt\", \"a\") as f:\n",
    "    f.write(f\"\\n {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} changes made and pushed to origin main\\n\")\n",
    "\n",
    "# Simple GitHub update function\n",
    "def update_github(branch_name=\"main\"):\n",
    "    print(f\"üîÑ Starting GitHub update for branch: {branch_name}...\")\n",
    "    !git add .\n",
    "    print(\"üì¶ Files added to staging\")\n",
    "    !git commit -m \"Update: $(date +'%Y-%m-%d %H:%M:%S')\"\n",
    "    print(\"üíæ Changes committed\")\n",
    "    !git push origin {branch_name}\n",
    "    print(f\"‚úÖ Changes pushed to GitHub branch '{branch_name}' successfully!\")\n",
    "\n",
    "# To use it, just run with your desired branch name:\n",
    "update_github(\"main-rag\")# Or use default main branch:\n",
    "# update_github()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:50:23.979205Z",
     "start_time": "2025-06-04T16:50:22.863275Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1610,
     "status": "ok",
     "timestamp": 1748965317848,
     "user": {
      "displayName": "Mohammad A.",
      "userId": "15199683412159334052"
     },
     "user_tz": 240
    },
    "id": "tjThfmG7EDzG",
    "outputId": "c0e3a16d-87b8-4a04-ec34-d92e7264e169"
   },
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Log end time\n",
    "with open(\"update_log.txt\", \"a\") as f:\n",
    "    f.write(f\"\\n {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} changes made and pushed to origin main\\n\")\n",
    "\n",
    "# Simple GitHub update function\n",
    "def update_github():\n",
    "    !git add .\n",
    "    !git commit -m \"Update: Adding all files to repository\"\n",
    "    !git push origin main\n",
    "    print(\"All files pushed to GitHub successfully!\")\n",
    "\n",
    "# To use it, just run:\n",
    "update_github()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
