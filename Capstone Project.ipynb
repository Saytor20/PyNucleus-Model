{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# **PyNucleus Model - User Interface**\n",
        "\n",
        "## **Welcome to PyNucleus!** ğŸš€\n",
        "\n",
        "This notebook provides a simple interface to run the PyNucleus pipeline for chemical process analysis.\n",
        "\n",
        "### **What PyNucleus Does:**\n",
        "- **ğŸ“š Document Analysis**: Processes chemical engineering documents using RAG (Retrieval-Augmented Generation)\n",
        "- **ğŸ”¬ DWSIM Simulations**: Runs chemical process simulations with predefined scenarios\n",
        "- **ğŸ“Š Results Export**: Automatically exports results to CSV files for analysis\n",
        "- **ğŸ’¡ LLM Integration**: Generates intelligent summaries and reports\n",
        "\n",
        "### **How to Use This Notebook:**\n",
        "1. **Run Cell 1**: Initialize the system\n",
        "2. **Run Cell 2**: Execute the complete pipeline\n",
        "3. **Run Cell 3**: View your results\n",
        "\n",
        "**âš¡ That's it! The system handles everything automatically.**\n",
        "\n",
        "---\n",
        "**ğŸ’¡ For developers**: Advanced features and diagnostics are available in `Developer_Notebook.ipynb`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”§ Initializing PyNucleus Model...\n",
            "ğŸ”§ Setting up RAG imports...\n",
            "Warning: wikipedia package not available. Wikipedia scraping disabled.\n",
            "âœ… RAG imports ready!\n",
            "ğŸ“‚ Loaded 5 existing DWSIM results from disk\n",
            "ğŸ”§ Setting up DWSIM imports...\n",
            "âœ… DWSIM modules imported successfully\n",
            "ğŸ“ Results directory: data/05_output/results\n",
            "ğŸ”§ Pipeline Utils initialized with results dir: data/05_output/results\n",
            "ğŸ”— DWSIM-RAG integration enabled\n",
            "âœ… PyNucleus Model initialized successfully!\n",
            "ğŸ“‹ System Ready:\n",
            "   â€¢ RAG Pipeline - Document processing and retrieval\n",
            "   â€¢ DWSIM Pipeline - Chemical process simulation\n",
            "   â€¢ Results Export - CSV and report generation\n",
            "   â€¢ LLM Integration - Intelligent analysis and summaries\n",
            "\n",
            "ğŸ¯ Ready to run analysis! Execute Cell 2 to start.\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: System Initialization\n",
        "# ===================================\n",
        "# This cell sets up PyNucleus and prepares all components\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"ğŸ”§ Initializing PyNucleus Model...\")\n",
        "\n",
        "# Add src to Python path\n",
        "src_path = str(Path().resolve() / \"src\")\n",
        "if src_path not in sys.path:\n",
        "    sys.path.insert(0, src_path)\n",
        "\n",
        "try:\n",
        "    # Import PyNucleus components\n",
        "    from pynucleus.pipeline import PipelineUtils\n",
        "    from pynucleus.integration.llm_output_generator import LLMOutputGenerator\n",
        "    \n",
        "    # Initialize pipeline\n",
        "    pipeline = PipelineUtils(results_dir=\"data/05_output/results\")\n",
        "    llm_generator = LLMOutputGenerator(results_dir=\"data/05_output/reports\")\n",
        "    \n",
        "    print(\"âœ… PyNucleus Model initialized successfully!\")\n",
        "    print(\"ğŸ“‹ System Ready:\")\n",
        "    print(\"   â€¢ RAG Pipeline - Document processing and retrieval\")\n",
        "    print(\"   â€¢ DWSIM Pipeline - Chemical process simulation\")\n",
        "    print(\"   â€¢ Results Export - CSV and report generation\")\n",
        "    print(\"   â€¢ LLM Integration - Intelligent analysis and summaries\")\n",
        "    print(\"\\nğŸ¯ Ready to run analysis! Execute Cell 2 to start.\")\n",
        "    \n",
        "except ImportError as e:\n",
        "    print(f\"âŒ Import Error: {e}\")\n",
        "    print(\"ğŸ’¡ Please ensure you're in the PyNucleus-Model directory\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Initialization Error: {e}\")\n",
        "    print(\"ğŸ’¡ Please check your system setup\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ Starting Complete PyNucleus Analysis...\n",
            "\n",
            "ğŸ“Š This will run:\n",
            "   1. Document processing and RAG analysis\n",
            "   2. DWSIM chemical process simulations\n",
            "   3. Results export and report generation\n",
            "\n",
            "â³ Please wait... This may take 20-30 seconds.\n",
            "\n",
            "ğŸš€ Running complete PyNucleus pipeline...\n",
            "ğŸ—‘ï¸ RAG results cleared.\n",
            "ğŸ—‘ï¸ RAG results cleared.\n",
            "ğŸ—‘ï¸ DWSIM results cleared from memory and disk.\n",
            "ğŸ—‘ï¸ DWSIM results cleared.\n",
            "ğŸ”¬ Step 1: Running DWSIM simulations...\n",
            "ğŸ”¬ Starting DWSIM Simulations...\n",
            "ğŸ“‹ Running 5 simulation cases...\n",
            "\n",
            "ğŸ§ª Case 1/5: distillation_ethanol_water\n",
            "   âœ… Success - Duration: 0.00s\n",
            "\n",
            "ğŸ§ª Case 2/5: reactor_methane_combustion\n",
            "   âœ… Success - Duration: 0.00s\n",
            "\n",
            "ğŸ§ª Case 3/5: heat_exchanger_steam\n",
            "   âœ… Success - Duration: 0.00s\n",
            "\n",
            "ğŸ§ª Case 4/5: absorber_co2_capture\n",
            "   âœ… Success - Duration: 0.00s\n",
            "\n",
            "ğŸ§ª Case 5/5: crystallizer_salt\n",
            "   âœ… Success - Duration: 0.00s\n",
            "\n",
            "ğŸ“Š Simulation Summary:\n",
            "   â€¢ Successful simulations: 5/5\n",
            "   â€¢ Failed simulations: 0/5\n",
            "ğŸ’¾ Saved 5 DWSIM results to disk\n",
            "ğŸ“Š DWSIM Statistics:\n",
            "   â€¢ Total Simulations: 5\n",
            "   â€¢ Success Rate: 100.0%\n",
            "   â€¢ Average Duration: 0.00s\n",
            "âœ… DWSIM: 5 simulations completed\n",
            "\n",
            "ğŸ“š Step 2: Running RAG pipeline with DWSIM integration...\n",
            "ğŸ“š Starting RAG Pipeline...\n",
            "Step 1: Processing source documents...\n",
            "ğŸ” OCR engines available: tesseract, easyocr\n",
            "--- ğŸ“„ Starting simple text processing for 9 file(s) in 'data/01_raw/source_documents' ---\n",
            "ğŸ’¡ Processing mode: Simple text output (no image files created)\n",
            "2025-06-17 22:26:06 [INFO] pynucleus.rag.document_processor: Starting document processing: 9 files from data/01_raw/source_documents\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing files:   0%|          | 0/9 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " â–¶ Processing: Engineering Economics and Economic Design for Process Engineers.pdf\n",
            "      ğŸ“„ Processing PDF...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-06-17 22:26:36 [INFO] pynucleus.rag.document_processor: Successfully extracted PDF text from Engineering Economics and Economic Design for Process Engineers.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing files:  11%|â–ˆ         | 1/9 [00:30<04:00, 30.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Success! Simple text saved to: data/02_processed/converted_to_txt/Engineering Economics and Economic Design for Process Engineers.txt\n",
            " â–¶ Processing: The Landscape of Modular Chemical Plants in Africa- Opportunities, Challenges, and Strategic Imperatives for Industrialization.txt\n",
            "      ğŸ“„ Processing text/other format...\n",
            "2025-06-17 22:26:36 [WARNING] unstructured: libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
            "2025-06-17 22:26:36 [INFO] pynucleus.rag.document_processor: Successfully processed text file The Landscape of Modular Chemical Plants in Africa- Opportunities, Challenges, and Strategic Imperatives for Industrialization.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing files:  22%|â–ˆâ–ˆâ–       | 2/9 [00:30<01:27, 12.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Success! Simple text saved to: data/02_processed/converted_to_txt/The Landscape of Modular Chemical Plants in Africa- Opportunities, Challenges, and Strategic Imperatives for Industrialization.txt\n",
            " â–¶ Processing: Process Simulation Specifications.pdf\n",
            "      ğŸ“„ Processing PDF...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-06-17 22:27:02 [INFO] pynucleus.rag.document_processor: Successfully extracted PDF text from Process Simulation Specifications.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing files:  33%|â–ˆâ–ˆâ–ˆâ–      | 3/9 [00:56<01:52, 18.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Success! Simple text saved to: data/02_processed/converted_to_txt/Process Simulation Specifications.txt\n",
            " â–¶ Processing: Engineering-Economy.pdf\n",
            "      ğŸ“„ Processing PDF...\n",
            "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
            "\n",
            "âš ï¸ PyMuPDF image text extraction failed: code=4: pixmap must be grayscale or rgb to write as png\n",
            "2025-06-17 22:27:11 [INFO] pynucleus.rag.document_processor: Successfully extracted PDF text from Engineering-Economy.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing files:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [01:04<01:13, 14.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Success! Simple text saved to: data/02_processed/converted_to_txt/Engineering-Economy.txt\n",
            " â–¶ Processing: Modular Chemical Plant Development Guide.pdf\n",
            "      ğŸ“„ Processing PDF...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Python(63133) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Python(63134) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Python(63135) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-06-17 22:27:40 [INFO] pynucleus.rag.document_processor: Successfully extracted PDF text from Modular Chemical Plant Development Guide.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing files:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [01:34<01:20, 20.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Success! Simple text saved to: data/02_processed/converted_to_txt/Modular Chemical Plant Development Guide.txt\n",
            " â–¶ Processing: Modular Chemical Plant Feasibility Parameters.pdf\n",
            "      ğŸ“„ Processing PDF...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Python(63232) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Python(63236) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Python(63242) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-06-17 22:28:06 [INFO] pynucleus.rag.document_processor: Successfully extracted PDF text from Modular Chemical Plant Feasibility Parameters.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing files:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [02:00<01:05, 21.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Success! Simple text saved to: data/02_processed/converted_to_txt/Modular Chemical Plant Feasibility Parameters.txt\n",
            " â–¶ Processing: Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.docx\n",
            "      ğŸ“„ Processing DOCX...\n",
            "2025-06-17 22:28:07 [INFO] pynucleus.rag.document_processor: Successfully processed DOCX file Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.docx\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing files:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [02:00<00:30, 15.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Success! Simple text saved to: data/02_processed/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
            " â–¶ Processing: 20180329160017017.pdf\n",
            "      ğŸ“„ Processing PDF...\n",
            "2025-06-17 22:28:53 [INFO] pynucleus.rag.document_processor: Successfully extracted PDF text from 20180329160017017.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing files:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [02:47<00:24, 24.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Success! Simple text saved to: data/02_processed/converted_to_txt/20180329160017017.txt\n",
            " â–¶ Processing: J.M. Smith, Hendrick Van Ness, Michael Abbott, Mark Swihart - Introduction to Chemical Engineering Thermodynamics-McGraw-Hill Education (2018).pdf\n",
            "      ğŸ“„ Processing PDF...\n",
            "âš ï¸ PyMuPDF image text extraction failed: code=4: pixmap must be grayscale or rgb to write as png\n",
            "2025-06-17 22:29:21 [INFO] pynucleus.rag.document_processor: Successfully extracted PDF text from J.M. Smith, Hendrick Van Ness, Michael Abbott, Mark Swihart - Introduction to Chemical Engineering Thermodynamics-McGraw-Hill Education (2018).pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [03:15<00:00, 21.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Success! Simple text saved to: data/02_processed/converted_to_txt/J.M. Smith, Hendrick Van Ness, Michael Abbott, Mark Swihart - Introduction to Chemical Engineering Thermodynamics-McGraw-Hill Education (2018).txt\n",
            "\n",
            "ğŸ‰ All files processed as simple text.\n",
            "\n",
            "ğŸ“Š Simple Text Processing Summary:\n",
            "   ğŸ“„ All content converted to simple text format\n",
            "   ğŸš« No image files created\n",
            "   ğŸ“Š Tables included as formatted text\n",
            "   ğŸ” OCR text extraction: Enabled\n",
            "\n",
            "Step 2: Scraping Wikipedia articles...\n",
            "ğŸ” Starting Wikipedia article search for 5 keywords...\n",
            "â–¶ï¸  Searching for: modular design\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ…  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_modular_design.txt\n",
            "â–¶ï¸  Searching for: software architecture\n",
            "âœ…  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_software_architecture.txt\n",
            "â–¶ï¸  Searching for: system design\n",
            "âœ…  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_system_design.txt\n",
            "â–¶ï¸  Searching for: industrial design\n",
            "âœ…  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_industrial_design.txt\n",
            "â–¶ï¸  Searching for: supply chain\n",
            "âœ…  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_supply_chain.txt\n",
            "\n",
            "âœ¨ Article scraping complete!\n",
            "\n",
            "Step 3: Processing and chunking documents...\n",
            "ğŸ“° Found 5 Wikipedia articles\n",
            "ğŸ“„ Found 9 converted documents\n",
            "ğŸ“‹ Total documents loaded: 14\n",
            "âœ‚ï¸ Split into 7136 chunks\n",
            "\n",
            "\n",
            "Step 4: Integrating DWSIM simulation data...\n",
            "   ğŸ“Š Using provided DWSIM data: 5 simulations\n",
            "   âœ… Created 5 simulation chunks\n",
            "   ğŸ“Š DWSIM data integrated successfully\n",
            "\n",
            "ğŸ” Enhanced Query Capabilities:\n",
            "   1. What are the performance metrics for the distillation simulation?\n",
            "   2. How do the reactor conversion rates compare across simulations?\n",
            "   3. Which simulation showed the highest efficiency?\n",
            "   ğŸ“Š Combined 7141 total chunks (documents + simulations)\n",
            "   ğŸ”— Simulation chunks properly formatted as Document objects\n",
            "   ğŸ’¾ Saving combined chunk data...\n",
            "   âœ… Chunk data saved successfully\n",
            "\n",
            "Step 5: Building FAISS vector store...\n",
            "=== FAISS VectorDB Analysis ===\n",
            "Started: 2025-06-17 22:29:26\n",
            "   ğŸ”„ Loading documents from saved JSON file...\n",
            "Loaded 7141 documents from /Users/mohammadalmusaiteer/PyNucleus-Model/data/03_intermediate/converted_chunked_data/chunked_data_full.json\n",
            "   âœ… Documents properly loaded: 7141 Document objects\n",
            "ğŸ” Building FAISS index with 7141 documents\n",
            "   First document type: <class 'langchain_core.documents.base.Document'>\n",
            "   Has page_content: âœ…\n",
            "âœ… FAISS index built successfully with langchain\n",
            "Embedding device â†’ cpu   | dim=384\n",
            "Docs indexed : 7141\n",
            "\n",
            "-- Files in chunk_reports/ --\n",
            "  Â· faiss_analysis_20250613_184115.txt\n",
            "  Â· faiss_analysis_20250613_222742.txt\n",
            "  Â· faiss_analysis_20250616_223115.txt\n",
            "  Â· faiss_analysis_20250613_213429.txt\n",
            "  Â· faiss_analysis_20250613_221504.txt\n",
            "  Â· faiss_analysis_20250616_223504.txt\n",
            "  Â· faiss_analysis_20250616_223512.txt\n",
            "  Â· faiss_analysis_20250613_222621.txt\n",
            "  Â· faiss_analysis_20250613_212251.txt\n",
            "  Â· faiss_analysis_20250613_183903.txt\n",
            "  Â· faiss_analysis_20250617_222926.txt\n",
            "  Â· faiss_analysis_20250617_214937.txt\n",
            "  Â· faiss_analysis_20250613_225611.txt\n",
            "  Â· embeddings.pkl\n",
            "  Â· faiss_analysis_20250616_223307.txt\n",
            "  Â· faiss_analysis_20250617_215829.txt\n",
            "  Â· faiss_analysis_20250613_185526.txt\n",
            "  Â· faiss_analysis_20250613_231402.txt\n",
            "  Â· faiss_analysis_20250613_185453.txt\n",
            "  Â· faiss_analysis_20250613_184822.txt\n",
            "  Â· faiss_analysis_20250613_184438.txt\n",
            "  Â· faiss_analysis_20250613_182501.txt\n",
            "  Â· faiss_analysis_20250613_222726.txt\n",
            "  Â· faiss_analysis_20250613_190503.txt\n",
            "  Â· faiss_analysis_20250613_183001.txt\n",
            "  Â· faiss_analysis_20250613_185110.txt\n",
            "  Â· faiss_analysis_20250613_182051.txt\n",
            "  Â· faiss_analysis_20250613_185927.txt\n",
            "  Â· faiss_analysis_20250613_182443.txt\n",
            "  Â· faiss_analysis_20250613_221350.txt\n",
            "  Â· faiss_analysis_20250613_212200.txt\n",
            "  Â· pynucleus_mcp.faiss\n",
            "  Â· faiss_analysis_20250613_222428.txt\n",
            "  Â· faiss_analysis_20250613_225347.txt\n",
            "  Â· faiss_analysis_20250613_190418.txt\n",
            "  Â· faiss_analysis_20250617_215833.txt\n",
            "  Â· faiss_analysis_20250616_223123.txt\n",
            "  Â· faiss_analysis_20250613_182806.txt\n",
            "  Â· performance_metrics.jsonl\n",
            "  Â· faiss_analysis_20250613_222413.txt\n",
            "  Â· faiss_analysis_20250613_190224.txt\n",
            "  Â· faiss_analysis_20250613_222638.txt\n",
            "  Â· faiss_analysis_20250613_184906.txt\n",
            "  Â· faiss_analysis_20250613_222404.txt\n",
            "  Â· faiss_analysis_20250613_213155.txt\n",
            "  Â· faiss_analysis_20250617_214928.txt\n",
            "\n",
            "=== Evaluation (Recall@3) ===\n",
            "Q: what are the benefits of modular design  âœ—   top-score=0.4899   time=0.016s\n",
            "Q: how does modular design work in vehicles âœ—   top-score=0.4153   time=0.007s\n",
            "\n",
            "Recall@3: 0/2  â†’  0.0%\n",
            "Avg Similarity Score: 0.4526\n",
            "Avg Response Time: 0.011s\n",
            "âš ï¸ FAISS build encountered an issue: Object of type float32 is not JSON serializable\n",
            "   ğŸ”§ Continuing with basic document processing...\n",
            "=== FAISS VectorDB Analysis ===\n",
            "Started: 2025-06-17 22:32:01\n",
            "Loaded 7141 documents from /Users/mohammadalmusaiteer/PyNucleus-Model/data/03_intermediate/converted_chunked_data/chunked_data_full.json\n",
            "âœ… RAG Pipeline completed with fallback processing\n",
            "ğŸ” Testing RAG queries...\n",
            "\n",
            "ğŸ“ Query: What are the key challenges in implementing modular chemical plants?\n",
            "   âŒ Query failed: No search index available. Call build() first.\n",
            "\n",
            "ğŸ“ Query: How does supply chain management affect modular design?\n",
            "   âŒ Query failed: No search index available. Call build() first.\n",
            "\n",
            "ğŸ“ Query: What are the economic benefits of modular construction?\n",
            "   âŒ Query failed: No search index available. Call build() first.\n",
            "\n",
            "ğŸ“ Query: How does software architecture relate to modular design?\n",
            "   âŒ Query failed: No search index available. Call build() first.\n",
            "\n",
            "ğŸ“ Query: What are the environmental impacts of modular manufacturing?\n",
            "   âŒ Query failed: No search index available. Call build() first.\n",
            "âœ… Query testing completed! 0 results collected.\n",
            "âœ… RAG: 7141 chunks processed\n",
            "\n",
            "ğŸ’¾ Step 3: Exporting results...\n",
            "\n",
            "ğŸ’¾ Exporting DWSIM simulation results...\n",
            "âœ… DWSIM results exported: data/05_output/results/dwsim_simulation_results.csv\n",
            "   ğŸ“Š 5 simulation results exported\n",
            "   ğŸ“‹ Columns: Case Name, Type, Components, Status, Performance Metrics\n",
            "âœ… DWSIM summary exported: data/05_output/results/dwsim_summary.csv\n",
            "\n",
            "ğŸ‰ Export completed successfully!\n",
            "ğŸ“ All results saved in: data/05_output/results\n",
            "ğŸ“ˆ Files created:\n",
            "   â€¢ dwsim_simulation_results.csv (917 bytes)\n",
            "   â€¢ dwsim_summary.csv (360 bytes)\n",
            "âœ… Export: 2 files created\n",
            "\n",
            "âœ… Complete pipeline finished in 363.7 seconds!\n",
            "ğŸ“Š Components completed: 3/3\n",
            "\n",
            "ğŸ‰ Analysis completed successfully in 363.7 seconds!\n",
            "\n",
            "ğŸ“Š Results Summary:\n",
            "   â€¢ Documents Processed: 0 queries\n",
            "   â€¢ Simulations Completed: 5 scenarios\n",
            "   â€¢ Files Generated: 2 CSV files\n",
            "âœ… Enhanced 5 simulations with RAG insights\n",
            "\n",
            "ğŸ’° Financial Analysis:\n",
            "   â€¢ Recovery Rate: 84.7%\n",
            "   â€¢ Daily Revenue: $152,496.00\n",
            "   â€¢ Daily Profit: $62,496.00\n",
            "   â€¢ ROI: 6.9%\n",
            "\n",
            "ğŸ“„ Generated Reports: 3 detailed analysis files\n",
            "\n",
            "ğŸ“ All results saved to:\n",
            "   â€¢ CSV Files: data/05_output/results/\n",
            "   â€¢ Reports: data/05_output/reports/\n",
            "\n",
            "âœ… Analysis complete! Run Cell 3 to explore your results.\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Run Complete Analysis\n",
        "# ===================================\n",
        "# This cell runs the complete PyNucleus pipeline\n",
        "\n",
        "print(\"ğŸš€ Starting Complete PyNucleus Analysis...\")\n",
        "print(\"\\nğŸ“Š This will run:\")\n",
        "print(\"   1. Document processing and RAG analysis\")\n",
        "print(\"   2. DWSIM chemical process simulations\")\n",
        "print(\"   3. Results export and report generation\")\n",
        "print(\"\\nâ³ Please wait... This may take 20-30 seconds.\\n\")\n",
        "\n",
        "try:\n",
        "    # Run the complete pipeline\n",
        "    results = pipeline.run_complete_pipeline()\n",
        "    \n",
        "    if results:\n",
        "        print(f\"\\nğŸ‰ Analysis completed successfully in {results['duration']:.1f} seconds!\")\n",
        "        print(\"\\nğŸ“Š Results Summary:\")\n",
        "        print(f\"   â€¢ Documents Processed: {len(results['rag_data'])} queries\")\n",
        "        print(f\"   â€¢ Simulations Completed: {len(results['dwsim_data'])} scenarios\")\n",
        "        print(f\"   â€¢ Files Generated: {len(results['exported_files'])} CSV files\")\n",
        "        \n",
        "        # Generate enhanced reports if available\n",
        "        try:\n",
        "            from pynucleus.integration.dwsim_rag_integrator import DWSIMRAGIntegrator\n",
        "            \n",
        "            integrator = DWSIMRAGIntegrator(\n",
        "                rag_pipeline=pipeline.rag_pipeline,\n",
        "                results_dir=\"data/05_output/results\"\n",
        "            )\n",
        "            \n",
        "            # Enhanced analysis\n",
        "            dwsim_results = pipeline.dwsim_pipeline.get_results()\n",
        "            if dwsim_results:\n",
        "                enhanced_results = integrator.integrate_simulation_results(\n",
        "                    dwsim_results, perform_rag_analysis=True\n",
        "                )\n",
        "                \n",
        "                # Generate LLM reports\n",
        "                report_files = []\n",
        "                for result in enhanced_results[:3]:  # Generate reports for first 3 simulations\n",
        "                    report_file = llm_generator.export_llm_ready_text(result)\n",
        "                    report_files.append(report_file)\n",
        "                \n",
        "                # Financial analysis\n",
        "                financial_file = llm_generator.export_financial_analysis(enhanced_results)\n",
        "                metrics = llm_generator._calculate_key_metrics(enhanced_results)\n",
        "                \n",
        "                print(\"\\nğŸ’° Financial Analysis:\")\n",
        "                print(f\"   â€¢ Recovery Rate: {metrics['avg_recovery']:.1f}%\")\n",
        "                print(f\"   â€¢ Daily Revenue: ${metrics['estimated_revenue']:,.2f}\")\n",
        "                print(f\"   â€¢ Daily Profit: ${metrics['net_profit']:,.2f}\")\n",
        "                print(f\"   â€¢ ROI: {metrics['roi']:.1f}%\")\n",
        "                \n",
        "                print(f\"\\nğŸ“„ Generated Reports: {len(report_files)} detailed analysis files\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(\"âš ï¸ Enhanced analysis unavailable (using basic results only)\")\n",
        "        \n",
        "        print(\"\\nğŸ“ All results saved to:\")\n",
        "        print(\"   â€¢ CSV Files: data/05_output/results/\")\n",
        "        print(\"   â€¢ Reports: data/05_output/reports/\")\n",
        "        print(\"\\nâœ… Analysis complete! Run Cell 3 to explore your results.\")\n",
        "        \n",
        "    else:\n",
        "        print(\"âŒ Pipeline execution failed\")\n",
        "        print(\"ğŸ’¡ Please check your data directories and try again\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error during analysis: {e}\")\n",
        "    print(\"ğŸ’¡ Please ensure all components are properly initialized\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Cell 3: Refresh Pipeline (Run this if you encounter errors)\n",
        "# # ===================================\n",
        "# # This cell refreshes the pipeline instance with all latest fixes\n",
        "\n",
        "# print(\"ğŸ”„ Refreshing Pipeline Instance...\")\n",
        "\n",
        "# try:\n",
        "#     # Import the latest version\n",
        "#     from src.pynucleus.pipeline.pipeline_utils import PipelineUtils\n",
        "    \n",
        "#     # Create a fresh pipeline instance with all fixes\n",
        "#     pipeline = PipelineUtils()\n",
        "    \n",
        "#     print(\"âœ… Pipeline refreshed successfully!\")\n",
        "#     print(\"ğŸ“Š Now you can run Cell 3 to view the dashboard\")\n",
        "    \n",
        "#     # Quick test to verify it's working\n",
        "#     status = pipeline.quick_test()\n",
        "#     print(f\"\\nğŸ§ª Quick Test Results:\")\n",
        "#     print(f\"   ğŸ“ Results Directory: {status.get('results_dir', 'Not found')}\")\n",
        "#     print(f\"   ğŸ“„ CSV Files: {status.get('csv_files_count', 0)}\")\n",
        "#     print(f\"   ğŸ”— Integration: {'âœ… Enabled' if status.get('integration_enabled', False) else 'âšª Documents only'}\")\n",
        "#     print(f\"   ğŸ“Š Total Chunks: {status.get('rag_chunks', 0)}\")\n",
        "    \n",
        "# except Exception as e:\n",
        "#     print(f\"âŒ Error refreshing pipeline: {e}\")\n",
        "#     print(\"ğŸ’¡ Try restarting the kernel and running all cells from the beginning\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Š PyNucleus Results Dashboard\n",
            "========================================\n",
            "ğŸ§ª Quick Pipeline Test\n",
            "------------------------------\n",
            "ğŸ“š RAG: 7141 chunks available\n",
            "ğŸ”— Integration: âšª Documents only\n",
            "ğŸ“Š DWSIM Statistics:\n",
            "   â€¢ Total Simulations: 5\n",
            "   â€¢ Success Rate: 100.0%\n",
            "   â€¢ Average Duration: 0.00s\n",
            "ğŸ”¬ DWSIM: 5 simulations\n",
            "ğŸ“ Output: 2 CSV files\n",
            "ğŸ“ Results Directory: data/05_output/results\n",
            "ğŸ“„ CSV Files Found: 2\n",
            "\n",
            "ğŸ“‹ Available Files:\n",
            "   â€¢ dwsim_summary.csv (360 bytes)\n",
            "   â€¢ dwsim_simulation_results.csv (917 bytes)\n",
            "\n",
            "========================================\n",
            "\n",
            "ğŸ“Š Pipeline Results Summary\n",
            "============================================================\n",
            "ğŸ“Š DWSIM Statistics:\n",
            "   â€¢ Total Simulations: 5\n",
            "   â€¢ Success Rate: 100.0%\n",
            "   â€¢ Average Duration: 0.00s\n",
            "ğŸ“š RAG Knowledge Base:\n",
            "   Total Chunks: 7,141\n",
            "   Document Sources: 19\n",
            "   Integration: âšª Documents only\n",
            "   Avg Chunk Size: 787.7 chars\n",
            "\n",
            "ğŸ”¬ DWSIM Simulations:\n",
            "   Total Simulations: 5\n",
            "   Success Rate: 100.0%\n",
            "   Avg Duration: 0.00s\n",
            "\n",
            "ğŸ“ Output Files:\n",
            "   â€¢ dwsim_summary.csv (0.4 KB)\n",
            "   â€¢ dwsim_simulation_results.csv (0.9 KB)\n",
            "============================================================\n",
            "\n",
            "ğŸ”§ Additional Options:\n",
            "   â€¢ Re-run Cell 2 to generate new results\n",
            "   â€¢ Check data/05_output/ folder for all generated files\n",
            "   â€¢ View Developer_Notebook.ipynb for advanced features\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: View Results and Summary\n",
        "# ===================================\n",
        "# This cell displays your results and provides access to files\n",
        "\n",
        "print(\"ğŸ“Š PyNucleus Results Dashboard\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "try:\n",
        "    # Quick status check\n",
        "    status = pipeline.quick_test()\n",
        "    \n",
        "    print(f\"ğŸ“ Results Directory: {status['results_dir']}\")\n",
        "    print(f\"ğŸ“„ CSV Files Found: {status['csv_files_count']}\")\n",
        "    \n",
        "    if status['csv_files_count'] > 0:\n",
        "        print(\"\\nğŸ“‹ Available Files:\")\n",
        "        for file_info in status['csv_files']:\n",
        "            print(f\"   â€¢ {file_info['name']} ({file_info['size']} bytes)\")\n",
        "    \n",
        "    # Display detailed summary\n",
        "    print(\"\\n\" + \"=\" * 40)\n",
        "    pipeline.view_results_summary()\n",
        "    \n",
        "    print(\"\\nğŸ”§ Additional Options:\")\n",
        "    print(\"   â€¢ Re-run Cell 2 to generate new results\")\n",
        "    print(\"   â€¢ Check data/05_output/ folder for all generated files\")\n",
        "    print(\"   â€¢ View Developer_Notebook.ipynb for advanced features\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error viewing results: {e}\")\n",
        "    print(\"ğŸ’¡ Please run Cell 2 first to generate results\")"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "\n",
        "## **Optional: Individual Components**\n",
        "\n",
        "The cells below allow you to run specific parts of the pipeline individually if needed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Optional Cell 4A: Run Only Document Analysis (RAG)\n",
        "# # ====================================================\n",
        "# # Uncomment and run this cell if you only want document processing\n",
        "\n",
        "# print(\"ğŸ“š Running Document Analysis Only...\")\n",
        "# rag_results = pipeline.run_rag_only()\n",
        "# if rag_results:\n",
        "#     print(f\"âœ… Processed {len(rag_results['rag_data'])} document queries\")\n",
        "#     print(\"ğŸ“ Results saved to data/05_output/results/\")\n",
        "# else:\n",
        "#     print(\"âŒ Document analysis failed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Optional Cell 4B: Run Only Chemical Simulations (DWSIM)\n",
        "# # =======================================================\n",
        "# # Uncomment and run this cell if you only want DWSIM simulations\n",
        "\n",
        "# print(\"ğŸ”¬ Running Chemical Simulations Only...\")\n",
        "# dwsim_results = pipeline.run_dwsim_only()\n",
        "# if dwsim_results:\n",
        "#     print(f\"âœ… Completed {len(dwsim_results['dwsim_data'])} simulations\")\n",
        "#     print(\"ğŸ“ Results saved to data/05_output/results/\")\n",
        "# else:\n",
        "#     print(\"âŒ Chemical simulations failed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Optional Cell 5: Clean Up Results\n",
        "# # =================================\n",
        "# # Uncomment and run this cell to clear all previous results\n",
        "\n",
        "# print(\"ğŸ—‘ï¸ Cleaning up previous results...\")\n",
        "# pipeline.clean_all_results()\n",
        "# print(\"âœ… All results cleared. You can now run a fresh analysis.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # ========================================\n",
        "# # VERSION CONTROL (Optional - For Maintainers Only)\n",
        "# # ========================================\n",
        "# # Uncomment the lines below if you need to update the repository:\n",
        "\n",
        "# from datetime import datetime\n",
        "\n",
        "# # Log end time\n",
        "# with open(\"update_log.txt\", \"a\") as f:\n",
        "#     f.write(f\"\\n {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} changes made and pushed to origin main\\n\")\n",
        "\n",
        "# # Simple GitHub update function\n",
        "# def update_github():\n",
        "#     print(\" Starting GitHub update...\")\n",
        "#     !git add .\n",
        "#     print(\" Files added to staging\")\n",
        "#     !git commit -m \"Update: $(date +'%Y-%m-%d %H:%M:%S')\"\n",
        "#     print(\" Changes committed\")\n",
        "#     !git push origin main\n",
        "#     print(\" Changes pushed to GitHub successfully!\")\n",
        "\n",
        "# # To use it, just run:\n",
        "# update_github()"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "\n",
        "## **Need More Features?**\n",
        "\n",
        "ğŸ”§ **For Developers**: Advanced features, debugging, and system diagnostics are available in:\n",
        "- `Developer_Notebook.ipynb` - Full development environment\n",
        "- `scripts/comprehensive_system_diagnostic.py` - System health checks\n",
        "\n",
        "ğŸ“š **Documentation**: Check the `docs/` folder for detailed guides:\n",
        "- `README.md` - Complete setup and usage guide\n",
        "- `docs/ENHANCED_PIPELINE_SUMMARY.md` - Advanced features overview\n",
        "- `docs/project_info/` - Technical documentation\n",
        "\n",
        "ğŸ’¡ **Support**: For issues or questions, check the project documentation or create an issue in the repository.\n",
        "\n",
        "---\n",
        "\n",
        "**ğŸ‰ Thank you for using PyNucleus!**\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
