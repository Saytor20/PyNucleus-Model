{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# **PyNucleus Model - User Interface**\n",
        "\n",
        "## **Welcome to PyNucleus!** 🚀\n",
        "\n",
        "This notebook provides a simple interface to run the PyNucleus pipeline for chemical process analysis.\n",
        "\n",
        "### **What PyNucleus Does:**\n",
        "- **📚 Document Analysis**: Processes chemical engineering documents using RAG (Retrieval-Augmented Generation)\n",
        "- **🔬 DWSIM Simulations**: Runs chemical process simulations with predefined scenarios\n",
        "- **📊 Results Export**: Automatically exports results to CSV files for analysis\n",
        "- **💡 LLM Integration**: Generates intelligent summaries and reports\n",
        "\n",
        "### **How to Use This Notebook:**\n",
        "1. **Run Cell 1**: Initialize the system\n",
        "2. **Run Cell 2**: Execute the complete pipeline\n",
        "3. **Run Cell 3**: View your results\n",
        "\n",
        "**⚡ That's it! The system handles everything automatically.**\n",
        "\n",
        "---\n",
        "**💡 For developers**: Advanced features and diagnostics are available in `Developer_Notebook.ipynb`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔧 Initializing PyNucleus Model...\n",
            "🔧 Setting up RAG imports...\n",
            "Warning: wikipedia package not available. Wikipedia scraping disabled.\n",
            "✅ RAG imports ready!\n",
            "🔧 Setting up DWSIM imports...\n",
            "✅ DWSIM modules imported successfully\n",
            "📁 Results directory: data/05_output/results\n",
            "🔧 Pipeline Utils initialized with results dir: data/05_output/results\n",
            "🔗 DWSIM-RAG integration enabled\n",
            "✅ PyNucleus Model initialized successfully!\n",
            "📋 System Ready:\n",
            "   • RAG Pipeline - Document processing and retrieval\n",
            "   • DWSIM Pipeline - Chemical process simulation\n",
            "   • Results Export - CSV and report generation\n",
            "   • LLM Integration - Intelligent analysis and summaries\n",
            "\n",
            "🎯 Ready to run analysis! Execute Cell 2 to start.\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: System Initialization\n",
        "# ===================================\n",
        "# This cell sets up PyNucleus and prepares all components\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"🔧 Initializing PyNucleus Model...\")\n",
        "\n",
        "# Add src to Python path\n",
        "src_path = str(Path().resolve() / \"src\")\n",
        "if src_path not in sys.path:\n",
        "    sys.path.insert(0, src_path)\n",
        "\n",
        "try:\n",
        "    # Import PyNucleus components\n",
        "    from pynucleus.pipeline import PipelineUtils\n",
        "    from pynucleus.integration.llm_output_generator import LLMOutputGenerator\n",
        "    \n",
        "    # Initialize pipeline\n",
        "    pipeline = PipelineUtils(results_dir=\"data/05_output/results\")\n",
        "    llm_generator = LLMOutputGenerator(results_dir=\"data/05_output/reports\")\n",
        "    \n",
        "    print(\"✅ PyNucleus Model initialized successfully!\")\n",
        "    print(\"📋 System Ready:\")\n",
        "    print(\"   • RAG Pipeline - Document processing and retrieval\")\n",
        "    print(\"   • DWSIM Pipeline - Chemical process simulation\")\n",
        "    print(\"   • Results Export - CSV and report generation\")\n",
        "    print(\"   • LLM Integration - Intelligent analysis and summaries\")\n",
        "    print(\"\\n🎯 Ready to run analysis! Execute Cell 2 to start.\")\n",
        "    \n",
        "except ImportError as e:\n",
        "    print(f\"❌ Import Error: {e}\")\n",
        "    print(\"💡 Please ensure you're in the PyNucleus-Model directory\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Initialization Error: {e}\")\n",
        "    print(\"💡 Please check your system setup\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pynucleus.integration.dwsim_data_integrator:DWSIMDataIntegrator initialized with output: data/05_output\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 Starting Complete PyNucleus Analysis...\n",
            "\n",
            "📊 This will run:\n",
            "   1. Document processing and RAG analysis\n",
            "   2. DWSIM chemical process simulations\n",
            "   3. Results export and report generation\n",
            "\n",
            "⏳ Please wait... This may take 20-30 seconds.\n",
            "\n",
            "🚀 Running complete PyNucleus pipeline...\n",
            "🗑️ RAG results cleared.\n",
            "🗑️ DWSIM results cleared.\n",
            "🔬 Step 1: Running DWSIM simulations...\n",
            "🔬 Starting DWSIM Simulations...\n",
            "📋 Running 5 simulation cases...\n",
            "\n",
            "🧪 Case 1/5: distillation_ethanol_water\n",
            "   ✅ Success - Duration: 0.00s\n",
            "\n",
            "🧪 Case 2/5: reactor_methane_combustion\n",
            "   ✅ Success - Duration: 0.00s\n",
            "\n",
            "🧪 Case 3/5: heat_exchanger_steam\n",
            "   ✅ Success - Duration: 0.00s\n",
            "\n",
            "🧪 Case 4/5: absorber_co2_capture\n",
            "   ✅ Success - Duration: 0.00s\n",
            "\n",
            "🧪 Case 5/5: crystallizer_salt\n",
            "   ✅ Success - Duration: 0.00s\n",
            "\n",
            "📊 Simulation Summary:\n",
            "   • Successful simulations: 5/5\n",
            "   • Failed simulations: 0/5\n",
            "📊 DWSIM Statistics:\n",
            "   • Total Simulations: 5\n",
            "   • Success Rate: 100.0%\n",
            "   • Average Duration: 0.00s\n",
            "\n",
            "📚 Step 2: Running RAG pipeline with DWSIM integration...\n",
            "📚 Starting RAG Pipeline...\n",
            "Step 1: Processing source documents...\n",
            "📂 Creating directory: 'data/01_raw/source_docs'\n",
            "ℹ Please place your files (PDF, DOCX, TXT, etc.) in the 'data/01_raw/source_docs' directory and run the script again.\n",
            "\n",
            "Step 2: Scraping Wikipedia articles...\n",
            "🔍 Starting Wikipedia article search for 5 keywords...\n",
            "▶️  Searching for: modular design\n",
            "❌  Error processing modular design: name 'quote' is not defined\n",
            "▶️  Searching for: software architecture\n",
            "❌  Error processing software architecture: name 'quote' is not defined\n",
            "▶️  Searching for: system design\n",
            "❌  Error processing system design: name 'quote' is not defined\n",
            "▶️  Searching for: industrial design\n",
            "❌  Error processing industrial design: name 'quote' is not defined\n",
            "▶️  Searching for: supply chain\n",
            "❌  Error processing supply chain: name 'quote' is not defined\n",
            "\n",
            "✨ Article scraping complete!\n",
            "\n",
            "Step 3: Processing and chunking documents...\n",
            "📰 Found 0 Wikipedia articles\n",
            "📄 Found 0 converted documents\n",
            "⚠️ No documents found to process\n",
            "⚠️ No chunks to save\n",
            "\n",
            "Step 4: Integrating DWSIM simulation data...\n",
            "   ⚠️ No DWSIM simulation results found - skipping integration\n",
            "\n",
            "Step 5: Building FAISS vector store...\n",
            "=== FAISS VectorDB Analysis ===\n",
            "Started: 2025-06-13 18:04:09\n",
            "❌ Pipeline error: name 'HuggingFaceEmbeddings' is not defined\n",
            "❌ Pipeline execution failed\n",
            "💡 Please check your data directories and try again\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Run Complete Analysis\n",
        "# ===================================\n",
        "# This cell runs the complete PyNucleus pipeline\n",
        "\n",
        "print(\"🚀 Starting Complete PyNucleus Analysis...\")\n",
        "print(\"\\n📊 This will run:\")\n",
        "print(\"   1. Document processing and RAG analysis\")\n",
        "print(\"   2. DWSIM chemical process simulations\")\n",
        "print(\"   3. Results export and report generation\")\n",
        "print(\"\\n⏳ Please wait... This may take 20-30 seconds.\\n\")\n",
        "\n",
        "try:\n",
        "    # Run the complete pipeline\n",
        "    results = pipeline.run_complete_pipeline()\n",
        "    \n",
        "    if results:\n",
        "        print(f\"\\n🎉 Analysis completed successfully in {results['duration']:.1f} seconds!\")\n",
        "        print(\"\\n📊 Results Summary:\")\n",
        "        print(f\"   • Documents Processed: {len(results['rag_data'])} queries\")\n",
        "        print(f\"   • Simulations Completed: {len(results['dwsim_data'])} scenarios\")\n",
        "        print(f\"   • Files Generated: {len(results['exported_files'])} CSV files\")\n",
        "        \n",
        "        # Generate enhanced reports if available\n",
        "        try:\n",
        "            from pynucleus.integration.dwsim_rag_integrator import DWSIMRAGIntegrator\n",
        "            \n",
        "            integrator = DWSIMRAGIntegrator(\n",
        "                rag_pipeline=pipeline.rag_pipeline,\n",
        "                results_dir=\"data/05_output/results\"\n",
        "            )\n",
        "            \n",
        "            # Enhanced analysis\n",
        "            dwsim_results = pipeline.dwsim_pipeline.get_results()\n",
        "            if dwsim_results:\n",
        "                enhanced_results = integrator.integrate_simulation_results(\n",
        "                    dwsim_results, perform_rag_analysis=True\n",
        "                )\n",
        "                \n",
        "                # Generate LLM reports\n",
        "                report_files = []\n",
        "                for result in enhanced_results[:3]:  # Generate reports for first 3 simulations\n",
        "                    report_file = llm_generator.export_llm_ready_text(result)\n",
        "                    report_files.append(report_file)\n",
        "                \n",
        "                # Financial analysis\n",
        "                financial_file = llm_generator.export_financial_analysis(enhanced_results)\n",
        "                metrics = llm_generator._calculate_key_metrics(enhanced_results)\n",
        "                \n",
        "                print(\"\\n💰 Financial Analysis:\")\n",
        "                print(f\"   • Recovery Rate: {metrics['avg_recovery']:.1f}%\")\n",
        "                print(f\"   • Daily Revenue: ${metrics['estimated_revenue']:,.2f}\")\n",
        "                print(f\"   • Daily Profit: ${metrics['net_profit']:,.2f}\")\n",
        "                print(f\"   • ROI: {metrics['roi']:.1f}%\")\n",
        "                \n",
        "                print(f\"\\n📄 Generated Reports: {len(report_files)} detailed analysis files\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(\"⚠️ Enhanced analysis unavailable (using basic results only)\")\n",
        "        \n",
        "        print(\"\\n📁 All results saved to:\")\n",
        "        print(\"   • CSV Files: data/05_output/results/\")\n",
        "        print(\"   • Reports: data/05_output/reports/\")\n",
        "        print(\"\\n✅ Analysis complete! Run Cell 3 to explore your results.\")\n",
        "        \n",
        "    else:\n",
        "        print(\"❌ Pipeline execution failed\")\n",
        "        print(\"💡 Please check your data directories and try again\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"❌ Error during analysis: {e}\")\n",
        "    print(\"💡 Please ensure all components are properly initialized\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 PyNucleus Results Dashboard\n",
            "========================================\n",
            "🧪 Quick Pipeline Test\n",
            "------------------------------\n",
            "📚 RAG: 0 chunks available\n",
            "🔗 Integration: ⚪ Documents only\n",
            "📊 DWSIM Statistics:\n",
            "   • Total Simulations: 5\n",
            "   • Success Rate: 100.0%\n",
            "   • Average Duration: 0.00s\n",
            "🔬 DWSIM: 5 simulations\n",
            "📁 Output: 0 CSV files\n",
            "❌ Error viewing results: 'results_dir'\n",
            "💡 Please run Cell 2 first to generate results\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: View Results and Summary\n",
        "# ===================================\n",
        "# This cell displays your results and provides access to files\n",
        "\n",
        "print(\"📊 PyNucleus Results Dashboard\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "try:\n",
        "    # Quick status check\n",
        "    status = pipeline.quick_test()\n",
        "    \n",
        "    print(f\"📁 Results Directory: {status['results_dir']}\")\n",
        "    print(f\"📄 CSV Files Found: {status['csv_files_count']}\")\n",
        "    \n",
        "    if status['csv_files_count'] > 0:\n",
        "        print(\"\\n📋 Available Files:\")\n",
        "        for file_info in status['csv_files']:\n",
        "            print(f\"   • {file_info['name']} ({file_info['size']} bytes)\")\n",
        "    \n",
        "    # Display detailed summary\n",
        "    print(\"\\n\" + \"=\" * 40)\n",
        "    pipeline.view_results_summary()\n",
        "    \n",
        "    print(\"\\n🔧 Additional Options:\")\n",
        "    print(\"   • Re-run Cell 2 to generate new results\")\n",
        "    print(\"   • Check data/05_output/ folder for all generated files\")\n",
        "    print(\"   • View Developer_Notebook.ipynb for advanced features\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"❌ Error viewing results: {e}\")\n",
        "    print(\"💡 Please run Cell 2 first to generate results\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "\n",
        "## **Optional: Individual Components**\n",
        "\n",
        "The cells below allow you to run specific parts of the pipeline individually if needed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional Cell 4A: Run Only Document Analysis (RAG)\n",
        "# ====================================================\n",
        "# Uncomment and run this cell if you only want document processing\n",
        "\n",
        "# print(\"📚 Running Document Analysis Only...\")\n",
        "# rag_results = pipeline.run_rag_only()\n",
        "# if rag_results:\n",
        "#     print(f\"✅ Processed {len(rag_results['rag_data'])} document queries\")\n",
        "#     print(\"📁 Results saved to data/05_output/results/\")\n",
        "# else:\n",
        "#     print(\"❌ Document analysis failed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional Cell 4B: Run Only Chemical Simulations (DWSIM)\n",
        "# =======================================================\n",
        "# Uncomment and run this cell if you only want DWSIM simulations\n",
        "\n",
        "# print(\"🔬 Running Chemical Simulations Only...\")\n",
        "# dwsim_results = pipeline.run_dwsim_only()\n",
        "# if dwsim_results:\n",
        "#     print(f\"✅ Completed {len(dwsim_results['dwsim_data'])} simulations\")\n",
        "#     print(\"📁 Results saved to data/05_output/results/\")\n",
        "# else:\n",
        "#     print(\"❌ Chemical simulations failed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional Cell 5: Clean Up Results\n",
        "# =================================\n",
        "# Uncomment and run this cell to clear all previous results\n",
        "\n",
        "# print(\"🗑️ Cleaning up previous results...\")\n",
        "# pipeline.clean_all_results()\n",
        "# print(\"✅ All results cleared. You can now run a fresh analysis.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Starting GitHub update...\n",
            " Files added to staging\n",
            "[main 859c91e] Update: 2025-06-13 18:04:10\n",
            " 6 files changed, 131 insertions(+), 240 deletions(-)\n",
            " delete mode 100644 configs/bulk_modular_plants_template.csv\n",
            " delete mode 100644 configs/bulk_modular_plants_template.json\n",
            " delete mode 100644 configs/simulation_config_template.csv\n",
            " delete mode 100644 configs/simulation_config_template.json\n",
            " Changes committed\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 8 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 2.58 KiB | 2.58 MiB/s, done.\n",
            "Total 4 (delta 3), reused 0 (delta 0), pack-reused 0 (from 0)\n",
            "remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n",
            "To https://github.com/Saytor20/PyNucleus-Model.git\n",
            "   8b35bae..859c91e  main -> main\n",
            " Changes pushed to GitHub successfully!\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# VERSION CONTROL (Optional - For Maintainers Only)\n",
        "# ========================================\n",
        "# Uncomment the lines below if you need to update the repository:\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "# Log end time\n",
        "with open(\"update_log.txt\", \"a\") as f:\n",
        "    f.write(f\"\\n {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} changes made and pushed to origin main\\n\")\n",
        "\n",
        "# Simple GitHub update function\n",
        "def update_github():\n",
        "    print(\" Starting GitHub update...\")\n",
        "    !git add .\n",
        "    print(\" Files added to staging\")\n",
        "    !git commit -m \"Update: $(date +'%Y-%m-%d %H:%M:%S')\"\n",
        "    print(\" Changes committed\")\n",
        "    !git push origin main\n",
        "    print(\" Changes pushed to GitHub successfully!\")\n",
        "\n",
        "# To use it, just run:\n",
        "update_github()"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "\n",
        "## **Need More Features?**\n",
        "\n",
        "🔧 **For Developers**: Advanced features, debugging, and system diagnostics are available in:\n",
        "- `Developer_Notebook.ipynb` - Full development environment\n",
        "- `scripts/comprehensive_system_diagnostic.py` - System health checks\n",
        "\n",
        "📚 **Documentation**: Check the `docs/` folder for detailed guides:\n",
        "- `README.md` - Complete setup and usage guide\n",
        "- `docs/ENHANCED_PIPELINE_SUMMARY.md` - Advanced features overview\n",
        "- `docs/project_info/` - Technical documentation\n",
        "\n",
        "💡 **Support**: For issues or questions, check the project documentation or create an issue in the repository.\n",
        "\n",
        "---\n",
        "\n",
        "**🎉 Thank you for using PyNucleus!**\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
