{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1u5UGmr8qymPfSqLP8CchGfulbkXhQ22y","timestamp":1748897747281}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"pxJK6GpyVui7","colab":{"base_uri":"https://localhost:8080/","height":341},"outputId":"be2af41e-0a03-4c74-c1d4-adcc52bad232","executionInfo":{"status":"error","timestamp":1748899717977,"user_tz":240,"elapsed":1677,"user":{"displayName":"Mohammad A.","userId":"15199683412159334052"}}},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d4e4da7eabff>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mnotebook_drive_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/PyNucleus Project/Capstone Project V2.ipynb\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnotebook_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Capstone Project V2.ipynb\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m     case = d.expect([\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pexpect/spawnbase.py\u001b[0m in \u001b[0;36mexpect\u001b[0;34m(self, pattern, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mcompiled_pattern_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_pattern_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m         return self.expect_list(compiled_pattern_list,\n\u001b[0m\u001b[1;32m    355\u001b[0m                 timeout, searchwindowsize, async_)\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pexpect/spawnbase.py\u001b[0m in \u001b[0;36mexpect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mexpect_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     def expect_exact(self, pattern_list, timeout=-1, searchwindowsize=-1,\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pexpect/expect.py\u001b[0m in \u001b[0;36mexpect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mincoming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_nonblocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayafterread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayafterread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincoming\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;31m# Keep reading until exception or return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Commented out IPython magic to ensure Python compatibility.\n","from google.colab import drive,userdata\n","import os\n","\n","drive.mount('/content/drive', force_remount=True)\n","notebook_drive_path = \"/content/drive/MyDrive/PyNucleus Project/Capstone Project V2.ipynb\"\n","notebook_filename = \"Capstone Project V2.ipynb\"\n","\n","# GitHub details\n","GITHUB_USERNAME = userdata.get('GITHUB_USERNAME')\n","GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n","REPOSITORY_NAME = 'PyNucleus-Model'\n","REPO_PATH = f\"/content/{REPOSITORY_NAME}\" # The path where the repo will be cloned\n","\n","# --- STEP 2: CLONE REPOSITORY (ONLY IF IT DOESN'T EXIST) ---\n","if not os.path.exists(REPO_PATH):\n","    print(f\"Cloning {REPOSITORY_NAME} repository...\")\n","    repository_url = f\"https://{GITHUB_TOKEN}@github.com/{GITHUB_USERNAME}/{REPOSITORY_NAME}.git\"\n","    !git clone {repository_url} {REPO_PATH}\n","else:\n","    print(\"Repository already exists. Skipping clone.\")\n","\n","# --- STEP 3: NAVIGATE INTO REPOSITORY & COPY YOUR NOTEBOOK ---\n","\n","# The '%cd' command changes the current directory in Colab\n","%cd {REPO_PATH}\n","\n","# --- CONFIGURE GIT USER HERE ---\n","print(\"Configuring Git user...\")\n","!git config user.name \"{GITHUB_USERNAME}\"\n","!git config user.email \"{GITHUB_USERNAME}@users.noreply.github.com\"\n","\n","# print(\"Setup complete. You are ready to work.\")"]},{"cell_type":"code","source":["# --- Installation Cell (Run this ONCE per session) ---\n","print(\"Installing all required packages...\")\n","\n","# Core LangChain and Community Packages\n","!pip install -q langchain langchain-core langchain-community langchain-text-splitters\n","\n","# Document Loading & Processing (Unstructured handles many file types including OCR)\n","!pip install -q \"unstructured[local-inference]\"\n","\n","# LLM & ML Libraries\n","!pip install -q transformers accelerate bitsandbytes torch sentence-transformers\n","\n","# Vector Stores\n","!pip install -q chromadb faiss-cpu # faiss-gpu if you have a Pro Colab with a good GPU\n","\n","# Data Handling & Utilities\n","!pip install -q pandas numpy tqdm PyYAML\n","\n","print(\"All packages installed successfully.\")"],"metadata":{"id":"DfNy6HlnOsXc","executionInfo":{"status":"aborted","timestamp":1748899717983,"user_tz":240,"elapsed":1,"user":{"displayName":"Mohammad A.","userId":"15199683412159334052"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- Core Utilities & File Handling ---\n","import getpass\n","import yaml # Make sure PyYAML is installed\n","from pathlib import Path\n","\n","# --- Data Handling & Progress Bars ---\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","\n","# --- Document Loading ---\n","# UnstructuredFileLoader is now in langchain_community\n","from langchain_community.document_loaders import UnstructuredFileLoader\n","# For future testing of more specific loaders:\n","# from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader\n","\n","# --- OCR Libraries ---\n","# No direct imports needed here if using UnstructuredFileLoader with local-inference,\n","# as it handles OCR internally.\n","# You would only import these for a manual OCR process:\n","# import pytesseract\n","# from pdf2image import convert_from_path\n","# from PIL import Image\n","\n","# --- Core ML & LLM Libraries ---\n","import torch\n","import transformers\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","import bitsandbytes\n","import accelerate # Often used with transformers\n","\n","# --- Vector Stores & Embeddings ---\n","# Using ChromaDB as the primary vector store.\n","import chromadb\n","from langchain_community.vectorstores import Chroma # Chroma is now in langchain_community\n","from langchain_community.embeddings import HuggingFaceEmbeddings # Embeddings are also in langchain_community\n","# For future testing of a high-performance alternative:\n","# import faiss\n","# from langchain_community.vectorstores import FAISS\n","\n","# --- RAG/Agent Frameworks ---\n","# Core LangChain components\n","import langchain\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.output_parsers import StrOutputParser\n","# For future testing of an alternative RAG-focused toolkit:\n","# from llama_index.core import SimpleDirectoryReader, VectorStoreIndex"],"metadata":{"id":"BPyfUDJoDjgn","executionInfo":{"status":"aborted","timestamp":1748899717984,"user_tz":240,"elapsed":1751,"user":{"displayName":"Mohammad A.","userId":"15199683412159334052"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Data Ingestion and Preprocessing for RAG**"],"metadata":{"id":"OL-SmhSQQ_21"}},{"cell_type":"code","source":[],"metadata":{"id":"I69992m0RE82","executionInfo":{"status":"aborted","timestamp":1748899717985,"user_tz":240,"elapsed":1750,"user":{"displayName":"Mohammad A.","userId":"15199683412159334052"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# This is the last cell of the code"],"metadata":{"id":"hISFF6TUEB_H"}},{"cell_type":"code","source":["# # --- STEP 3: Add, Commit, and Push Your Changes ---\n","\n","# # For this example, let's create a new file to commit\n","# with open(\"update_log.txt\", \"a\") as f:\n","#     from datetime import datetime\n","#     f.write(f\"Notebook run on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n","\n","# print(\"Staging changes...\")\n","# # Add all modified and new files to the staging area\n","# !git add .\n","\n","# print(\"Committing changes...\")\n","# # Commit the staged changes with a descriptive message\n","# !git commit -m \"added new libraries and Set up Python Env\"\n","\n","# print(\"Pushing changes to GitHub...\")\n","# # Push your committed changes to the 'main' or 'master' branch on GitHub\n","# !git push\n","\n","# print(\"GitHub sync complete!\")\n","\n","print(\"Copying your notebook into the repository...\")\n","!cp \"{notebook_drive_path}\" \"{notebook_filename_in_repo}\"\n","\n","# Add the notebook file to Git\n","!git add \"{notebook_filename_in_repo}\"\n","\n","# Commit the changes with a message\n","!git commit -m \"Update project notebook with new analysis\"\n","\n","# Push the changes to GitHub\n","!git push origin main\n","\n","print(\"SUCCESS! Your notebook has been updated on GitHub.\")"],"metadata":{"id":"tjThfmG7EDzG","executionInfo":{"status":"aborted","timestamp":1748899717986,"user_tz":240,"elapsed":1750,"user":{"displayName":"Mohammad A.","userId":"15199683412159334052"}}},"execution_count":null,"outputs":[]}]}