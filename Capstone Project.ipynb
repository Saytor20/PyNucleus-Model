{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from datetime import datetime\n",
    "# from dotenv import load_dotenv\n",
    "# #\n",
    "# # #--------Google Drive Integration--------#\n",
    "# # # from google.colab import drive, userdata\n",
    "# # # This gives Colab access to your files in Google Drive.\n",
    "# # # drive.mount('/content/drive')\n",
    "# # # 'GITHUB_USERNAME' and 'GITHUB_TOKEN' saved as secrets in Colab.\n",
    "# # GITHUB_USERNAME = userdata.get('GITHUB_USERNAME')\n",
    "# # GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n",
    "# # REPOSITORY_NAME = 'PyNucleus-Model' # Your repository name\n",
    "# # NOTEBOOK_DRIVE_PATH = \"/content/drive/MyDrive/PyNucleus Project/Capstone Project.ipynb\"\n",
    "# #\n",
    "# #\n",
    "# # #--------Cursor Integration--------#\n",
    "# # # Load environment variables from .env file\n",
    "# load_dotenv()\n",
    "# #\n",
    "# # # Get GitHub credentials from environment variables\n",
    "# GITHUB_USERNAME = os.getenv('GITHUB_USERNAME')\n",
    "# GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')\n",
    "# #\n",
    "# # # Print to verify the variables are loaded (remove this in production)\n",
    "# print(f\"Username: {GITHUB_USERNAME}\")\n",
    "# print(f\"Token: {GITHUB_TOKEN[:4]}...\") # Only print first 4 chars of token for security\n",
    "# #\n",
    "# # Repository information\n",
    "# REPOSITORY_NAME = 'PyNucleus-Model'\n",
    "# NOTEBOOK_REPO_FILENAME = \"Capstone Project.ipynb\"\n",
    "# LOG_FILENAME = \"update_log.txt\"\n",
    "\n",
    "# # Pull latest changes from GitHub\n",
    "# print(\"Pulling latest changes from GitHub...\")\n",
    "# !git pull https://{GITHUB_TOKEN}@github.com/{GITHUB_USERNAME}/{REPOSITORY_NAME}.git main\n",
    "\n",
    "# print(\"Repository is up to date!\")\n",
    "\n",
    "# # Log start time\n",
    "# with open(\"update_log.txt\", \"a\") as f:\n",
    "#     f.write(f\" {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}: Log Update\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21621,
     "status": "ok",
     "timestamp": 1748965189264,
     "user": {
      "displayName": "Mohammad A.",
      "userId": "15199683412159334052"
     },
     "user_tz": 240
    },
    "id": "pxJK6GpyVui7",
    "outputId": "5fcaf74f-4292-4847-fb37-57d1c0d9a971"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PyNucleus Model - Pipeline Ready!\n",
      " Available Components:\n",
      "   ‚Ä¢ RAGPipeline - Document processing and retrieval\n",
      "   ‚Ä¢ DWSIMPipeline - Chemical process simulation\n",
      "   ‚Ä¢ ResultsExporter - CSV export functionality\n",
      "   ‚Ä¢ PipelineUtils - Complete pipeline orchestration\n"
     ]
    }
   ],
   "source": [
    "# PyNucleus Model - Setup and Imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to Python path\n",
    "src_path = str(Path().resolve() / \"src\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "# Import PyNucleus Pipeline modules\n",
    "from pynucleus.pipeline import RAGPipeline, DWSIMPipeline, ResultsExporter, PipelineUtils\n",
    "from pynucleus.integration.config_manager import ConfigManager\n",
    "from pynucleus.integration.dwsim_rag_integrator import DWSIMRAGIntegrator\n",
    "from pynucleus.integration.llm_output_generator import LLMOutputGenerator\n",
    "\n",
    "\n",
    "print(\" PyNucleus Model - Pipeline Ready!\")\n",
    "print(\" Available Components:\")\n",
    "print(\"   ‚Ä¢ RAGPipeline - Document processing and retrieval\")\n",
    "print(\"   ‚Ä¢ DWSIMPipeline - Chemical process simulation\") \n",
    "print(\"   ‚Ä¢ ResultsExporter - CSV export functionality\")\n",
    "print(\"   ‚Ä¢ PipelineUtils - Complete pipeline orchestration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84DXL9QuH0Tx"
   },
   "source": [
    "# **PyNucleus Model - Complete Pipeline**\n",
    "\n",
    "This notebook contains the complete PyNucleus model pipeline with separate sections for:\n",
    "1. **Data Ingestion and Preprocessing for RAG** \n",
    "2. **DWSIM Integration and Simulation**\n",
    "3. **Results Export to CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Setting up RAG imports...\n",
      "‚úÖ RAG imports ready!\n",
      "üîß Setting up DWSIM imports...\n",
      "‚úÖ DWSIM modules imported successfully\n",
      "üìÅ Results directory: data/05_output/results\n",
      "üîß Pipeline Utils initialized with results dir: data/05_output/results\n",
      "\n",
      "üîß Pipeline Initialized!\n",
      "Available Functions:\n",
      "   ‚Ä¢ pipeline.run_complete_pipeline() - Run everything\n",
      "   ‚Ä¢ pipeline.run_rag_only() - RAG pipeline only\n",
      "   ‚Ä¢ pipeline.run_dwsim_only() - DWSIM simulations only\n",
      "   ‚Ä¢ pipeline.quick_test() - Verify status\n",
      "   ‚Ä¢ pipeline.view_results_summary() - View results\n",
      "   ‚Ä¢ pipeline.print_pipeline_status() - Detailed status\n",
      "   ‚Ä¢ pipeline.clean_all_results() - Clean all data\n"
     ]
    }
   ],
   "source": [
    "# Initialize Pipeline Components\n",
    "pipeline = PipelineUtils(results_dir=\"data/05_output/results\")\n",
    "\n",
    "print(\"\\nüîß Pipeline Initialized!\")\n",
    "print(\"Available Functions:\")\n",
    "print(\"   ‚Ä¢ pipeline.run_complete_pipeline() - Run everything\")\n",
    "print(\"   ‚Ä¢ pipeline.run_rag_only() - RAG pipeline only\")  \n",
    "print(\"   ‚Ä¢ pipeline.run_dwsim_only() - DWSIM simulations only\")\n",
    "print(\"   ‚Ä¢ pipeline.quick_test() - Verify status\")\n",
    "print(\"   ‚Ä¢ pipeline.view_results_summary() - View results\")\n",
    "print(\"   ‚Ä¢ pipeline.print_pipeline_status() - Detailed status\")\n",
    "print(\"   ‚Ä¢ pipeline.clean_all_results() - Clean all data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Running complete PyNucleus pipeline...\n",
      "üóëÔ∏è RAG results cleared.\n",
      "üóëÔ∏è DWSIM results cleared.\n",
      "üìö Starting RAG Pipeline...\n",
      "Step 1: Processing source documents...\n",
      "--- üìÑ Starting processing for 5 file(s) in '/Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/source_documents' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   0%|          | 0/5 [00:00<?, ?it/s]WARNING:unstructured:libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "WARNING:unstructured:libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ‚ñ∂ Processing: Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.docx\n",
      "   ‚Ä¢ Success! Saved to: /Users/mohammadalmusaiteer/PyNucleus-Model/data/02_processed/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      " ‚ñ∂ Processing: mcp_basics.txt\n",
      "   ‚Ä¢ Success! Saved to: /Users/mohammadalmusaiteer/PyNucleus-Model/data/02_processed/converted_to_txt/mcp_basics.txt\n",
      " ‚ñ∂ Processing: feasibility_factors.txt\n",
      "   ‚Ä¢ Success! Saved to: /Users/mohammadalmusaiteer/PyNucleus-Model/data/02_processed/converted_to_txt/feasibility_factors.txt\n",
      " ‚ñ∂ Processing: Bist_Madan.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00,  9.48it/s]WARNING:unstructured:libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "Processing files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 11.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚Ä¢ Success! Saved to: /Users/mohammadalmusaiteer/PyNucleus-Model/data/02_processed/converted_to_txt/Bist_Madan.txt\n",
      " ‚ñ∂ Processing: sample_document.txt\n",
      "   ‚Ä¢ Success! Saved to: /Users/mohammadalmusaiteer/PyNucleus-Model/data/02_processed/converted_to_txt/sample_document.txt\n",
      "\n",
      " All files processed.\n",
      "\n",
      "Step 2: Scraping Wikipedia articles...\n",
      "üîç Starting Wikipedia article search for 5 keywords...\n",
      "‚ñ∂Ô∏è  Searching for: modular design\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_modular_design.txt\n",
      "‚ñ∂Ô∏è  Searching for: software architecture\n",
      "‚úÖ  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_software_architecture.txt\n",
      "‚ñ∂Ô∏è  Searching for: system design\n",
      "‚úÖ  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_system_design.txt\n",
      "‚ñ∂Ô∏è  Searching for: industrial design\n",
      "‚úÖ  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_industrial_design.txt\n",
      "‚ñ∂Ô∏è  Searching for: supply chain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_supply_chain.txt\n",
      "\n",
      "‚ú® Article scraping complete!\n",
      "\n",
      "Step 3: Processing and chunking documents...\n",
      "üì∞ Found 5 Wikipedia articles\n",
      "üìÑ Found 5 converted documents\n",
      "üìã Total documents loaded: 10\n",
      "‚úÇÔ∏è Split into 846 chunks\n",
      "\n",
      "‚úÖ Successfully saved chunked data to /Users/mohammadalmusaiteer/PyNucleus-Model/data/03_intermediate/converted_chunked_data/:\n",
      "  ‚Ä¢ chunked_data_full.json - Complete data with metadata\n",
      "  ‚Ä¢ chunked_data_stats.json - Statistical analysis\n",
      "  ‚Ä¢ chunked_data_content.txt - Human-readable content\n",
      "\n",
      "\n",
      "Step 4: Building FAISS vector store...\n",
      "=== FAISS VectorDB Analysis ===\n",
      "Started: 2025-06-10 23:11:51\n",
      "Loaded 846 documents from /Users/mohammadalmusaiteer/PyNucleus-Model/data/03_intermediate/converted_chunked_data/chunked_data_full.json\n",
      "Embedding device ‚Üí cpu   | dim=384\n",
      "Docs indexed : 846\n",
      "Index file   : /Users/mohammadalmusaiteer/PyNucleus-Model/data/04_models/chunk_reports/pynucleus_mcp.faiss\n",
      "Embeds .pkl  : /Users/mohammadalmusaiteer/PyNucleus-Model/data/04_models/chunk_reports/embeddings.pkl\n",
      "\n",
      "-- Files in chunk_reports/ --\n",
      "  ¬∑ faiss_analysis_20250610_230957.txt\n",
      "  ¬∑ faiss_analysis_20250610_231057.txt\n",
      "  ¬∑ faiss_analysis_20250610_230005.txt\n",
      "  ¬∑ embeddings.pkl\n",
      "  ¬∑ faiss_analysis_20250610_223220.txt\n",
      "  ¬∑ faiss_analysis_20250610_231151.txt\n",
      "  ¬∑ faiss_analysis_20250610_230055.txt\n",
      "  ¬∑ faiss_analysis_20250610_222122.txt\n",
      "  ¬∑ faiss_analysis_20250610_225513.txt\n",
      "  ¬∑ faiss_analysis_20250610_224231.txt\n",
      "  ¬∑ faiss_analysis_20250610_221927.txt\n",
      "  ¬∑ pynucleus_mcp.faiss\n",
      "  ¬∑ faiss_analysis_20250610_230814.txt\n",
      "  ¬∑ faiss_analysis_20250610_225004.txt\n",
      "  ¬∑ faiss_analysis_20250610_222838.txt\n",
      "\n",
      "=== Evaluation (Recall@3) ===\n",
      "Q: what are the benefits of modular design  ‚úì   top-score=0.4110\n",
      "Q: how does modular design work in vehicles ‚úì   top-score=0.3477\n",
      "\n",
      "Recall@3: 2/2  ‚Üí  100.0%\n",
      "‚úÖ RAG Pipeline completed! FAISS log ‚Üí /Users/mohammadalmusaiteer/PyNucleus-Model/data/04_models/chunk_reports/faiss_analysis_20250610_231151.txt\n",
      "üîç Testing RAG queries...\n",
      "\n",
      "üìù Query: What are the key challenges in implementing modular chemical plants?\n",
      "   1. Score: 0.5875 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/data/02_processed/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      "   2. Score: 0.6000 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/data/02_processed/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      "   3. Score: 0.6108 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/data/02_processed/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      "\n",
      "üìù Query: How does supply chain management affect modular design?\n",
      "   1. Score: 0.7411 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_modular_design.txt\n",
      "   2. Score: 0.7464 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_supply_chain.txt\n",
      "   3. Score: 0.8460 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_modular_design.txt\n",
      "\n",
      "üìù Query: What are the economic benefits of modular construction?\n",
      "   1. Score: 0.5366 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_modular_design.txt\n",
      "   2. Score: 0.6558 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_modular_design.txt\n",
      "   3. Score: 0.6602 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_modular_design.txt\n",
      "\n",
      "üìù Query: How does software architecture relate to modular design?\n",
      "   1. Score: 0.4339 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_modular_design.txt\n",
      "   2. Score: 0.6026 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_software_architecture.txt\n",
      "   3. Score: 0.6121 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_modular_design.txt\n",
      "\n",
      "üìù Query: What are the environmental impacts of modular manufacturing?\n",
      "   1. Score: 0.7035 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/data/02_processed/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      "   2. Score: 0.7424 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/data/02_processed/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      "   3. Score: 0.7768 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/data/02_processed/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      "‚úÖ Query testing completed! 15 results collected.\n",
      "üìä RAG Statistics:\n",
      "   ‚Ä¢ Total Chunks: 846\n",
      "   ‚Ä¢ Average Chunk Size: 375.2 characters\n",
      "   ‚Ä¢ Number of Sources: 10\n",
      "üî¨ Starting DWSIM Simulations...\n",
      "üìã Running 5 simulation cases...\n",
      "\n",
      "üß™ Case 1/5: distillation_ethanol_water\n",
      "   ‚úÖ Success - Duration: 0.00s\n",
      "\n",
      "üß™ Case 2/5: reactor_methane_combustion\n",
      "   ‚úÖ Success - Duration: 0.00s\n",
      "\n",
      "üß™ Case 3/5: heat_exchanger_steam\n",
      "   ‚úÖ Success - Duration: 0.00s\n",
      "\n",
      "üß™ Case 4/5: absorber_co2_capture\n",
      "   ‚úÖ Success - Duration: 0.00s\n",
      "\n",
      "üß™ Case 5/5: crystallizer_salt\n",
      "   ‚úÖ Success - Duration: 0.00s\n",
      "\n",
      "üìä Simulation Summary:\n",
      "   ‚Ä¢ Successful simulations: 5/5\n",
      "   ‚Ä¢ Failed simulations: 0/5\n",
      "üìä DWSIM Statistics:\n",
      "   ‚Ä¢ Total Simulations: 5\n",
      "   ‚Ä¢ Success Rate: 100.0%\n",
      "   ‚Ä¢ Average Duration: 0.00s\n",
      "\n",
      "üíæ Exporting DWSIM simulation results...\n",
      "‚úÖ DWSIM results exported: data/05_output/results/dwsim_simulation_results.csv\n",
      "   üìä 5 simulation results exported\n",
      "   üìã Columns: Case Name, Type, Components, Status, Performance Metrics\n",
      "‚úÖ DWSIM summary exported: data/05_output/results/dwsim_summary.csv\n",
      "\n",
      "üéâ Export completed successfully!\n",
      "üìÅ All results saved in: data/05_output/results\n",
      "üìà Files created:\n",
      "   ‚Ä¢ dwsim_simulation_results.csv (913 bytes)\n",
      "   ‚Ä¢ dwsim_summary.csv (360 bytes)\n",
      "‚úÖ Complete pipeline finished in 11.0 seconds!\n",
      "\n",
      "üéâ Pipeline completed in 11.0 seconds!\n",
      "üìä RAG Results: 15 queries processed\n",
      "üî¨ DWSIM Results: 5 simulations completed\n",
      "üìÅ Exported Files: 2 CSV files created\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# SECTION 1: COMPLETE PIPELINE - Run Everything (Basic Mode)\n",
    "\"\"\"This section is the basic pipeline which covers \n",
    "- Runs standard RAG + DWSIM + CSV Export\n",
    "- Output: Basic CSV files with simulation results\n",
    "- For: Regular users who need standard functionality \"\"\"\n",
    "# ========================================\n",
    "\n",
    "# Run the complete pipeline (RAG + DWSIM + Export)\n",
    "results = pipeline.run_complete_pipeline()\n",
    "\n",
    "# Display results summary\n",
    "if results:\n",
    "    print(f\"\\nüéâ Pipeline completed in {results['duration']:.1f} seconds!\")\n",
    "    print(f\"üìä RAG Results: {len(results['rag_data'])} queries processed\")\n",
    "    print(f\"üî¨ DWSIM Results: {len(results['dwsim_data'])} simulations completed\")\n",
    "    print(f\"üìÅ Exported Files: {len(results['exported_files'])} CSV files created\")\n",
    "else:\n",
    "    print(\"‚ùå Pipeline execution failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ========================================\n",
    "# # OPTIONAL: INDIVIDUAL PIPELINE COMPONENTS\n",
    "# # ========================================\n",
    "\n",
    "# # Option 1: Run only RAG Pipeline\n",
    "# print(\"üìö RAG Only Pipeline:\")\n",
    "# rag_results = pipeline.run_rag_only()\n",
    "# if rag_results:\n",
    "#     print(f\"   ‚úÖ {len(rag_results['rag_data'])} RAG queries processed\")\n",
    "\n",
    "# print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# # Option 2: Run only DWSIM Simulations  \n",
    "# print(\"üî¨ DWSIM Only Pipeline:\")\n",
    "# dwsim_results = pipeline.run_dwsim_only()\n",
    "# if dwsim_results:\n",
    "#     print(f\"   ‚úÖ {len(dwsim_results['dwsim_data'])} DWSIM simulations completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ========================================\n",
    "# # OPTIONAL: View Results & Status (After Running Pipelines)\n",
    "# # ========================================\n",
    "\n",
    "# # View pipeline status\n",
    "# pipeline.print_pipeline_status()\n",
    "\n",
    "# print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# # View results summary\n",
    "# pipeline.view_results_summary()\n",
    "\n",
    "# print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# # Quick test\n",
    "# test_results = pipeline.quick_test()\n",
    "# print(f\"‚úÖ Quick test completed! Found {test_results['csv_files_count']} CSV files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# OPTIONAL: CLEANUP AND RESET (Optional)\n",
    "# ========================================\n",
    "# Uncomment the lines below if you need to clean up results:\n",
    "\n",
    "# Clean up and reset (optional - removes all previous results)\n",
    "# pipeline.clean_all_results()\n",
    "\n",
    "# print(\"‚úÖ PyNucleus Pipeline is ready!\")\n",
    "# print(\"üìã Usage Guide:\")\n",
    "# print(\"   ‚Ä¢ Section 1: Run complete pipeline (RAG + DWSIM + Export)\")\n",
    "# print(\"   ‚Ä¢ Section 2: Individual components (commented out)\")\n",
    "# print(\"   ‚Ä¢ Section 3: Utility functions (status, summary, test)\")\n",
    "# print(\"   ‚Ä¢ Enhanced Pipeline: Advanced configuration, integration, LLM output\")\n",
    "# print(\"   ‚Ä¢ Enhanced Features: Configuration, Integration, LLM Output\")\n",
    "# print(\"\\nüîÑ Run any cell multiple times to re-execute components\")\n",
    "# print(\"üìÅ All results automatically saved as CSV files in data/05_output/results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# OPTION A: Run Individual Components (Alternative to Section 1)\n",
    "# ========================================\n",
    "# Uncomment ONLY the lines you want to run:\n",
    "\n",
    "# Option A1: Complete pipeline (same as Section 1)\n",
    "# results = pipeline.run_complete_pipeline()\n",
    "\n",
    "# Option A2: Individual components only\n",
    "# rag_results = pipeline.run_rag_only()        # RAG documents only\n",
    "# dwsim_results = pipeline.run_dwsim_only()    # DWSIM simulations only"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# **ENHANCED PIPELINE - Advanced Features**\n",
    "\n",
    "This section contains enhanced capabilities for advanced users:\n",
    "\n",
    "1. **Enhanced Pipeline Initialization** (Cell 10) - Initialize advanced components FIRST\n",
    "2. **Configurable DWSIM Simulations** (Cell 11) - JSON/CSV configuration files\n",
    "3. **DWSIM-RAG Integration** (Cell 12) - Enhanced analysis with knowledge insights  \n",
    "4. **LLM-Ready Outputs** (Cell 13) - Text summaries with enhanced feed conditions\n",
    "5. **Production Analytics** (Cell 14) - Recovery rates, ROI, and profit analysis\n",
    "\n",
    "**‚ö†Ô∏è CRITICAL: Execute cells in this exact order for enhanced features to work:**\n",
    "**1. Cell 10 (Enhanced Pipeline Initialization) FIRST**\n",
    "**2. Cell 11 (Configuration Templates)**  \n",
    "**3. Cell 12 (DWSIM-RAG Integration)**\n",
    "**4. Cell 13 (LLM-Ready Output with Enhanced Feed Conditions)**\n",
    "**5. Cell 14 (Custom Simulations)**\n",
    "\n",
    "Results are automatically exported to data/05_output/ subdirectories:\n",
    "‚Ä¢ Regular results: data/05_output/results/\n",
    "‚Ä¢ LLM reports: data/05_output/llm_reports/\n",
    "‚Ä¢ Configuration templates: configs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Initializing Enhanced Pipeline Components...\n",
      "‚úÖ Enhanced Pipeline Ready: Configuration, Integration, LLM Output\n",
      "‚úÖ LLM reports will be saved to: data/05_output/llm_reports/\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# ENHANCED PIPELINE - Initialize Advanced Features\n",
    "\"\"\"PREREQUISITE: Run Section 1 (Complete Pipeline) first!\n",
    "This section adds advanced capabilities ON TOP OF the basic pipeline:\n",
    "‚Ä¢ Financial analysis with ROI calculations\n",
    "‚Ä¢ LLM-ready reports and summaries  \n",
    "‚Ä¢ DWSIM-RAG integration with enhanced analytics\n",
    "‚Ä¢ Custom configuration templates\"\"\"\n",
    "# ========================================\n",
    "\n",
    "print(\"üîß Initializing Enhanced Pipeline Components...\")\n",
    "\n",
    "try:\n",
    "    # Force reload modules to get latest version (fixes notebook caching)\n",
    "    import importlib\n",
    "    \n",
    "    # Clear any cached modules\n",
    "    modules_to_reload = [\n",
    "        'pynucleus.integration.config_manager',\n",
    "        'pynucleus.integration.dwsim_rag_integrator', \n",
    "        'pynucleus.integration.llm_output_generator'\n",
    "    ]\n",
    "    \n",
    "    for module_name in modules_to_reload:\n",
    "        if module_name in sys.modules:\n",
    "            importlib.reload(sys.modules[module_name])\n",
    "    \n",
    "    config_manager = ConfigManager(config_dir=\"configs\")\n",
    "    dwsim_rag_integrator = DWSIMRAGIntegrator(\n",
    "    rag_pipeline=pipeline.rag_pipeline if hasattr(pipeline, 'rag_pipeline') else None,\n",
    "    results_dir=\"data/05_output/results\"\n",
    "    )\n",
    "    llm_generator = LLMOutputGenerator(results_dir=\"data/05_output/llm_reports\")\n",
    "\n",
    "    print(\"‚úÖ Enhanced Pipeline Ready: Configuration, Integration, LLM Output\")\n",
    "    print(f\"‚úÖ LLM reports will be saved to: {llm_generator.results_dir}/\")\n",
    "    enhanced_available = True\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Enhanced features not available: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    enhanced_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pydantic template created: configs/simulation_config_template.json\n",
      "‚úÖ Template created: configs/simulation_config_template.csv\n",
      "‚úÖ Configuration templates created:\n",
      "   JSON: configs/simulation_config_template.json\n",
      "   CSV: configs/simulation_config_template.csv\n"
     ]
    }
   ],
   "source": [
    "# ENHANCED PIPELINE STEP 2: Configuration Templates\n",
    "if 'enhanced_available' in locals() and enhanced_available:\n",
    "    json_template = config_manager.create_template_json(\"simulation_config_template.json\", verbose=True)\n",
    "    csv_template = config_manager.create_template_csv(\"simulation_config_template.csv\", verbose=True)\n",
    "    \n",
    "    print(\"‚úÖ Configuration templates created:\")\n",
    "    print(f\"   JSON: {json_template}\")\n",
    "    print(f\"   CSV: {csv_template}\")\n",
    "else:\n",
    "    print(\"‚ùå Enhanced configuration not available\")\n",
    "    print(\"‚ö†Ô∏è Run Cell 10 (Enhanced Pipeline Initialization) first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Enhanced 5 simulations with RAG insights\n",
      "‚úÖ Enhanced Analysis Complete:\n",
      "   Simulations: 5\n",
      "   Performance: Good\n",
      "   Efficiency: High\n",
      "   Results: data/05_output/results/integrated_dwsim_rag_results_20250610_231158.json\n"
     ]
    }
   ],
   "source": [
    "# ENHANCED PIPELINE STEP 3: DWSIM-RAG Integration with Enhanced Analytics\n",
    "if 'enhanced_available' in locals() and enhanced_available:\n",
    "    dwsim_results = pipeline.dwsim_pipeline.get_results()\n",
    "    \n",
    "    if dwsim_results:\n",
    "        # Perform integration\n",
    "        integrated_results = dwsim_rag_integrator.integrate_simulation_results(\n",
    "            dwsim_results, perform_rag_analysis=True\n",
    "        )\n",
    "        \n",
    "        # Export results\n",
    "        integrated_export_file = dwsim_rag_integrator.export_integrated_results()\n",
    "        \n",
    "        # Show key metrics only\n",
    "        if integrated_results:\n",
    "            sample = integrated_results[0]\n",
    "            print(f\"‚úÖ Enhanced Analysis Complete:\")\n",
    "            print(f\"   Simulations: {len(integrated_results)}\")\n",
    "            print(f\"   Performance: {sample['performance_metrics']['overall_performance']}\")\n",
    "            print(f\"   Efficiency: {sample['performance_metrics']['efficiency_rating']}\")\n",
    "            print(f\"   Results: {integrated_export_file}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No DWSIM results available\")\n",
    "else:\n",
    "    print(\"‚ùå Enhanced integration not available\")\n",
    "    print(\"‚ö†Ô∏è Run Cell 10 (Enhanced Pipeline Initialization) first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Running enhanced LLM output generation with detailed feed conditions...\n",
      "‚úÖ Analysis Reports Generated:\n",
      "   LLM Summaries: 5 files created\n",
      "     ‚Ä¢ data/05_output/llm_reports/distillation_ethanol_water_summary.md\n",
      "     ‚Ä¢ data/05_output/llm_reports/reactor_methane_combustion_summary.md\n",
      "     ‚Ä¢ data/05_output/llm_reports/heat_exchanger_steam_summary.md\n",
      "     ‚Ä¢ data/05_output/llm_reports/absorber_co2_capture_summary.md\n",
      "     ‚Ä¢ data/05_output/llm_reports/crystallizer_salt_summary.md\n",
      "   Financial Analysis: data/05_output/llm_reports/financial_analysis_20250610_231158.csv\n",
      "\n",
      "üí∞ Key Financial Metrics:\n",
      "   Recovery Rate: 82.5%\n",
      "   Daily Revenue: $148,500.00\n",
      "   Daily Profit: $58,500.00\n",
      "   ROI: 6.5%\n"
     ]
    }
   ],
   "source": [
    "# ENHANCED PIPELINE STEP 4: LLM-Ready Output with Enhanced Feed Conditions\n",
    "if 'enhanced_available' in locals() and enhanced_available and 'integrated_results' in locals():\n",
    "    print(\"üîÑ Running enhanced LLM output generation with detailed feed conditions...\")\n",
    "    # Generate LLM summary for each simulation using Jinja2 template\n",
    "    llm_ready_files = []\n",
    "    for i, result in enumerate(integrated_results):\n",
    "        # Template uses original_simulation.case_name, no need to add simulation_name\n",
    "        llm_file = llm_generator.export_llm_ready_text(result)\n",
    "        llm_ready_files.append(llm_file)\n",
    "    \n",
    "    # Export financial analysis and show metrics\n",
    "    financial_file = llm_generator.export_financial_analysis(integrated_results)\n",
    "    metrics = llm_generator._calculate_key_metrics(integrated_results)\n",
    "    \n",
    "    print(f\"‚úÖ Analysis Reports Generated:\")\n",
    "    print(f\"   LLM Summaries: {len(llm_ready_files)} files created\")\n",
    "    for llm_file in llm_ready_files:\n",
    "        print(f\"     ‚Ä¢ {llm_file}\")\n",
    "    print(f\"   Financial Analysis: {financial_file}\")\n",
    "    print(f\"\\nüí∞ Key Financial Metrics:\")\n",
    "    print(f\"   Recovery Rate: {metrics['avg_recovery']:.1f}%\")\n",
    "    print(f\"   Daily Revenue: ${metrics['estimated_revenue']:,.2f}\")\n",
    "    print(f\"   Daily Profit: ${metrics['net_profit']:,.2f}\")\n",
    "    print(f\"   ROI: {metrics['roi']:.1f}%\")\n",
    "    \n",
    "elif 'enhanced_available' in locals() and enhanced_available:\n",
    "    print(\"‚ùå Run Cell 12 (DWSIM-RAG Integration) first to generate integrated_results\")\n",
    "else:\n",
    "    print(\"‚ùå Enhanced LLM output not available\")\n",
    "    print(\"‚ö†Ô∏è Run Cell 10 (Enhanced Pipeline Initialization) first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Custom Configuration Demo:\n",
      "   Configuration: configs/custom_simulations_demo.json\n",
      "   Simulations: 1\n",
      "   Status: Ready for processing\n"
     ]
    }
   ],
   "source": [
    "#  PIPELINE STEP 5: Custom Simulations (Advanced Configuration)  \n",
    "if 'enhanced_available' in locals() and enhanced_available:\n",
    "    # Create and save custom configuration\n",
    "    custom_simulations = [\n",
    "        {\n",
    "            \"name\": \"optimized_ethanol_plant\",\n",
    "            \"type\": \"distillation\",\n",
    "            \"components\": [\"water\", \"ethanol\"],\n",
    "            \"description\": \"Optimized ethanol plant with enhanced parameters\",\n",
    "            \"parameters\": {\"temperature\": 82.0, \"pressure\": 101325, \"flow_rate\": 1500, \"reflux_ratio\": 3.0},\n",
    "            \"expected_outputs\": {\"conversion\": 0.97, \"selectivity\": 0.99, \"yield\": 0.96}\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Save and load configuration to configs/ directory\n",
    "    import json\n",
    "    from pathlib import Path\n",
    "    config_file = Path(\"configs/custom_simulations_demo.json\")\n",
    "    config_file.parent.mkdir(exist_ok=True)\n",
    "    \n",
    "    with open(config_file, 'w') as f:\n",
    "        json.dump({\"simulations\": custom_simulations}, f, indent=2)\n",
    "    \n",
    "    print(f\"‚úÖ Custom Configuration Demo:\")\n",
    "    print(f\"   Configuration: {config_file}\")\n",
    "    print(f\"   Simulations: {len(custom_simulations)}\")\n",
    "    print(f\"   Status: Ready for processing\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Enhanced configuration not available\")\n",
    "    print(\"‚ö†Ô∏è Run Cell 10 (Enhanced Pipeline Initialization) first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ========================================\n",
    "# # VERSION CONTROL (Optional - For Maintainers Only)\n",
    "# # ========================================\n",
    "# # Uncomment the lines below if you need to update the repository:\n",
    "\n",
    "# from datetime import datetime\n",
    "\n",
    "# # Log end time\n",
    "# with open(\"update_log.txt\", \"a\") as f:\n",
    "#     f.write(f\"\\n {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} changes made and pushed to origin main\\n\")\n",
    "\n",
    "# # Simple GitHub update function\n",
    "# def update_github():\n",
    "#     print(\" Starting GitHub update...\")\n",
    "#     !git add .\n",
    "#     print(\"üì¶ Files added to staging\")\n",
    "#     !git commit -m \"Update: $(date +'%Y-%m-%d %H:%M:%S')\"\n",
    "#     print(\"üíæ Changes committed\")\n",
    "#     !git push origin main\n",
    "#     print(\"‚úÖ Changes pushed to GitHub successfully!\")\n",
    "\n",
    "# # To use it, just run:\n",
    "# update_github()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
