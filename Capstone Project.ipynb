{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# **PyNucleus Model - User Interface**\n",
        "\n",
        "## **Welcome to PyNucleus!** 🚀\n",
        "\n",
        "This notebook provides a simple interface to run the PyNucleus pipeline for chemical process analysis.\n",
        "\n",
        "### **What PyNucleus Does:**\n",
        "- **📚 Document Analysis**: Processes chemical engineering documents using RAG (Retrieval-Augmented Generation)\n",
        "- **🔬 DWSIM Simulations**: Runs chemical process simulations with predefined scenarios\n",
        "- **📊 Results Export**: Automatically exports results to CSV files for analysis\n",
        "- **💡 LLM Integration**: Generates intelligent summaries and reports\n",
        "\n",
        "### **How to Use This Notebook:**\n",
        "1. **Run Cell 1**: Initialize the system\n",
        "2. **Run Cell 2**: Execute the complete pipeline\n",
        "3. **Run Cell 3**: View your results\n",
        "\n",
        "**⚡ That's it! The system handles everything automatically.**\n",
        "\n",
        "---\n",
        "**💡 For developers**: Advanced features and diagnostics are available in `Developer_Notebook.ipynb`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔧 Initializing PyNucleus Model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔧 Setting up RAG imports...\n",
            "Warning: wikipedia package not available. Wikipedia scraping disabled.\n",
            "✅ RAG imports ready!\n",
            "📂 Loaded 5 existing DWSIM results from disk\n",
            "🔧 Setting up DWSIM imports...\n",
            "✅ DWSIM modules imported successfully\n",
            "📁 Results directory: data/05_output/results\n",
            "🔧 Pipeline Utils initialized with results dir: data/05_output/results\n",
            "🔗 DWSIM-RAG integration enabled\n",
            "✅ PyNucleus Model initialized successfully!\n",
            "📋 System Ready:\n",
            "   • RAG Pipeline - Document processing and retrieval\n",
            "   • DWSIM Pipeline - Chemical process simulation\n",
            "   • Results Export - CSV and report generation\n",
            "   • LLM Integration - Intelligent analysis and summaries\n",
            "\n",
            "🎯 Ready to run analysis! Execute Cell 2 to start.\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: System Initialization\n",
        "# ===================================\n",
        "# This cell sets up PyNucleus and prepares all components\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"🔧 Initializing PyNucleus Model...\")\n",
        "\n",
        "# Add src to Python path\n",
        "src_path = str(Path().resolve() / \"src\")\n",
        "if src_path not in sys.path:\n",
        "    sys.path.insert(0, src_path)\n",
        "\n",
        "try:\n",
        "    # Import PyNucleus components\n",
        "    from pynucleus.pipeline import PipelineUtils\n",
        "    from pynucleus.integration.llm_output_generator import LLMOutputGenerator\n",
        "    \n",
        "    # Initialize pipeline\n",
        "    pipeline = PipelineUtils(results_dir=\"data/05_output/results\")\n",
        "    llm_generator = LLMOutputGenerator(results_dir=\"data/05_output/reports\")\n",
        "    \n",
        "    print(\"✅ PyNucleus Model initialized successfully!\")\n",
        "    print(\"📋 System Ready:\")\n",
        "    print(\"   • RAG Pipeline - Document processing and retrieval\")\n",
        "    print(\"   • DWSIM Pipeline - Chemical process simulation\")\n",
        "    print(\"   • Results Export - CSV and report generation\")\n",
        "    print(\"   • LLM Integration - Intelligent analysis and summaries\")\n",
        "    print(\"\\n🎯 Ready to run analysis! Execute Cell 2 to start.\")\n",
        "    \n",
        "except ImportError as e:\n",
        "    print(f\"❌ Import Error: {e}\")\n",
        "    print(\"💡 Please ensure you're in the PyNucleus-Model directory\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Initialization Error: {e}\")\n",
        "    print(\"💡 Please check your system setup\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 Starting Complete PyNucleus Analysis...\n",
            "\n",
            "📊 This will run:\n",
            "   1. Document processing and RAG analysis\n",
            "   2. DWSIM chemical process simulations\n",
            "   3. Results export and report generation\n",
            "\n",
            "⏳ Please wait... This may take 20-30 seconds.\n",
            "\n",
            "🚀 Running complete PyNucleus pipeline...\n",
            "🗑️ RAG results cleared.\n",
            "🗑️ RAG results cleared.\n",
            "🗑️ DWSIM results cleared from memory and disk.\n",
            "🗑️ DWSIM results cleared.\n",
            "🔬 Step 1: Running DWSIM simulations...\n",
            "🔬 Starting DWSIM Simulations...\n",
            "📋 Running 5 simulation cases...\n",
            "\n",
            "🧪 Case 1/5: distillation_ethanol_water\n",
            "   ✅ Success - Duration: 0.00s\n",
            "\n",
            "🧪 Case 2/5: reactor_methane_combustion\n",
            "   ✅ Success - Duration: 0.00s\n",
            "\n",
            "🧪 Case 3/5: heat_exchanger_steam\n",
            "   ✅ Success - Duration: 0.00s\n",
            "\n",
            "🧪 Case 4/5: absorber_co2_capture\n",
            "   ✅ Success - Duration: 0.00s\n",
            "\n",
            "🧪 Case 5/5: crystallizer_salt\n",
            "   ✅ Success - Duration: 0.00s\n",
            "\n",
            "📊 Simulation Summary:\n",
            "   • Successful simulations: 5/5\n",
            "   • Failed simulations: 0/5\n",
            "💾 Saved 5 DWSIM results to disk\n",
            "📊 DWSIM Statistics:\n",
            "   • Total Simulations: 5\n",
            "   • Success Rate: 100.0%\n",
            "   • Average Duration: 0.00s\n",
            "✅ DWSIM: 5 simulations completed\n",
            "\n",
            "📚 Step 2: Running RAG pipeline with DWSIM integration...\n",
            "📚 Starting RAG Pipeline...\n",
            "Step 1: Processing source documents...\n",
            "--- 📄 Starting processing for 4 file(s) in 'data/01_raw/source_documents' ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing files:   0%|          | 0/4 [00:00<?, ?it/s]WARNING:unstructured:libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ▶ Processing: Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.docx\n",
            "   • Success! Saved to: data/02_processed/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
            " ▶ Processing: mcp_basics.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing files:  50%|█████     | 2/4 [00:00<00:00,  3.58it/s]WARNING:unstructured:libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   • Success! Saved to: data/02_processed/converted_to_txt/mcp_basics.txt\n",
            " ▶ Processing: feasibility_factors.txt\n",
            "   • Success! Saved to: data/02_processed/converted_to_txt/feasibility_factors.txt\n",
            " ▶ Processing: Bist_Madan.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing files: 100%|██████████| 4/4 [00:01<00:00,  3.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   • Success! Saved to: data/02_processed/converted_to_txt/Bist_Madan.txt\n",
            "\n",
            " All files processed.\n",
            "\n",
            "Step 2: Scraping Wikipedia articles...\n",
            "🔍 Starting Wikipedia article search for 5 keywords...\n",
            "▶️  Searching for: modular design\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_modular_design.txt\n",
            "▶️  Searching for: software architecture\n",
            "✅  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_software_architecture.txt\n",
            "▶️  Searching for: system design\n",
            "✅  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_system_design.txt\n",
            "▶️  Searching for: industrial design\n",
            "✅  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_industrial_design.txt\n",
            "▶️  Searching for: supply chain\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pynucleus.integration.dwsim_data_integrator:DWSIMDataIntegrator initialized with output: data/05_output\n",
            "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/data/01_raw/web_sources/wikipedia_supply_chain.txt\n",
            "\n",
            "✨ Article scraping complete!\n",
            "\n",
            "Step 3: Processing and chunking documents...\n",
            "📰 Found 5 Wikipedia articles\n",
            "📄 Found 4 converted documents\n",
            "📋 Total documents loaded: 9\n",
            "✂️ Split into 440 chunks\n",
            "\n",
            "\n",
            "Step 4: Integrating DWSIM simulation data...\n",
            "   📊 Using provided DWSIM data: 5 simulations\n",
            "   ✅ Created 5 simulation chunks\n",
            "   📊 DWSIM data integrated successfully\n",
            "\n",
            "🔍 Enhanced Query Capabilities:\n",
            "   1. What are the performance metrics for the distillation simulation?\n",
            "   2. How do the reactor conversion rates compare across simulations?\n",
            "   3. Which simulation showed the highest efficiency?\n",
            "   📊 Combined 445 total chunks (documents + simulations)\n",
            "   🔗 Simulation chunks properly formatted as Document objects\n",
            "   💾 Saving combined chunk data...\n",
            "   ✅ Chunk data saved successfully\n",
            "\n",
            "Step 5: Building FAISS vector store...\n",
            "=== FAISS VectorDB Analysis ===\n",
            "Started: 2025-06-13 21:34:29\n",
            "   🔄 Loading documents from saved JSON file...\n",
            "Loaded 445 documents from /Users/mohammadalmusaiteer/PyNucleus-Model/data/03_intermediate/converted_chunked_data/chunked_data_full.json\n",
            "   ✅ Documents properly loaded: 445 Document objects\n",
            "🔍 Building FAISS index with 445 documents\n",
            "   First document type: <class 'langchain_core.documents.base.Document'>\n",
            "   Has page_content: ✅\n",
            "✅ FAISS index built successfully with langchain\n",
            "Embedding device → cpu   | dim=384\n",
            "Docs indexed : 445\n",
            "\n",
            "-- Files in chunk_reports/ --\n",
            "  · faiss_analysis_20250613_184115.txt\n",
            "  · faiss_analysis_20250613_213429.txt\n",
            "  · faiss_analysis_20250613_212251.txt\n",
            "  · faiss_analysis_20250613_183903.txt\n",
            "  · embeddings.pkl\n",
            "  · faiss_analysis_20250613_185526.txt\n",
            "  · faiss_analysis_20250613_185453.txt\n",
            "  · faiss_analysis_20250613_184822.txt\n",
            "  · faiss_analysis_20250613_184438.txt\n",
            "  · faiss_analysis_20250613_182501.txt\n",
            "  · faiss_analysis_20250613_190503.txt\n",
            "  · faiss_analysis_20250613_183001.txt\n",
            "  · faiss_analysis_20250613_185110.txt\n",
            "  · faiss_analysis_20250613_182051.txt\n",
            "  · faiss_analysis_20250613_185927.txt\n",
            "  · faiss_analysis_20250613_182443.txt\n",
            "  · faiss_analysis_20250613_212200.txt\n",
            "  · pynucleus_mcp.faiss\n",
            "  · faiss_analysis_20250613_190418.txt\n",
            "  · faiss_analysis_20250613_182806.txt\n",
            "  · faiss_analysis_20250613_190224.txt\n",
            "  · faiss_analysis_20250613_184906.txt\n",
            "  · faiss_analysis_20250613_213155.txt\n",
            "\n",
            "=== Evaluation (Recall@3) ===\n",
            "Q: what are the benefits of modular design  ✗   top-score=0.4899\n",
            "Q: how does modular design work in vehicles ✗   top-score=0.4153\n",
            "\n",
            "Recall@3: 0/2  →  0.0%\n",
            "✅ RAG Pipeline completed! FAISS log → data/04_models/chunk_reports/faiss_analysis_20250613_213429.txt\n",
            "🔍 Testing RAG queries...\n",
            "\n",
            "📝 Query: What are the key challenges in implementing modular chemical plants?\n",
            "   1. Score: 0.6239 | Source: data/02_processed/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
            "   2. Score: 0.6494 | Source: data/02_processed/converted_to_txt/mcp_basics.txt\n",
            "   3. Score: 0.6552 | Source: data/02_processed/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
            "\n",
            "📝 Query: How does supply chain management affect modular design?\n",
            "   1. Score: 0.7417 | Source: data/01_raw/web_sources/wikipedia_modular_design.txt\n",
            "   2. Score: 0.7481 | Source: data/01_raw/web_sources/wikipedia_supply_chain.txt\n",
            "   3. Score: 0.7660 | Source: data/01_raw/web_sources/wikipedia_supply_chain.txt\n",
            "\n",
            "📝 Query: What are the economic benefits of modular construction?\n",
            "   1. Score: 0.7034 | Source: data/01_raw/web_sources/wikipedia_modular_design.txt\n",
            "   2. Score: 0.7115 | Source: data/01_raw/web_sources/wikipedia_modular_design.txt\n",
            "   3. Score: 0.7493 | Source: data/02_processed/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
            "\n",
            "📝 Query: How does software architecture relate to modular design?\n",
            "   1. Score: 0.5024 | Source: data/01_raw/web_sources/wikipedia_modular_design.txt\n",
            "   2. Score: 0.5750 | Source: data/01_raw/web_sources/wikipedia_software_architecture.txt\n",
            "   3. Score: 0.6297 | Source: data/01_raw/web_sources/wikipedia_modular_design.txt\n",
            "\n",
            "📝 Query: What are the environmental impacts of modular manufacturing?\n",
            "   1. Score: 0.6874 | Source: data/02_processed/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
            "   2. Score: 0.7515 | Source: data/02_processed/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
            "   3. Score: 0.7518 | Source: data/02_processed/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
            "✅ Query testing completed! 15 results collected.\n",
            "✅ RAG: 445 chunks processed\n",
            "\n",
            "💾 Step 3: Exporting results...\n",
            "\n",
            "💾 Exporting DWSIM simulation results...\n",
            "✅ DWSIM results exported: data/05_output/results/dwsim_simulation_results.csv\n",
            "   📊 5 simulation results exported\n",
            "   📋 Columns: Case Name, Type, Components, Status, Performance Metrics\n",
            "✅ DWSIM summary exported: data/05_output/results/dwsim_summary.csv\n",
            "\n",
            "🎉 Export completed successfully!\n",
            "📁 All results saved in: data/05_output/results\n",
            "📈 Files created:\n",
            "   • dwsim_simulation_results.csv (910 bytes)\n",
            "   • dwsim_summary.csv (360 bytes)\n",
            "✅ Export: 2 files created\n",
            "\n",
            "✅ Complete pipeline finished in 14.9 seconds!\n",
            "📊 Components completed: 3/3\n",
            "\n",
            "🎉 Analysis completed successfully in 14.9 seconds!\n",
            "\n",
            "📊 Results Summary:\n",
            "   • Documents Processed: 15 queries\n",
            "   • Simulations Completed: 5 scenarios\n",
            "   • Files Generated: 2 CSV files\n",
            "✅ Enhanced 5 simulations with RAG insights\n",
            "\n",
            "💰 Financial Analysis:\n",
            "   • Recovery Rate: 83.0%\n",
            "   • Daily Revenue: $149,328.00\n",
            "   • Daily Profit: $59,328.00\n",
            "   • ROI: 6.6%\n",
            "\n",
            "📄 Generated Reports: 3 detailed analysis files\n",
            "\n",
            "📁 All results saved to:\n",
            "   • CSV Files: data/05_output/results/\n",
            "   • Reports: data/05_output/reports/\n",
            "\n",
            "✅ Analysis complete! Run Cell 3 to explore your results.\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Run Complete Analysis\n",
        "# ===================================\n",
        "# This cell runs the complete PyNucleus pipeline\n",
        "\n",
        "print(\"🚀 Starting Complete PyNucleus Analysis...\")\n",
        "print(\"\\n📊 This will run:\")\n",
        "print(\"   1. Document processing and RAG analysis\")\n",
        "print(\"   2. DWSIM chemical process simulations\")\n",
        "print(\"   3. Results export and report generation\")\n",
        "print(\"\\n⏳ Please wait... This may take 20-30 seconds.\\n\")\n",
        "\n",
        "try:\n",
        "    # Run the complete pipeline\n",
        "    results = pipeline.run_complete_pipeline()\n",
        "    \n",
        "    if results:\n",
        "        print(f\"\\n🎉 Analysis completed successfully in {results['duration']:.1f} seconds!\")\n",
        "        print(\"\\n📊 Results Summary:\")\n",
        "        print(f\"   • Documents Processed: {len(results['rag_data'])} queries\")\n",
        "        print(f\"   • Simulations Completed: {len(results['dwsim_data'])} scenarios\")\n",
        "        print(f\"   • Files Generated: {len(results['exported_files'])} CSV files\")\n",
        "        \n",
        "        # Generate enhanced reports if available\n",
        "        try:\n",
        "            from pynucleus.integration.dwsim_rag_integrator import DWSIMRAGIntegrator\n",
        "            \n",
        "            integrator = DWSIMRAGIntegrator(\n",
        "                rag_pipeline=pipeline.rag_pipeline,\n",
        "                results_dir=\"data/05_output/results\"\n",
        "            )\n",
        "            \n",
        "            # Enhanced analysis\n",
        "            dwsim_results = pipeline.dwsim_pipeline.get_results()\n",
        "            if dwsim_results:\n",
        "                enhanced_results = integrator.integrate_simulation_results(\n",
        "                    dwsim_results, perform_rag_analysis=True\n",
        "                )\n",
        "                \n",
        "                # Generate LLM reports\n",
        "                report_files = []\n",
        "                for result in enhanced_results[:3]:  # Generate reports for first 3 simulations\n",
        "                    report_file = llm_generator.export_llm_ready_text(result)\n",
        "                    report_files.append(report_file)\n",
        "                \n",
        "                # Financial analysis\n",
        "                financial_file = llm_generator.export_financial_analysis(enhanced_results)\n",
        "                metrics = llm_generator._calculate_key_metrics(enhanced_results)\n",
        "                \n",
        "                print(\"\\n💰 Financial Analysis:\")\n",
        "                print(f\"   • Recovery Rate: {metrics['avg_recovery']:.1f}%\")\n",
        "                print(f\"   • Daily Revenue: ${metrics['estimated_revenue']:,.2f}\")\n",
        "                print(f\"   • Daily Profit: ${metrics['net_profit']:,.2f}\")\n",
        "                print(f\"   • ROI: {metrics['roi']:.1f}%\")\n",
        "                \n",
        "                print(f\"\\n📄 Generated Reports: {len(report_files)} detailed analysis files\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(\"⚠️ Enhanced analysis unavailable (using basic results only)\")\n",
        "        \n",
        "        print(\"\\n📁 All results saved to:\")\n",
        "        print(\"   • CSV Files: data/05_output/results/\")\n",
        "        print(\"   • Reports: data/05_output/reports/\")\n",
        "        print(\"\\n✅ Analysis complete! Run Cell 3 to explore your results.\")\n",
        "        \n",
        "    else:\n",
        "        print(\"❌ Pipeline execution failed\")\n",
        "        print(\"💡 Please check your data directories and try again\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"❌ Error during analysis: {e}\")\n",
        "    print(\"💡 Please ensure all components are properly initialized\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔄 Refreshing Pipeline Instance...\n",
            "🔧 Setting up RAG imports...\n",
            "Warning: wikipedia package not available. Wikipedia scraping disabled.\n",
            "✅ RAG imports ready!\n",
            "📂 Loaded 5 existing DWSIM results from disk\n",
            "🔧 Setting up DWSIM imports...\n",
            "✅ DWSIM modules imported successfully\n",
            "📁 Results directory: data/05_output/results\n",
            "🔧 Pipeline Utils initialized with results dir: data/05_output/results\n",
            "🔗 DWSIM-RAG integration enabled\n",
            "✅ Pipeline refreshed successfully!\n",
            "📊 Now you can run Cell 3 to view the dashboard\n",
            "🧪 Quick Pipeline Test\n",
            "------------------------------\n",
            "📚 RAG: 445 chunks available\n",
            "🔗 Integration: ⚪ Documents only\n",
            "📊 DWSIM Statistics:\n",
            "   • Total Simulations: 5\n",
            "   • Success Rate: 100.0%\n",
            "   • Average Duration: 0.00s\n",
            "🔬 DWSIM: 5 simulations\n",
            "📁 Output: 2 CSV files\n",
            "\n",
            "🧪 Quick Test Results:\n",
            "   📁 Results Directory: data/05_output/results\n",
            "   📄 CSV Files: 2\n",
            "   🔗 Integration: ⚪ Documents only\n",
            "   📊 Total Chunks: 445\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Refresh Pipeline (Run this if you encounter errors)\n",
        "# ===================================\n",
        "# This cell refreshes the pipeline instance with all latest fixes\n",
        "\n",
        "print(\"🔄 Refreshing Pipeline Instance...\")\n",
        "\n",
        "try:\n",
        "    # Import the latest version\n",
        "    from src.pynucleus.pipeline.pipeline_utils import PipelineUtils\n",
        "    \n",
        "    # Create a fresh pipeline instance with all fixes\n",
        "    pipeline = PipelineUtils()\n",
        "    \n",
        "    print(\"✅ Pipeline refreshed successfully!\")\n",
        "    print(\"📊 Now you can run Cell 3 to view the dashboard\")\n",
        "    \n",
        "    # Quick test to verify it's working\n",
        "    status = pipeline.quick_test()\n",
        "    print(f\"\\n🧪 Quick Test Results:\")\n",
        "    print(f\"   📁 Results Directory: {status.get('results_dir', 'Not found')}\")\n",
        "    print(f\"   📄 CSV Files: {status.get('csv_files_count', 0)}\")\n",
        "    print(f\"   🔗 Integration: {'✅ Enabled' if status.get('integration_enabled', False) else '⚪ Documents only'}\")\n",
        "    print(f\"   📊 Total Chunks: {status.get('rag_chunks', 0)}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"❌ Error refreshing pipeline: {e}\")\n",
        "    print(\"💡 Try restarting the kernel and running all cells from the beginning\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 PyNucleus Results Dashboard\n",
            "========================================\n",
            "🧪 Quick Pipeline Test\n",
            "------------------------------\n",
            "📚 RAG: 445 chunks available\n",
            "🔗 Integration: ⚪ Documents only\n",
            "📊 DWSIM Statistics:\n",
            "   • Total Simulations: 5\n",
            "   • Success Rate: 100.0%\n",
            "   • Average Duration: 0.00s\n",
            "🔬 DWSIM: 5 simulations\n",
            "📁 Output: 2 CSV files\n",
            "📁 Results Directory: data/05_output/results\n",
            "📄 CSV Files Found: 2\n",
            "\n",
            "📋 Available Files:\n",
            "   • dwsim_summary.csv (360 bytes)\n",
            "   • dwsim_simulation_results.csv (910 bytes)\n",
            "\n",
            "========================================\n",
            "\n",
            "📊 Pipeline Results Summary\n",
            "============================================================\n",
            "📊 DWSIM Statistics:\n",
            "   • Total Simulations: 5\n",
            "   • Success Rate: 100.0%\n",
            "   • Average Duration: 0.00s\n",
            "📚 RAG Knowledge Base:\n",
            "   Total Chunks: 445\n",
            "   Document Sources: 14\n",
            "   Integration: ⚪ Documents only\n",
            "   Avg Chunk Size: 760.5 chars\n",
            "\n",
            "🔬 DWSIM Simulations:\n",
            "   Total Simulations: 5\n",
            "   Success Rate: 100.0%\n",
            "   Avg Duration: 0.00s\n",
            "\n",
            "📁 Output Files:\n",
            "   • dwsim_summary.csv (0.4 KB)\n",
            "   • dwsim_simulation_results.csv (0.9 KB)\n",
            "============================================================\n",
            "\n",
            "🔧 Additional Options:\n",
            "   • Re-run Cell 2 to generate new results\n",
            "   • Check data/05_output/ folder for all generated files\n",
            "   • View Developer_Notebook.ipynb for advanced features\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: View Results and Summary\n",
        "# ===================================\n",
        "# This cell displays your results and provides access to files\n",
        "\n",
        "print(\"📊 PyNucleus Results Dashboard\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "try:\n",
        "    # Quick status check\n",
        "    status = pipeline.quick_test()\n",
        "    \n",
        "    print(f\"📁 Results Directory: {status['results_dir']}\")\n",
        "    print(f\"📄 CSV Files Found: {status['csv_files_count']}\")\n",
        "    \n",
        "    if status['csv_files_count'] > 0:\n",
        "        print(\"\\n📋 Available Files:\")\n",
        "        for file_info in status['csv_files']:\n",
        "            print(f\"   • {file_info['name']} ({file_info['size']} bytes)\")\n",
        "    \n",
        "    # Display detailed summary\n",
        "    print(\"\\n\" + \"=\" * 40)\n",
        "    pipeline.view_results_summary()\n",
        "    \n",
        "    print(\"\\n🔧 Additional Options:\")\n",
        "    print(\"   • Re-run Cell 2 to generate new results\")\n",
        "    print(\"   • Check data/05_output/ folder for all generated files\")\n",
        "    print(\"   • View Developer_Notebook.ipynb for advanced features\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"❌ Error viewing results: {e}\")\n",
        "    print(\"💡 Please run Cell 2 first to generate results\")"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "\n",
        "## **Optional: Individual Components**\n",
        "\n",
        "The cells below allow you to run specific parts of the pipeline individually if needed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Optional Cell 4A: Run Only Document Analysis (RAG)\n",
        "# # ====================================================\n",
        "# # Uncomment and run this cell if you only want document processing\n",
        "\n",
        "# print(\"📚 Running Document Analysis Only...\")\n",
        "# rag_results = pipeline.run_rag_only()\n",
        "# if rag_results:\n",
        "#     print(f\"✅ Processed {len(rag_results['rag_data'])} document queries\")\n",
        "#     print(\"📁 Results saved to data/05_output/results/\")\n",
        "# else:\n",
        "#     print(\"❌ Document analysis failed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Optional Cell 4B: Run Only Chemical Simulations (DWSIM)\n",
        "# # =======================================================\n",
        "# # Uncomment and run this cell if you only want DWSIM simulations\n",
        "\n",
        "# print(\"🔬 Running Chemical Simulations Only...\")\n",
        "# dwsim_results = pipeline.run_dwsim_only()\n",
        "# if dwsim_results:\n",
        "#     print(f\"✅ Completed {len(dwsim_results['dwsim_data'])} simulations\")\n",
        "#     print(\"📁 Results saved to data/05_output/results/\")\n",
        "# else:\n",
        "#     print(\"❌ Chemical simulations failed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Optional Cell 5: Clean Up Results\n",
        "# # =================================\n",
        "# # Uncomment and run this cell to clear all previous results\n",
        "\n",
        "# print(\"🗑️ Cleaning up previous results...\")\n",
        "# pipeline.clean_all_results()\n",
        "# print(\"✅ All results cleared. You can now run a fresh analysis.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # ========================================\n",
        "# # VERSION CONTROL (Optional - For Maintainers Only)\n",
        "# # ========================================\n",
        "# # Uncomment the lines below if you need to update the repository:\n",
        "\n",
        "# from datetime import datetime\n",
        "\n",
        "# # Log end time\n",
        "# with open(\"update_log.txt\", \"a\") as f:\n",
        "#     f.write(f\"\\n {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} changes made and pushed to origin main\\n\")\n",
        "\n",
        "# # Simple GitHub update function\n",
        "# def update_github():\n",
        "#     print(\" Starting GitHub update...\")\n",
        "#     !git add .\n",
        "#     print(\" Files added to staging\")\n",
        "#     !git commit -m \"Update: $(date +'%Y-%m-%d %H:%M:%S')\"\n",
        "#     print(\" Changes committed\")\n",
        "#     !git push origin main\n",
        "#     print(\" Changes pushed to GitHub successfully!\")\n",
        "\n",
        "# # To use it, just run:\n",
        "# update_github()"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "\n",
        "## **Need More Features?**\n",
        "\n",
        "🔧 **For Developers**: Advanced features, debugging, and system diagnostics are available in:\n",
        "- `Developer_Notebook.ipynb` - Full development environment\n",
        "- `scripts/comprehensive_system_diagnostic.py` - System health checks\n",
        "\n",
        "📚 **Documentation**: Check the `docs/` folder for detailed guides:\n",
        "- `README.md` - Complete setup and usage guide\n",
        "- `docs/ENHANCED_PIPELINE_SUMMARY.md` - Advanced features overview\n",
        "- `docs/project_info/` - Technical documentation\n",
        "\n",
        "💡 **Support**: For issues or questions, check the project documentation or create an issue in the repository.\n",
        "\n",
        "---\n",
        "\n",
        "**🎉 Thank you for using PyNucleus!**\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
