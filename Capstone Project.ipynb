{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21621,
     "status": "ok",
     "timestamp": 1748965189264,
     "user": {
      "displayName": "Mohammad A.",
      "userId": "15199683412159334052"
     },
     "user_tz": 240
    },
    "id": "pxJK6GpyVui7",
    "outputId": "5fcaf74f-4292-4847-fb37-57d1c0d9a971"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username: Saytor20\n",
      "Token: ghp_...\n",
      "Pulling latest changes from GitHub...\n",
      "From https://github.com/Saytor20/PyNucleus-Model\n",
      " * branch            main       -> FETCH_HEAD\n",
      "Already up to date.\n",
      "Repository is up to date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "#--------Google Drive Integration--------#\n",
    "# from google.colab import drive, userdata\n",
    "# This gives Colab access to your files in Google Drive.\n",
    "# drive.mount('/content/drive')\n",
    "# 'GITHUB_USERNAME' and 'GITHUB_TOKEN' saved as secrets in Colab.\n",
    "# GITHUB_USERNAME = userdata.get('GITHUB_USERNAME')\n",
    "# GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n",
    "# REPOSITORY_NAME = 'PyNucleus-Model' # Your repository name\n",
    "# NOTEBOOK_DRIVE_PATH = \"/content/drive/MyDrive/PyNucleus Project/Capstone Project.ipynb\"\n",
    "\n",
    "\n",
    "#--------Cursor Integration--------#\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get GitHub credentials from environment variables\n",
    "GITHUB_USERNAME = os.getenv('GITHUB_USERNAME')\n",
    "GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')\n",
    "\n",
    "# Print to verify the variables are loaded (remove this in production)\n",
    "print(f\"Username: {GITHUB_USERNAME}\")\n",
    "print(f\"Token: {GITHUB_TOKEN[:4]}...\") # Only print first 4 chars of token for security\n",
    "\n",
    "# Repository information\n",
    "REPOSITORY_NAME = 'PyNucleus-Model'\n",
    "NOTEBOOK_REPO_FILENAME = \"Capstone Project.ipynb\"\n",
    "LOG_FILENAME = \"update_log.txt\"\n",
    "\n",
    "# Pull latest changes from GitHub\n",
    "print(\"Pulling latest changes from GitHub...\")\n",
    "!git pull https://{GITHUB_TOKEN}@github.com/{GITHUB_USERNAME}/{REPOSITORY_NAME}.git main\n",
    "\n",
    "print(\"Repository is up to date!\")\n",
    "\n",
    "# Add a new line to your log file with the current date and time.\n",
    "log_message = f\"Notebook saved on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "with open(LOG_FILENAME, \"a\") as f:\n",
    "    f.write(f\"\\n[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Your update message here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Clone the Repository\n",
    "# repo_path = f'/content/{REPOSITORY_NAME}'\n",
    "# !git clone https://{GITHUB_TOKEN}@github.com/{GITHUB_USERNAME}/{REPOSITORY_NAME}.git {repo_path}\n",
    "\n",
    "# # Change the current working directory to the repository\n",
    "# # All subsequent commands will run from inside the repo folder.\n",
    "# os.chdir(repo_path)\n",
    "\n",
    "# # Add a new line to your log file with the current date and time.\n",
    "# log_message = f\"Notebook saved on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "# with open(LOG_FILENAME, \"a\") as f:\n",
    "#     f.write(log_message + \"\\n\")\n",
    "# print(f\"Updated '{LOG_FILENAME}'\")\n",
    "\n",
    "# # Copy the latest version of notebook from Drive into the cloned repo.\n",
    "# !cp \"{NOTEBOOK_DRIVE_PATH}\" \"{NOTEBOOK_REPO_FILENAME}\"\n",
    "# print(f\"Copied '{NOTEBOOK_REPO_FILENAME}' from Google Drive.\")\n",
    "\n",
    "# # Git identity for commenting\n",
    "# !git config user.name \"{GITHUB_USERNAME}\"\n",
    "# !git config user.email \"{GITHUB_USERNAME}@users.noreply.github.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 110795,
     "status": "ok",
     "timestamp": 1748965303690,
     "user": {
      "displayName": "Mohammad A.",
      "userId": "15199683412159334052"
     },
     "user_tz": 240
    },
    "id": "DfNy6HlnOsXc",
    "outputId": "8b84eae8-c15c-4509-db15-00592ebae7ca"
   },
   "outputs": [],
   "source": [
    "# # --- Installation Cell (Run this ONCE per session) ---\n",
    "# print(\"Installing all required packages...\")\n",
    "\n",
    "# %pip install -q langchain langchain-core langchain-community langchain-text-splitters\n",
    "\n",
    "# %pip install -q \"unstructured[local-inference]\"\n",
    "\n",
    "# # LLM & ML Libraries\n",
    "# %pip install -q transformers accelerate bitsandbytes torch sentence-transformers\n",
    "\n",
    "# # Vector Stores\n",
    "# %pip install -q chromadb faiss-cpu # faiss-gpu if you have a Pro Colab with a good GPU\n",
    "\n",
    "# # Data Handling & Utilities\n",
    "# %pip install -q pandas numpy tqdm PyYAML\n",
    "\n",
    "# print(\"All packages installed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "executionInfo": {
     "elapsed": 12520,
     "status": "ok",
     "timestamp": 1748965316213,
     "user": {
      "displayName": "Mohammad A.",
      "userId": "15199683412159334052"
     },
     "user_tz": 240
    },
    "id": "BPyfUDJoDjgn"
   },
   "outputs": [],
   "source": [
    "# --- Core Utilities & File Handling ---\n",
    "import getpass\n",
    "import yaml # Make sure PyYAML is installed\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Data Handling & Progress Bars ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Document Loading ---\n",
    "# UnstructuredFileLoader is now in langchain_community\n",
    "from langchain_community.document_loaders import UnstructuredFileLoader\n",
    "# For future testing of more specific loaders:\n",
    "# from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader\n",
    "\n",
    "# --- OCR Libraries ---\n",
    "# No direct imports needed here if using UnstructuredFileLoader with local-inference,\n",
    "# as it handles OCR internally.\n",
    "# You would only import these for a manual OCR process:\n",
    "# import pytesseract\n",
    "# from pdf2image import convert_from_path\n",
    "# from PIL import Image\n",
    "\n",
    "# --- Core ML & LLM Libraries ---\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import bitsandbytes\n",
    "import accelerate # Often used with transformers\n",
    "\n",
    "# --- Vector Stores & Embeddings ---\n",
    "# Using ChromaDB as the primary vector store.\n",
    "import chromadb\n",
    "from langchain_community.vectorstores import Chroma # Chroma is now in langchain_community\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings # Embeddings are also in langchain_community\n",
    "# For future testing of a high-performance alternative:\n",
    "# import faiss\n",
    "# from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# --- RAG/Agent Frameworks ---\n",
    "# Core LangChain components\n",
    "import langchain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# For future testing of an alternative RAG-focused toolkit:\n",
    "# from llama_index.core import SimpleDirectoryReader, VectorStoreIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84DXL9QuH0Tx"
   },
   "source": [
    "# **Data Ingestion and Preprocessing for RAG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1748965316223,
     "user": {
      "displayName": "Mohammad A.",
      "userId": "15199683412159334052"
     },
     "user_tz": 240
    },
    "id": "SvrR6N-LH7HB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OL-SmhSQQ_21"
   },
   "source": [
    "# **Data Scrapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1748965316233,
     "user": {
      "displayName": "Mohammad A.",
      "userId": "15199683412159334052"
     },
     "user_tz": 240
    },
    "id": "I69992m0RE82"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hISFF6TUEB_H"
   },
   "source": [
    "# This is the last cell of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1610,
     "status": "ok",
     "timestamp": 1748965317848,
     "user": {
      "displayName": "Mohammad A.",
      "userId": "15199683412159334052"
     },
     "user_tz": 240
    },
    "id": "tjThfmG7EDzG",
    "outputId": "c0e3a16d-87b8-4a04-ec34-d92e7264e169"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 6f17796] Update notebook and log file on 2025-06-03\n",
      " 1 file changed, 2 insertions(+), 1 deletion(-)\n",
      "\n",
      "Pushing changes to GitHub...\n",
      "Enumerating objects: 5, done.\n",
      "Counting objects: 100% (5/5), done.\n",
      "Delta compression using up to 8 threads\n",
      "Compressing objects: 100% (3/3), done.\n",
      "Writing objects: 100% (3/3), 326 bytes | 326.00 KiB/s, done.\n",
      "Total 3 (delta 2), reused 0 (delta 0), pack-reused 0 (from 0)\n",
      "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
      "To https://github.com/Saytor20/PyNucleus-Model.git\n",
      "   ad3e558..6f17796  main -> main\n",
      "\n",
      " Successfully saved 'Capstone Project.ipynb' to your GitHub repository!\n"
     ]
    }
   ],
   "source": [
    "# Add the notebook to the staging area\n",
    "!git add \"{NOTEBOOK_REPO_FILENAME}\"\n",
    "!git add \"{LOG_FILENAME}\"\n",
    "\n",
    "# Commit the changes with a more descriptive message\n",
    "commit_message = f\"Update notebook and log file on {datetime.now().strftime('%Y-%m-%d')}\"\n",
    "!git commit -m \"{commit_message}\"\n",
    "\n",
    "# Push to GitHub using the token for authentication\n",
    "print(\"\\nPushing changes to GitHub...\")\n",
    "!git push https://{GITHUB_TOKEN}@github.com/{GITHUB_USERNAME}/{REPOSITORY_NAME}.git main\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\n Successfully saved '{NOTEBOOK_REPO_FILENAME}' to your GitHub repository!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
