{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from datetime import datetime\n",
    "# from dotenv import load_dotenv\n",
    "# #\n",
    "# # #--------Google Drive Integration--------#\n",
    "# # # from google.colab import drive, userdata\n",
    "# # # This gives Colab access to your files in Google Drive.\n",
    "# # # drive.mount('/content/drive')\n",
    "# # # 'GITHUB_USERNAME' and 'GITHUB_TOKEN' saved as secrets in Colab.\n",
    "# # GITHUB_USERNAME = userdata.get('GITHUB_USERNAME')\n",
    "# # GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n",
    "# # REPOSITORY_NAME = 'PyNucleus-Model' # Your repository name\n",
    "# # NOTEBOOK_DRIVE_PATH = \"/content/drive/MyDrive/PyNucleus Project/Capstone Project.ipynb\"\n",
    "# #\n",
    "# #\n",
    "# # #--------Cursor Integration--------#\n",
    "# # # Load environment variables from .env file\n",
    "# load_dotenv()\n",
    "# #\n",
    "# # # Get GitHub credentials from environment variables\n",
    "# GITHUB_USERNAME = os.getenv('GITHUB_USERNAME')\n",
    "# GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')\n",
    "# #\n",
    "# # # Print to verify the variables are loaded (remove this in production)\n",
    "# print(f\"Username: {GITHUB_USERNAME}\")\n",
    "# print(f\"Token: {GITHUB_TOKEN[:4]}...\") # Only print first 4 chars of token for security\n",
    "# #\n",
    "# # Repository information\n",
    "# REPOSITORY_NAME = 'PyNucleus-Model'\n",
    "# NOTEBOOK_REPO_FILENAME = \"Capstone Project.ipynb\"\n",
    "# LOG_FILENAME = \"update_log.txt\"\n",
    "\n",
    "# # Pull latest changes from GitHub\n",
    "# print(\"Pulling latest changes from GitHub...\")\n",
    "# !git pull https://{GITHUB_TOKEN}@github.com/{GITHUB_USERNAME}/{REPOSITORY_NAME}.git main\n",
    "\n",
    "# print(\"Repository is up to date!\")\n",
    "\n",
    "# # Log start time\n",
    "# with open(\"update_log.txt\", \"a\") as f:\n",
    "#     f.write(f\" {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}: Log Update\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21621,
     "status": "ok",
     "timestamp": 1748965189264,
     "user": {
      "displayName": "Mohammad A.",
      "userId": "15199683412159334052"
     },
     "user_tz": 240
    },
    "id": "pxJK6GpyVui7",
    "outputId": "5fcaf74f-4292-4847-fb37-57d1c0d9a971"
   },
   "outputs": [],
   "source": [
    "# PyNucleus Model - Setup and Imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to Python path\n",
    "src_path = str(Path().resolve() / \"src\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "# Import PyNucleus Pipeline modules\n",
    "from pynucleus.pipeline import RAGPipeline, DWSIMPipeline, ResultsExporter, PipelineUtils\n",
    "from pynucleus.integration.config_manager import ConfigManager\n",
    "from pynucleus.integration.dwsim_rag_integrator import DWSIMRAGIntegrator\n",
    "from pynucleus.integration.llm_output_generator import LLMOutputGenerator\n",
    "\n",
    "\n",
    "print(\" PyNucleus Model - Pipeline Ready!\")\n",
    "print(\" Available Components:\")\n",
    "print(\"   â€¢ RAGPipeline - Document processing and retrieval\")\n",
    "print(\"   â€¢ DWSIMPipeline - Chemical process simulation\") \n",
    "print(\"   â€¢ ResultsExporter - CSV export functionality\")\n",
    "print(\"   â€¢ PipelineUtils - Complete pipeline orchestration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84DXL9QuH0Tx"
   },
   "source": [
    "# **PyNucleus Model - Complete Pipeline**\n",
    "\n",
    "This notebook contains the complete PyNucleus model pipeline with separate sections for:\n",
    "1. **Data Ingestion and Preprocessing for RAG** \n",
    "2. **DWSIM Integration and Simulation**\n",
    "3. **Results Export to CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Pipeline Components\n",
    "pipeline = PipelineUtils(results_dir=\"data/05_output/results\")\n",
    "\n",
    "\n",
    "print(\"\\nðŸ”§ Pipeline Initialized!\")\n",
    "print(\"Available Functions:\")\n",
    "print(\"   â€¢ pipeline.run_complete_pipeline() - Run everything\")\n",
    "print(\"   â€¢ pipeline.run_rag_only() - RAG pipeline only\")  \n",
    "print(\"   â€¢ pipeline.run_dwsim_only() - DWSIM simulations only\")\n",
    "print(\"   â€¢ pipeline.quick_test() - Verify status\")\n",
    "print(\"   â€¢ pipeline.view_results_summary() - View results\")\n",
    "print(\"   â€¢ pipeline.print_pipeline_status() - Detailed status\")\n",
    "print(\"   â€¢ pipeline.clean_all_results() - Clean all data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# SECTION 1: COMPLETE PIPELINE - Run Everything (Basic Mode)\n",
    "\"\"\"This section is the basic pipeline which covers \n",
    "- Runs standard RAG + DWSIM + CSV Export\n",
    "- Output: Basic CSV files with simulation results\n",
    "- For: Regular users who need standard functionality \"\"\"\n",
    "# ========================================\n",
    "\n",
    "# Run the complete pipeline (RAG + DWSIM + Export)\n",
    "results = pipeline.run_complete_pipeline()\n",
    "\n",
    "# Display results summary\n",
    "if results:\n",
    "    print(f\"\\nðŸŽ‰ Pipeline completed in {results['duration']:.1f} seconds!\")\n",
    "    print(f\"ðŸ“Š RAG Results: {len(results['rag_data'])} queries processed\")\n",
    "    print(f\"ðŸ”¬ DWSIM Results: {len(results['dwsim_data'])} simulations completed\")\n",
    "    print(f\"ðŸ“ Exported Files: {len(results['exported_files'])} CSV files created\")\n",
    "else:\n",
    "    print(\"âŒ Pipeline execution failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ========================================\n",
    "# # OPTIONAL: INDIVIDUAL PIPELINE COMPONENTS\n",
    "# # ========================================\n",
    "\n",
    "# # Option 1: Run only RAG Pipeline\n",
    "# print(\"ðŸ“š RAG Only Pipeline:\")\n",
    "# rag_results = pipeline.run_rag_only()\n",
    "# if rag_results:\n",
    "#     print(f\"   âœ… {len(rag_results['rag_data'])} RAG queries processed\")\n",
    "\n",
    "# print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# # Option 2: Run only DWSIM Simulations  \n",
    "# print(\"ðŸ”¬ DWSIM Only Pipeline:\")\n",
    "# dwsim_results = pipeline.run_dwsim_only()\n",
    "# if dwsim_results:\n",
    "#     print(f\"   âœ… {len(dwsim_results['dwsim_data'])} DWSIM simulations completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ========================================\n",
    "# # OPTIONAL: View Results & Status (After Running Pipelines)\n",
    "# # ========================================\n",
    "\n",
    "# # View pipeline status\n",
    "# pipeline.print_pipeline_status()\n",
    "\n",
    "# print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# # View results summary\n",
    "# pipeline.view_results_summary()\n",
    "\n",
    "# print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# # Quick test\n",
    "# test_results = pipeline.quick_test()\n",
    "# print(f\"âœ… Quick test completed! Found {test_results['csv_files_count']} CSV files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# OPTIONAL: CLEANUP AND RESET (Optional)\n",
    "# ========================================\n",
    "# Uncomment the lines below if you need to clean up results:\n",
    "\n",
    "# Clean up and reset (optional - removes all previous results)\n",
    "# pipeline.clean_all_results()\n",
    "\n",
    "# print(\"âœ… PyNucleus Pipeline is ready!\")\n",
    "# print(\"ðŸ“‹ Usage Guide:\")\n",
    "# print(\"   â€¢ Section 1: Run complete pipeline (RAG + DWSIM + Export)\")\n",
    "# print(\"   â€¢ Section 2: Individual components (commented out)\")\n",
    "# print(\"   â€¢ Section 3: Utility functions (status, summary, test)\")\n",
    "# print(\"   â€¢ Enhanced Pipeline: Advanced configuration, integration, LLM output\")\n",
    "# print(\"   â€¢ Enhanced Features: Configuration, Integration, LLM Output\")\n",
    "# print(\"\\nðŸ”„ Run any cell multiple times to re-execute components\")\n",
    "# print(\"ðŸ“ All results automatically saved as CSV files in data/05_output/results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# OPTION A: Run Individual Components (Alternative to Section 1)\n",
    "# ========================================\n",
    "# Uncomment ONLY the lines you want to run:\n",
    "\n",
    "# Option A1: Complete pipeline (same as Section 1)\n",
    "# results = pipeline.run_complete_pipeline()\n",
    "\n",
    "# Option A2: Individual components only\n",
    "# rag_results = pipeline.run_rag_only()        # RAG documents only\n",
    "# dwsim_results = pipeline.run_dwsim_only()    # DWSIM simulations only"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# **ENHANCED PIPELINE - Advanced Features**\n",
    "\n",
    "This section contains enhanced capabilities for advanced users:\n",
    "\n",
    "1. **Enhanced Pipeline Initialization** (Cell 10) - Initialize advanced components FIRST\n",
    "2. **Configurable DWSIM Simulations** (Cell 11) - JSON/CSV configuration files\n",
    "3. **DWSIM-RAG Integration** (Cell 12) - Enhanced analysis with knowledge insights  \n",
    "4. **LLM-Ready Outputs** (Cell 13) - Text summaries with enhanced feed conditions\n",
    "5. **Production Analytics** (Cell 14) - Recovery rates, ROI, and profit analysis\n",
    "\n",
    "**âš ï¸ CRITICAL: Execute cells in this exact order for enhanced features to work:**\n",
    "**1. Cell 10 (Enhanced Pipeline Initialization) FIRST**\n",
    "**2. Cell 11 (Configuration Templates)**  \n",
    "**3. Cell 12 (DWSIM-RAG Integration)**\n",
    "**4. Cell 13 (LLM-Ready Output with Enhanced Feed Conditions)**\n",
    "**5. Cell 14 (Custom Simulations)**\n",
    "\n",
    "Results are automatically exported to data/05_output/ subdirectories:\n",
    "â€¢ Regular results: data/05_output/results/\n",
    "â€¢ LLM reports: data/05_output/llm_reports/\n",
    "â€¢ Configuration templates: configs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ENHANCED PIPELINE - Initialize Advanced Features\n",
    "\"\"\"PREREQUISITE: Run Section 1 (Complete Pipeline) first!\n",
    "This section adds advanced capabilities ON TOP OF the basic pipeline:\n",
    "â€¢ Financial analysis with ROI calculations\n",
    "â€¢ LLM-ready reports and summaries  \n",
    "â€¢ DWSIM-RAG integration with enhanced analytics\n",
    "â€¢ Custom configuration templates\"\"\"\n",
    "# ========================================\n",
    "\n",
    "print(\"ðŸ”§ Initializing Enhanced Pipeline Components...\")\n",
    "\n",
    "try:\n",
    "    # Force reload modules to get latest version (fixes notebook caching)\n",
    "    import importlib\n",
    "    \n",
    "    # Clear any cached modules\n",
    "    modules_to_reload = [\n",
    "        'pynucleus.integration.config_manager',\n",
    "        'pynucleus.integration.dwsim_rag_integrator', \n",
    "        'pynucleus.integration.llm_output_generator'\n",
    "    ]\n",
    "    \n",
    "    for module_name in modules_to_reload:\n",
    "        if module_name in sys.modules:\n",
    "            importlib.reload(sys.modules[module_name])\n",
    "    \n",
    "    config_manager = ConfigManager(config_dir=\"configs\")\n",
    "    dwsim_rag_integrator = DWSIMRAGIntegrator(\n",
    "    rag_pipeline=pipeline.rag_pipeline if hasattr(pipeline, 'rag_pipeline') else None,\n",
    "    results_dir=\"data/05_output/results\"\n",
    "    )\n",
    "    llm_generator = LLMOutputGenerator(results_dir=\"data/05_output/llm_reports\")\n",
    "\n",
    "    print(\"âœ… Enhanced Pipeline Ready: Configuration, Integration, LLM Output\")\n",
    "    print(f\"âœ… LLM reports will be saved to: {llm_generator.results_dir}/\")\n",
    "    enhanced_available = True\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Enhanced features not available: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    enhanced_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENHANCED PIPELINE STEP 2: Configuration Templates\n",
    "if 'enhanced_available' in locals() and enhanced_available:\n",
    "    json_template = config_manager.create_template_json(\"simulation_config_template.json\", verbose=True)\n",
    "    csv_template = config_manager.create_template_csv(\"simulation_config_template.csv\", verbose=True)\n",
    "    \n",
    "    print(\"âœ… Configuration templates created:\")\n",
    "    print(f\"   JSON: {json_template}\")\n",
    "    print(f\"   CSV: {csv_template}\")\n",
    "else:\n",
    "    print(\"âŒ Enhanced configuration not available\")\n",
    "    print(\"âš ï¸ Run Cell 10 (Enhanced Pipeline Initialization) first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENHANCED PIPELINE STEP 3: DWSIM-RAG Integration with Enhanced Analytics\n",
    "if 'enhanced_available' in locals() and enhanced_available:\n",
    "    dwsim_results = pipeline.dwsim_pipeline.get_results()\n",
    "    \n",
    "    if dwsim_results:\n",
    "        # Perform integration\n",
    "        integrated_results = dwsim_rag_integrator.integrate_simulation_results(\n",
    "            dwsim_results, perform_rag_analysis=True\n",
    "        )\n",
    "        \n",
    "        # Export results\n",
    "        integrated_export_file = dwsim_rag_integrator.export_integrated_results()\n",
    "        \n",
    "        # Show key metrics only\n",
    "        if integrated_results:\n",
    "            sample = integrated_results[0]\n",
    "            print(f\"âœ… Enhanced Analysis Complete:\")\n",
    "            print(f\"   Simulations: {len(integrated_results)}\")\n",
    "            print(f\"   Performance: {sample['performance_metrics']['overall_performance']}\")\n",
    "            print(f\"   Efficiency: {sample['performance_metrics']['efficiency_rating']}\")\n",
    "            print(f\"   Results: {integrated_export_file}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ No DWSIM results available\")\n",
    "else:\n",
    "    print(\"âŒ Enhanced integration not available\")\n",
    "    print(\"âš ï¸ Run Cell 10 (Enhanced Pipeline Initialization) first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENHANCED PIPELINE STEP 4: LLM-Ready Output with Enhanced Feed Conditions\n",
    "if 'enhanced_available' in locals() and enhanced_available and 'integrated_results' in locals():\n",
    "    print(\"ðŸ”„ Running enhanced LLM output generation with detailed feed conditions...\")\n",
    "    # Generate LLM summary for each simulation using Jinja2 template\n",
    "    llm_ready_files = []\n",
    "    for i, result in enumerate(integrated_results):\n",
    "        # Template uses original_simulation.case_name, no need to add simulation_name\n",
    "        llm_file = llm_generator.export_llm_ready_text(result)\n",
    "        llm_ready_files.append(llm_file)\n",
    "    \n",
    "    # Export financial analysis and show metrics\n",
    "    financial_file = llm_generator.export_financial_analysis(integrated_results)\n",
    "    metrics = llm_generator._calculate_key_metrics(integrated_results)\n",
    "    \n",
    "    print(f\"âœ… Analysis Reports Generated:\")\n",
    "    print(f\"   LLM Summaries: {len(llm_ready_files)} files created\")\n",
    "    for llm_file in llm_ready_files:\n",
    "        print(f\"     â€¢ {llm_file}\")\n",
    "    print(f\"   Financial Analysis: {financial_file}\")\n",
    "    print(f\"\\nðŸ’° Key Financial Metrics:\")\n",
    "    print(f\"   Recovery Rate: {metrics['avg_recovery']:.1f}%\")\n",
    "    print(f\"   Daily Revenue: ${metrics['estimated_revenue']:,.2f}\")\n",
    "    print(f\"   Daily Profit: ${metrics['net_profit']:,.2f}\")\n",
    "    print(f\"   ROI: {metrics['roi']:.1f}%\")\n",
    "    \n",
    "elif 'enhanced_available' in locals() and enhanced_available:\n",
    "    print(\"âŒ Run Cell 12 (DWSIM-RAG Integration) first to generate integrated_results\")\n",
    "else:\n",
    "    print(\"âŒ Enhanced LLM output not available\")\n",
    "    print(\"âš ï¸ Run Cell 10 (Enhanced Pipeline Initialization) first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# JINJA2 PROMPT TEMPLATE SYSTEM\n",
    "# ========================================\n",
    "\n",
    "# Simple one-line integration\n",
    "exec(open('prompts/notebook_integration.py').read())\n",
    "\n",
    "# Quick demo and validation\n",
    "demo_prompts()\n",
    "validate_prompts()\n",
    "\n",
    "# Example usage\n",
    "prompt = create_prompt(\n",
    "    question=\"What troubleshooting steps would you recommend for a distillation column showing efficiency issues?\",\n",
    "    system_msg=\"You are an expert chemical process engineer.\",\n",
    "    context=\"A distillation column is showing efficiency issues.\",\n",
    "    constraints=\"Safety first, cost-effective solutions\",\n",
    "    format_instructions=\"Provide a structured response with causes and solutions.\"\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ“‹ Example Prompt:\")\n",
    "print(\"â”€\" * 30)\n",
    "print(prompt[:200] + \"...\" if len(prompt) > 200 else prompt)\n",
    "\n",
    "print(\"\\nâœ… Prompt system ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pynucleus.llm import LLMRunner\n",
    "\n",
    "# Initialize with default model (gpt2)\n",
    "runner = LLMRunner()\n",
    "\n",
    "# Generate text with custom parameters\n",
    "response = runner.ask(\n",
    "    \"The future of artificial intelligence\",\n",
    "    max_length=50,\n",
    "    temperature=0.7,\n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "# Get model information\n",
    "info = runner.get_model_info()\n",
    "print(f\"Model: {info['model_id']}, Vocab: {info['vocab_size']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ========================================\n",
    "# # VERSION CONTROL (Optional - For Maintainers Only)\n",
    "# # ========================================\n",
    "# # Uncomment the lines below if you need to update the repository:\n",
    "\n",
    "# from datetime import datetime\n",
    "\n",
    "# # Log end time\n",
    "# with open(\"update_log.txt\", \"a\") as f:\n",
    "#     f.write(f\"\\n {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} changes made and pushed to origin main\\n\")\n",
    "\n",
    "# # Simple GitHub update function\n",
    "# def update_github():\n",
    "#     print(\" Starting GitHub update...\")\n",
    "#     !git add .\n",
    "#     print(\"ðŸ“¦ Files added to staging\")\n",
    "#     !git commit -m \"Update: $(date +'%Y-%m-%d %H:%M:%S')\"\n",
    "#     print(\"ðŸ’¾ Changes committed\")\n",
    "#     !git push origin main\n",
    "#     print(\"âœ… Changes pushed to GitHub successfully!\")\n",
    "\n",
    "# # To use it, just run:\n",
    "# update_github()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
