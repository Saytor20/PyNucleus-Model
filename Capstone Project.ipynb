{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# **PyNucleus Model - User Interface**\n",
        "\n",
        "## **Welcome to PyNucleus!** ðŸš€\n",
        "\n",
        "This notebook provides a simple interface to run the PyNucleus pipeline for chemical process analysis.\n",
        "\n",
        "### **What PyNucleus Does:**\n",
        "- **ðŸ“š Document Analysis**: Processes chemical engineering documents using RAG (Retrieval-Augmented Generation)\n",
        "- **ðŸ”¬ DWSIM Simulations**: Runs chemical process simulations with predefined scenarios\n",
        "- **ðŸ“Š Results Export**: Automatically exports results to CSV files for analysis\n",
        "- **ðŸ’¡ LLM Integration**: Generates intelligent summaries and reports\n",
        "\n",
        "### **How to Use This Notebook:**\n",
        "1. **Run Cell 1**: Initialize the system\n",
        "2. **Run Cell 2**: Execute the complete pipeline\n",
        "3. **Run Cell 3**: View your results\n",
        "\n",
        "**âš¡ That's it! The system handles everything automatically.**\n",
        "\n",
        "---\n",
        "**ðŸ’¡ For developers**: Advanced features and diagnostics are available in `Developer_Notebook.ipynb`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ”§ Initializing PyNucleus Model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ”§ Setting up RAG imports...\n",
            "Warning: wikipedia package not available. Wikipedia scraping disabled.\n",
            "âœ… RAG imports ready!\n",
            "ðŸ”§ Setting up DWSIM imports...\n",
            "âœ… DWSIM modules imported successfully\n",
            "ðŸ“ Results directory: data/05_output/results\n",
            "ðŸ”§ Pipeline Utils initialized with results dir: data/05_output/results\n",
            "ðŸ”— DWSIM-RAG integration enabled\n",
            "âœ… PyNucleus Model initialized successfully!\n",
            "ðŸ“‹ System Ready:\n",
            "   â€¢ RAG Pipeline - Document processing and retrieval\n",
            "   â€¢ DWSIM Pipeline - Chemical process simulation\n",
            "   â€¢ Results Export - CSV and report generation\n",
            "   â€¢ LLM Integration - Intelligent analysis and summaries\n",
            "\n",
            "ðŸŽ¯ Ready to run analysis! Execute Cell 2 to start.\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: System Initialization\n",
        "# ===================================\n",
        "# This cell sets up PyNucleus and prepares all components\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"ðŸ”§ Initializing PyNucleus Model...\")\n",
        "\n",
        "# Add src to Python path\n",
        "src_path = str(Path().resolve() / \"src\")\n",
        "if src_path not in sys.path:\n",
        "    sys.path.insert(0, src_path)\n",
        "\n",
        "try:\n",
        "    # Import PyNucleus components\n",
        "    from pynucleus.pipeline import PipelineUtils\n",
        "    from pynucleus.integration.llm_output_generator import LLMOutputGenerator\n",
        "    \n",
        "    # Initialize pipeline\n",
        "    pipeline = PipelineUtils(results_dir=\"data/05_output/results\")\n",
        "    llm_generator = LLMOutputGenerator(results_dir=\"data/05_output/reports\")\n",
        "    \n",
        "    print(\"âœ… PyNucleus Model initialized successfully!\")\n",
        "    print(\"ðŸ“‹ System Ready:\")\n",
        "    print(\"   â€¢ RAG Pipeline - Document processing and retrieval\")\n",
        "    print(\"   â€¢ DWSIM Pipeline - Chemical process simulation\")\n",
        "    print(\"   â€¢ Results Export - CSV and report generation\")\n",
        "    print(\"   â€¢ LLM Integration - Intelligent analysis and summaries\")\n",
        "    print(\"\\nðŸŽ¯ Ready to run analysis! Execute Cell 2 to start.\")\n",
        "    \n",
        "except ImportError as e:\n",
        "    print(f\"âŒ Import Error: {e}\")\n",
        "    print(\"ðŸ’¡ Please ensure you're in the PyNucleus-Model directory\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Initialization Error: {e}\")\n",
        "    print(\"ðŸ’¡ Please check your system setup\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: Run Complete Analysis\n",
        "# ===================================\n",
        "# This cell runs the complete PyNucleus pipeline\n",
        "\n",
        "print(\"ðŸš€ Starting Complete PyNucleus Analysis...\")\n",
        "print(\"\\nðŸ“Š This will run:\")\n",
        "print(\"   1. Document processing and RAG analysis\")\n",
        "print(\"   2. DWSIM chemical process simulations\")\n",
        "print(\"   3. Results export and report generation\")\n",
        "print(\"\\nâ³ Please wait... This may take 20-30 seconds.\\n\")\n",
        "\n",
        "try:\n",
        "    # Run the complete pipeline\n",
        "    results = pipeline.run_complete_pipeline()\n",
        "    \n",
        "    if results:\n",
        "        print(f\"\\nðŸŽ‰ Analysis completed successfully in {results['duration']:.1f} seconds!\")\n",
        "        print(\"\\nðŸ“Š Results Summary:\")\n",
        "        print(f\"   â€¢ Documents Processed: {len(results['rag_data'])} queries\")\n",
        "        print(f\"   â€¢ Simulations Completed: {len(results['dwsim_data'])} scenarios\")\n",
        "        print(f\"   â€¢ Files Generated: {len(results['exported_files'])} CSV files\")\n",
        "        \n",
        "        # Generate enhanced reports if available\n",
        "        try:\n",
        "            from pynucleus.integration.dwsim_rag_integrator import DWSIMRAGIntegrator\n",
        "            \n",
        "            integrator = DWSIMRAGIntegrator(\n",
        "                rag_pipeline=pipeline.rag_pipeline,\n",
        "                results_dir=\"data/05_output/results\"\n",
        "            )\n",
        "            \n",
        "            # Enhanced analysis\n",
        "            dwsim_results = pipeline.dwsim_pipeline.get_results()\n",
        "            if dwsim_results:\n",
        "                enhanced_results = integrator.integrate_simulation_results(\n",
        "                    dwsim_results, perform_rag_analysis=True\n",
        "                )\n",
        "                \n",
        "                # Generate LLM reports\n",
        "                report_files = []\n",
        "                for result in enhanced_results[:3]:  # Generate reports for first 3 simulations\n",
        "                    report_file = llm_generator.export_llm_ready_text(result)\n",
        "                    report_files.append(report_file)\n",
        "                \n",
        "                # Financial analysis\n",
        "                financial_file = llm_generator.export_financial_analysis(enhanced_results)\n",
        "                metrics = llm_generator._calculate_key_metrics(enhanced_results)\n",
        "                \n",
        "                print(\"\\nðŸ’° Financial Analysis:\")\n",
        "                print(f\"   â€¢ Recovery Rate: {metrics['avg_recovery']:.1f}%\")\n",
        "                print(f\"   â€¢ Daily Revenue: ${metrics['estimated_revenue']:,.2f}\")\n",
        "                print(f\"   â€¢ Daily Profit: ${metrics['net_profit']:,.2f}\")\n",
        "                print(f\"   â€¢ ROI: {metrics['roi']:.1f}%\")\n",
        "                \n",
        "                print(f\"\\nðŸ“„ Generated Reports: {len(report_files)} detailed analysis files\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(\"âš ï¸ Enhanced analysis unavailable (using basic results only)\")\n",
        "        \n",
        "        print(\"\\nðŸ“ All results saved to:\")\n",
        "        print(\"   â€¢ CSV Files: data/05_output/results/\")\n",
        "        print(\"   â€¢ Reports: data/05_output/reports/\")\n",
        "        print(\"\\nâœ… Analysis complete! Run Cell 3 to explore your results.\")\n",
        "        \n",
        "    else:\n",
        "        print(\"âŒ Pipeline execution failed\")\n",
        "        print(\"ðŸ’¡ Please check your data directories and try again\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error during analysis: {e}\")\n",
        "    print(\"ðŸ’¡ Please ensure all components are properly initialized\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: View Results and Summary\n",
        "# ===================================\n",
        "# This cell displays your results and provides access to files\n",
        "\n",
        "print(\"ðŸ“Š PyNucleus Results Dashboard\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "try:\n",
        "    # Quick status check\n",
        "    status = pipeline.quick_test()\n",
        "    \n",
        "    print(f\"ðŸ“ Results Directory: {status['results_dir']}\")\n",
        "    print(f\"ðŸ“„ CSV Files Found: {status['csv_files_count']}\")\n",
        "    \n",
        "    if status['csv_files_count'] > 0:\n",
        "        print(\"\\nðŸ“‹ Available Files:\")\n",
        "        for file_info in status['csv_files']:\n",
        "            print(f\"   â€¢ {file_info['name']} ({file_info['size']} bytes)\")\n",
        "    \n",
        "    # Display detailed summary\n",
        "    print(\"\\n\" + \"=\" * 40)\n",
        "    pipeline.view_results_summary()\n",
        "    \n",
        "    print(\"\\nðŸ”§ Additional Options:\")\n",
        "    print(\"   â€¢ Re-run Cell 2 to generate new results\")\n",
        "    print(\"   â€¢ Check data/05_output/ folder for all generated files\")\n",
        "    print(\"   â€¢ View Developer_Notebook.ipynb for advanced features\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error viewing results: {e}\")\n",
        "    print(\"ðŸ’¡ Please run Cell 2 first to generate results\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "\n",
        "## **Optional: Individual Components**\n",
        "\n",
        "The cells below allow you to run specific parts of the pipeline individually if needed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional Cell 4A: Run Only Document Analysis (RAG)\n",
        "# ====================================================\n",
        "# Uncomment and run this cell if you only want document processing\n",
        "\n",
        "# print(\"ðŸ“š Running Document Analysis Only...\")\n",
        "# rag_results = pipeline.run_rag_only()\n",
        "# if rag_results:\n",
        "#     print(f\"âœ… Processed {len(rag_results['rag_data'])} document queries\")\n",
        "#     print(\"ðŸ“ Results saved to data/05_output/results/\")\n",
        "# else:\n",
        "#     print(\"âŒ Document analysis failed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional Cell 4B: Run Only Chemical Simulations (DWSIM)\n",
        "# =======================================================\n",
        "# Uncomment and run this cell if you only want DWSIM simulations\n",
        "\n",
        "# print(\"ðŸ”¬ Running Chemical Simulations Only...\")\n",
        "# dwsim_results = pipeline.run_dwsim_only()\n",
        "# if dwsim_results:\n",
        "#     print(f\"âœ… Completed {len(dwsim_results['dwsim_data'])} simulations\")\n",
        "#     print(\"ðŸ“ Results saved to data/05_output/results/\")\n",
        "# else:\n",
        "#     print(\"âŒ Chemical simulations failed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional Cell 5: Clean Up Results\n",
        "# =================================\n",
        "# Uncomment and run this cell to clear all previous results\n",
        "\n",
        "# print(\"ðŸ—‘ï¸ Cleaning up previous results...\")\n",
        "# pipeline.clean_all_results()\n",
        "# print(\"âœ… All results cleared. You can now run a fresh analysis.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Starting GitHub update...\n",
            " Files added to staging\n",
            "[main 8b35bae] Update: 2025-06-13 18:02:11\n",
            " 72 files changed, 16393 insertions(+), 3005 deletions(-)\n",
            " create mode 100644 backups/backup_20250612_163726/data/01_raw/source_documents/Bist_Madan.pdf\n",
            " create mode 100644 backups/backup_20250612_163726/data/01_raw/source_documents/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.docx\n",
            " create mode 100644 backups/backup_20250612_163726/data/01_raw/source_documents/feasibility_factors.txt\n",
            " create mode 100644 backups/backup_20250612_163726/data/01_raw/source_documents/mcp_basics.txt\n",
            " create mode 100644 backups/backup_20250612_163726/data/01_raw/web_sources/wikipedia_industrial_design.txt\n",
            " create mode 100644 backups/backup_20250612_163726/data/01_raw/web_sources/wikipedia_modular_design.txt\n",
            " create mode 100644 backups/backup_20250612_163726/data/01_raw/web_sources/wikipedia_software_architecture.txt\n",
            " create mode 100644 backups/backup_20250612_163726/data/01_raw/web_sources/wikipedia_supply_chain.txt\n",
            " create mode 100644 backups/backup_20250612_163726/data/01_raw/web_sources/wikipedia_system_design.txt\n",
            " create mode 100644 backups/backup_20250612_163726/data/02_processed/converted_to_txt/Bist_Madan.txt\n",
            " create mode 100644 backups/backup_20250612_163726/data/02_processed/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
            " create mode 100644 backups/backup_20250612_163726/data/02_processed/converted_to_txt/feasibility_factors.txt\n",
            " create mode 100644 backups/backup_20250612_163726/data/02_processed/converted_to_txt/mcp_basics.txt\n",
            " create mode 100644 backups/backup_20250612_163726/data/03_intermediate/converted_chunked_data/chunked_data_content.txt\n",
            " create mode 100644 backups/backup_20250612_163726/data/03_intermediate/converted_chunked_data/chunked_data_full.json\n",
            " create mode 100644 backups/backup_20250612_163726/data/03_intermediate/converted_chunked_data/chunked_data_stats.json\n",
            " create mode 100644 backups/backup_20250612_163726/data/04_models/chunk_reports/embeddings.pkl\n",
            " create mode 100644 backups/backup_20250612_163726/data/04_models/chunk_reports/faiss_analysis_20250611_211950.txt\n",
            " create mode 100644 backups/backup_20250612_163726/data/04_models/chunk_reports/faiss_analysis_20250611_222659.txt\n",
            " create mode 100644 backups/backup_20250612_163726/data/04_models/chunk_reports/faiss_analysis_20250611_223025.txt\n",
            " create mode 100644 backups/backup_20250612_163726/data/04_models/chunk_reports/faiss_analysis_20250611_223039.txt\n",
            " create mode 100644 backups/backup_20250612_163726/data/04_models/chunk_reports/faiss_analysis_20250611_225943.txt\n",
            " create mode 100644 backups/backup_20250612_163726/data/04_models/chunk_reports/pynucleus_mcp.faiss/index.faiss\n",
            " create mode 100644 backups/backup_20250612_163726/data/04_models/chunk_reports/pynucleus_mcp.faiss/index.pkl\n",
            " create mode 100644 backups/backup_20250612_163726/data/05_output/llm_reports/absorber_co2_capture_summary.md\n",
            " create mode 100644 backups/backup_20250612_163726/data/05_output/llm_reports/crystallizer_salt_summary.md\n",
            " create mode 100644 backups/backup_20250612_163726/data/05_output/llm_reports/distillation_ethanol_water_summary.md\n",
            " create mode 100644 backups/backup_20250612_163726/data/05_output/llm_reports/heat_exchanger_steam_summary.md\n",
            " create mode 100644 backups/backup_20250612_163726/data/05_output/llm_reports/reactor_methane_combustion_summary.md\n",
            " create mode 100644 backups/backup_20250612_163726/data/05_output/llm_reports/system_test_distillation_summary.md\n",
            " create mode 100644 backups/backup_20250612_163726/data/05_output/results/dwsim_simulation_results.csv\n",
            " create mode 100644 backups/backup_20250612_163726/data/05_output/results/dwsim_summary.csv\n",
            " create mode 100644 backups/backup_20250612_163726/data/05_output/results/integrated_dwsim_rag_results_20250611_212019.json\n",
            " create mode 100644 backups/backup_20250612_163726/data/05_output/results/integrated_dwsim_rag_results_20250611_222716.json\n",
            " create mode 100644 backups/backup_20250612_163726/data/05_output/results/integrated_dwsim_rag_results_20250611_223030.json\n",
            " create mode 100644 backups/backup_20250612_163726/data/05_output/results/integrated_dwsim_rag_results_20250611_223045.json\n",
            " create mode 100644 backups/backup_20250612_163726/data/05_output/results/integrated_dwsim_rag_results_20250611_225959.json\n",
            " create mode 100644 backups/backup_20250612_163726/dwsim_libs/CapeOpen.dll\n",
            " create mode 100644 backups/backup_20250612_163726/dwsim_libs/DWSIM.Automation.dll\n",
            " create mode 100644 backups/backup_20250612_163726/dwsim_libs/DWSIM.GlobalSettings.dll\n",
            " create mode 100644 backups/backup_20250612_163726/dwsim_libs/DWSIM.Interfaces.dll\n",
            " create mode 100644 backups/backup_20250612_163726/dwsim_libs/DWSIM.Thermodynamics.dll\n",
            " create mode 100644 backups/backup_20250612_163726/dwsim_libs/DWSIM.UnitOperations.dll\n",
            " delete mode 100644 docs/project_info/DIRECTORY_RENAME_SUMMARY.md\n",
            " delete mode 100644 docs/project_info/DWSIM_CLEANUP_SUMMARY.md\n",
            " delete mode 100644 docs/project_info/LOCAL_TESTING_REPORT.md\n",
            " delete mode 100644 docs/project_info/PROJECT_STRUCTURE.md\n",
            " create mode 100644 logs/diagnostic_report_20250612_163754.txt\n",
            " create mode 100644 logs/diagnostic_report_20250612_164154.txt\n",
            " create mode 100644 logs/system_diagnostic_20250612_163754.log\n",
            " create mode 100644 logs/system_diagnostic_20250612_164154.log\n",
            " create mode 100644 logs/system_validation_20250612_163805.log\n",
            " create mode 100644 logs/system_validation_report_20250612_163805.txt\n",
            " delete mode 100644 test_llm_fix.py\n",
            " Changes committed\n",
            "Enumerating objects: 122, done.\n",
            "Counting objects: 100% (122/122), done.\n",
            "Delta compression using up to 8 threads\n",
            "Compressing objects: 100% (86/86), done.\n",
            "Writing objects: 100% (90/90), 82.42 MiB | 2.54 MiB/s, done.\n",
            "Total 90 (delta 42), reused 0 (delta 0), pack-reused 0 (from 0)\n",
            "remote: Resolving deltas: 100% (42/42), completed with 22 local objects.\u001b[K\n",
            "remote: \u001b[1;33mwarning\u001b[m: See https://gh.io/lfs for more information.\u001b[K\n",
            "remote: \u001b[1;33mwarning\u001b[m: File backups/backup_20250612_163726/data/04_models/chunk_reports/embeddings.pkl is 87.16 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB\u001b[K\n",
            "remote: \u001b[1;33mwarning\u001b[m: GH001: Large files detected. You may want to try Git Large File Storage - https://git-lfs.github.com.\u001b[K\n",
            "To https://github.com/Saytor20/PyNucleus-Model.git\n",
            "   d38b2a1..8b35bae  main -> main\n",
            " Changes pushed to GitHub successfully!\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# VERSION CONTROL (Optional - For Maintainers Only)\n",
        "# ========================================\n",
        "# Uncomment the lines below if you need to update the repository:\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "# Log end time\n",
        "with open(\"update_log.txt\", \"a\") as f:\n",
        "    f.write(f\"\\n {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} changes made and pushed to origin main\\n\")\n",
        "\n",
        "# Simple GitHub update function\n",
        "def update_github():\n",
        "    print(\" Starting GitHub update...\")\n",
        "    !git add .\n",
        "    print(\" Files added to staging\")\n",
        "    !git commit -m \"Update: $(date +'%Y-%m-%d %H:%M:%S')\"\n",
        "    print(\" Changes committed\")\n",
        "    !git push origin main\n",
        "    print(\" Changes pushed to GitHub successfully!\")\n",
        "\n",
        "# To use it, just run:\n",
        "update_github()"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "\n",
        "## **Need More Features?**\n",
        "\n",
        "ðŸ”§ **For Developers**: Advanced features, debugging, and system diagnostics are available in:\n",
        "- `Developer_Notebook.ipynb` - Full development environment\n",
        "- `scripts/comprehensive_system_diagnostic.py` - System health checks\n",
        "\n",
        "ðŸ“š **Documentation**: Check the `docs/` folder for detailed guides:\n",
        "- `README.md` - Complete setup and usage guide\n",
        "- `docs/ENHANCED_PIPELINE_SUMMARY.md` - Advanced features overview\n",
        "- `docs/project_info/` - Technical documentation\n",
        "\n",
        "ðŸ’¡ **Support**: For issues or questions, check the project documentation or create an issue in the repository.\n",
        "\n",
        "---\n",
        "\n",
        "**ðŸŽ‰ Thank you for using PyNucleus!**\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
