{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":26,"metadata":{"id":"pxJK6GpyVui7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"288540bd-a241-43e1-8a9f-3893b7807d28","executionInfo":{"status":"ok","timestamp":1748913633990,"user_tz":240,"elapsed":1094,"user":{"displayName":"Mohammad A.","userId":"15199683412159334052"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Commented out IPython magic to ensure Python compatibility.\n","from google.colab import drive,userdata\n","import os\n","from datetime import datetime\n","\n","drive.mount('/content/drive')\n","notebook_drive_path = \"/content/drive/MyDrive/PyNucleus Project/Capstone Project.ipynb\"\n","notebook_filename_in_repo = \"Capstone Project.ipynb\"\n","log_filename = \"update_log.txt\"\n","\n","# GitHub details\n","GITHUB_USERNAME = userdata.get('GITHUB_USERNAME')\n","GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n","REPOSITORY_NAME = 'PyNucleus-Model'\n","REPO_PATH = f\"/content/drive/MyDrive/{REPOSITORY_NAME}\"\n"]},{"cell_type":"code","source":["# --- CLONE REPOSITORY OR SYNC IF IT EXISTS ---\n","if not os.path.exists(REPO_PATH):\n","    print(f\"Cloning {REPOSITORY_NAME} repository into your Google Drive...\")\n","    # Clone directly into the full REPO_PATH\n","    !git clone {repository_url} {REPO_PATH}\n","else:\n","    print(\"Repository already exists in Drive. Syncing with GitHub...\")\n","    # If it exists, we don't need to do anything here,\n","    # because the commands after this block will handle it.\n","\n","# --- NAVIGATE INTO REPO, PULL, & CONFIGURE ---\n","# This ensures we are in the right place, regardless of if we just cloned or not.\n","%cd {REPO_PATH}\n","print(\"Pulling latest changes to ensure we are up-to-date...\")\n","!git pull\n","\n","print(\"\\nConfiguring Git user for this session...\")\n","!git config user.name \"{GITHUB_USERNAME}\"\n","!git config user.email \"{GITHUB_USERNAME}@users.noreply.github.com\"\n","\n","print(f\"\\n Setup complete. You are ready to work. Current directory: {os.getcwd()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qqy1ABswnFgQ","executionInfo":{"status":"ok","timestamp":1748913635230,"user_tz":240,"elapsed":1232,"user":{"displayName":"Mohammad A.","userId":"15199683412159334052"}},"outputId":"6be1cca8-e38d-44cd-c931-eac041426cd3"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Repository already exists in Drive. Syncing with GitHub...\n","/content/drive/MyDrive/PyNucleus-Model\n","Pulling latest changes to ensure we are up-to-date...\n","Already up to date.\n","\n","Configuring Git user for this session...\n","\n"," Setup complete. You are ready to work. Current directory: /content/drive/MyDrive/PyNucleus-Model\n"]}]},{"cell_type":"code","source":["# # --- Installation Cell (Run this ONCE per session) ---\n","# print(\"Installing all required packages...\")\n","\n","# # Core LangChain and Community Packages\n","# !pip install -q langchain langchain-core langchain-community langchain-text-splitters\n","\n","# # Document Loading & Processing (Unstructured handles many file types including OCR)\n","# !pip install -q \"unstructured[local-inference]\"\n","\n","# # LLM & ML Libraries\n","# !pip install -q transformers accelerate bitsandbytes torch sentence-transformers\n","\n","# # Vector Stores\n","# !pip install -q chromadb faiss-cpu # faiss-gpu if you have a Pro Colab with a good GPU\n","\n","# # Data Handling & Utilities\n","# !pip install -q pandas numpy tqdm PyYAML\n","\n","# print(\"All packages installed successfully.\")"],"metadata":{"id":"DfNy6HlnOsXc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748913657330,"user_tz":240,"elapsed":22095,"user":{"displayName":"Mohammad A.","userId":"15199683412159334052"}},"outputId":"4ef191cb-9367-49fc-992f-0343949a8744"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Installing all required packages...\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0mAll packages installed successfully.\n"]}]},{"cell_type":"code","source":["# --- Core Utilities & File Handling ---\n","import getpass\n","import yaml # Make sure PyYAML is installed\n","from pathlib import Path\n","\n","# --- Data Handling & Progress Bars ---\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","\n","# --- Document Loading ---\n","# UnstructuredFileLoader is now in langchain_community\n","from langchain_community.document_loaders import UnstructuredFileLoader\n","# For future testing of more specific loaders:\n","# from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader\n","\n","# --- OCR Libraries ---\n","# No direct imports needed here if using UnstructuredFileLoader with local-inference,\n","# as it handles OCR internally.\n","# You would only import these for a manual OCR process:\n","# import pytesseract\n","# from pdf2image import convert_from_path\n","# from PIL import Image\n","\n","# --- Core ML & LLM Libraries ---\n","import torch\n","import transformers\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","import bitsandbytes\n","import accelerate # Often used with transformers\n","\n","# --- Vector Stores & Embeddings ---\n","# Using ChromaDB as the primary vector store.\n","import chromadb\n","from langchain_community.vectorstores import Chroma # Chroma is now in langchain_community\n","from langchain_community.embeddings import HuggingFaceEmbeddings # Embeddings are also in langchain_community\n","# For future testing of a high-performance alternative:\n","# import faiss\n","# from langchain_community.vectorstores import FAISS\n","\n","# --- RAG/Agent Frameworks ---\n","# Core LangChain components\n","import langchain\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.output_parsers import StrOutputParser\n","# For future testing of an alternative RAG-focused toolkit:\n","# from llama_index.core import SimpleDirectoryReader, VectorStoreIndex"],"metadata":{"id":"BPyfUDJoDjgn","executionInfo":{"status":"ok","timestamp":1748913657357,"user_tz":240,"elapsed":24,"user":{"displayName":"Mohammad A.","userId":"15199683412159334052"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["# **Data Ingestion and Preprocessing for RAG**"],"metadata":{"id":"OL-SmhSQQ_21"}},{"cell_type":"code","source":[],"metadata":{"id":"I69992m0RE82","executionInfo":{"status":"ok","timestamp":1748913657359,"user_tz":240,"elapsed":1,"user":{"displayName":"Mohammad A.","userId":"15199683412159334052"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["# This is the last cell of the code"],"metadata":{"id":"hISFF6TUEB_H"}},{"cell_type":"code","source":["\n","# --- CREATE/UPDATE THE LOG FILE ---\n","# This will add a new line to your log file with the current date and time.\n","log_message = f\"Notebook saved on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n","with open(log_filename, \"a\") as f:\n","    f.write(log_message + \"\\n\")\n","print(f\"Updated '{log_filename}'\")\n","\n","# --- COPY YOUR NOTEBOOK FROM DRIVE INTO THE REPO ---\n","print(f\"Copying '{notebook_filename_in_repo}' from Google Drive...\")\n","!cp \"{notebook_drive_path}\" \"{notebook_filename_in_repo}\"\n","\n","# --- ADD, COMMIT, AND PUSH BOTH FILES ---\n","print(\"Staging files for commit...\")\n","# Add BOTH the notebook and the log file to Git\n","!git add \"{log_filename}\"\n","!git add \"{notebook_filename_in_repo}\"\n","\n","# Create a commit message\n","commit_message = f\"Update project notebook and log file - {datetime.now().strftime('%Y-%m-%d')}\"\n","print(f\"Committing with message: '{commit_message}'\")\n","!git commit -m \"{commit_message}\"\n","\n","print(\"\\nPushing changes to GitHub...\")\n","!git push origin main\n","\n","print(\"\\n SUCCESS! Your notebook and log file have been updated on GitHub.\")"],"metadata":{"id":"tjThfmG7EDzG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748913660170,"user_tz":240,"elapsed":2811,"user":{"displayName":"Mohammad A.","userId":"15199683412159334052"}},"outputId":"25dea1e4-c1de-4750-8fdd-189cc96ef9c4"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Updated 'update_log.txt'\n","Copying 'Capstone Project.ipynb' from Google Drive...\n","Staging files for commit...\n","Committing with message: 'Update project notebook and log file - 2025-06-03'\n","[main e881e41] Update project notebook and log file - 2025-06-03\n"," 1 file changed, 1 insertion(+)\n","\n","Pushing changes to GitHub...\n","Enumerating objects: 5, done.\n","Counting objects: 100% (5/5), done.\n","Delta compression using up to 2 threads\n","Compressing objects: 100% (3/3), done.\n","Writing objects: 100% (3/3), 327 bytes | 54.00 KiB/s, done.\n","Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\n","remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n","To https://github.com/Saytor20/PyNucleus-Model.git\n","   b8bdc5a..e881e41  main -> main\n","\n"," SUCCESS! Your notebook and log file have been updated on GitHub.\n"]}]}]}