{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from datetime import datetime\n",
    "# from dotenv import load_dotenv\n",
    "# #\n",
    "# # #--------Google Drive Integration--------#\n",
    "# # # from google.colab import drive, userdata\n",
    "# # # This gives Colab access to your files in Google Drive.\n",
    "# # # drive.mount('/content/drive')\n",
    "# # # 'GITHUB_USERNAME' and 'GITHUB_TOKEN' saved as secrets in Colab.\n",
    "# # GITHUB_USERNAME = userdata.get('GITHUB_USERNAME')\n",
    "# # GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n",
    "# # REPOSITORY_NAME = 'PyNucleus-Model' # Your repository name\n",
    "# # NOTEBOOK_DRIVE_PATH = \"/content/drive/MyDrive/PyNucleus Project/Capstone Project.ipynb\"\n",
    "# #\n",
    "# #\n",
    "# # #--------Cursor Integration--------#\n",
    "# # # Load environment variables from .env file\n",
    "# load_dotenv()\n",
    "# #\n",
    "# # # Get GitHub credentials from environment variables\n",
    "# GITHUB_USERNAME = os.getenv('GITHUB_USERNAME')\n",
    "# GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')\n",
    "# #\n",
    "# # # Print to verify the variables are loaded (remove this in production)\n",
    "# print(f\"Username: {GITHUB_USERNAME}\")\n",
    "# print(f\"Token: {GITHUB_TOKEN[:4]}...\") # Only print first 4 chars of token for security\n",
    "# #\n",
    "# # Repository information\n",
    "# REPOSITORY_NAME = 'PyNucleus-Model'\n",
    "# NOTEBOOK_REPO_FILENAME = \"Capstone Project.ipynb\"\n",
    "# LOG_FILENAME = \"update_log.txt\"\n",
    "\n",
    "# # Pull latest changes from GitHub\n",
    "# print(\"Pulling latest changes from GitHub...\")\n",
    "# !git pull https://{GITHUB_TOKEN}@github.com/{GITHUB_USERNAME}/{REPOSITORY_NAME}.git main\n",
    "\n",
    "# print(\"Repository is up to date!\")\n",
    "\n",
    "# # Log start time\n",
    "# with open(\"update_log.txt\", \"a\") as f:\n",
    "#     f.write(f\" {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}: Log Update\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21621,
     "status": "ok",
     "timestamp": 1748965189264,
     "user": {
      "displayName": "Mohammad A.",
      "userId": "15199683412159334052"
     },
     "user_tz": 240
    },
    "id": "pxJK6GpyVui7",
    "outputId": "5fcaf74f-4292-4847-fb37-57d1c0d9a971"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PyNucleus Model - Pipeline Ready!\n",
      " Available Components:\n",
      "   ‚Ä¢ RAGPipeline - Document processing and retrieval\n",
      "   ‚Ä¢ DWSIMPipeline - Chemical process simulation\n",
      "   ‚Ä¢ ResultsExporter - CSV export functionality\n",
      "   ‚Ä¢ PipelineUtils - Complete pipeline orchestration\n"
     ]
    }
   ],
   "source": [
    "# PyNucleus Model - Setup and Imports\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append(os.path.abspath('.'))\n",
    "\n",
    "# Import PyNucleus Pipeline modules\n",
    "from core_modules.pipeline import RAGPipeline, DWSIMPipeline, ResultsExporter, PipelineUtils\n",
    "\n",
    "print(\" PyNucleus Model - Pipeline Ready!\")\n",
    "print(\" Available Components:\")\n",
    "print(\"   ‚Ä¢ RAGPipeline - Document processing and retrieval\")\n",
    "print(\"   ‚Ä¢ DWSIMPipeline - Chemical process simulation\") \n",
    "print(\"   ‚Ä¢ ResultsExporter - CSV export functionality\")\n",
    "print(\"   ‚Ä¢ PipelineUtils - Complete pipeline orchestration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84DXL9QuH0Tx"
   },
   "source": [
    "# **PyNucleus Model - Complete Pipeline**\n",
    "\n",
    "This notebook contains the complete PyNucleus model pipeline with separate sections for:\n",
    "1. **Data Ingestion and Preprocessing for RAG** \n",
    "2. **DWSIM Integration and Simulation**\n",
    "3. **Results Export to CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Pipeline Components\n",
    "pipeline = PipelineUtils()\n",
    "\n",
    "print(\"\\nüîß Pipeline Initialized!\")\n",
    "print(\"Available Functions:\")\n",
    "print(\"   ‚Ä¢ pipeline.run_complete_pipeline() - Run everything\")\n",
    "print(\"   ‚Ä¢ pipeline.run_rag_only() - RAG pipeline only\")  \n",
    "print(\"   ‚Ä¢ pipeline.run_dwsim_only() - DWSIM simulations only\")\n",
    "print(\"   ‚Ä¢ pipeline.quick_test() - Verify status\")\n",
    "print(\"   ‚Ä¢ pipeline.view_results_summary() - View results\")\n",
    "print(\"   ‚Ä¢ pipeline.print_pipeline_status() - Detailed status\")\n",
    "print(\"   ‚Ä¢ pipeline.clean_all_results() - Clean all data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Running complete PyNucleus pipeline...\n",
      "üóëÔ∏è RAG results cleared.\n",
      "üóëÔ∏è DWSIM results cleared.\n",
      "üìö Starting RAG Pipeline...\n",
      "Step 1: Processing source documents...\n",
      "--- üìÑ Starting processing for 5 file(s) in '/Users/mohammadalmusaiteer/PyNucleus-Model/source_documents' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   0%|          | 0/5 [00:00<?, ?it/s]WARNING: libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "WARNING: libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ‚ñ∂ Processing: Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.docx\n",
      "   ‚Ä¢ Success! Saved to: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      " ‚ñ∂ Processing: mcp_basics.txt\n",
      "   ‚Ä¢ Success! Saved to: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/mcp_basics.txt\n",
      " ‚ñ∂ Processing: feasibility_factors.txt\n",
      "   ‚Ä¢ Success! Saved to: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/feasibility_factors.txt\n",
      " ‚ñ∂ Processing: Bist_Madan.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00,  8.79it/s]WARNING: libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "Processing files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 10.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚Ä¢ Success! Saved to: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/Bist_Madan.txt\n",
      " ‚ñ∂ Processing: sample_document.txt\n",
      "   ‚Ä¢ Success! Saved to: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/sample_document.txt\n",
      "\n",
      " All files processed.\n",
      "\n",
      "Step 2: Scraping Wikipedia articles...\n",
      "üîç Starting Wikipedia article search for 5 keywords...\n",
      "‚ñ∂Ô∏è  Searching for: modular design\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_modular_design.txt\n",
      "‚ñ∂Ô∏è  Searching for: software architecture\n",
      "‚úÖ  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_software_architecture.txt\n",
      "‚ñ∂Ô∏è  Searching for: system design\n",
      "‚úÖ  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_system_design.txt\n",
      "‚ñ∂Ô∏è  Searching for: industrial design\n",
      "‚úÖ  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_industrial_design.txt\n",
      "‚ñ∂Ô∏è  Searching for: supply chain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ  Saved article to: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_supply_chain.txt\n",
      "\n",
      "‚ú® Article scraping complete!\n",
      "\n",
      "Step 3: Processing and chunking documents...\n",
      "üì∞ Found 5 Wikipedia articles\n",
      "üìÑ Found 5 converted documents\n",
      "üìã Total documents loaded: 10\n",
      "‚úÇÔ∏è Split into 846 chunks\n",
      "\n",
      "‚úÖ Successfully saved chunked data to /Users/mohammadalmusaiteer/PyNucleus-Model/converted_chunked_data/:\n",
      "  ‚Ä¢ chunked_data_full.json - Complete data with metadata\n",
      "  ‚Ä¢ chunked_data_stats.json - Statistical analysis\n",
      "  ‚Ä¢ chunked_data_content.txt - Human-readable content\n",
      "\n",
      "\n",
      "Step 4: Building FAISS vector store...\n",
      "=== FAISS VectorDB Analysis ===\n",
      "Started: 2025-06-10 16:07:26\n",
      "Loaded 846 documents from /Users/mohammadalmusaiteer/PyNucleus-Model/converted_chunked_data/chunked_data_full.json\n",
      "Embedding device ‚Üí cpu   | dim=384\n",
      "Docs indexed : 846\n",
      "Index file   : /Users/mohammadalmusaiteer/PyNucleus-Model/chunk_reports/pynucleus_mcp.faiss\n",
      "Embeds .pkl  : /Users/mohammadalmusaiteer/PyNucleus-Model/chunk_reports/embeddings.pkl\n",
      "\n",
      "-- Files in chunk_reports/ --\n",
      "  ¬∑ embeddings.pkl\n",
      "  ¬∑ pynucleus_mcp.faiss\n",
      "  ¬∑ faiss_analysis_20250610_160726.txt\n",
      "\n",
      "=== Evaluation (Recall@3) ===\n",
      "Q: what are the benefits of modular design  ‚úì   top-score=0.4110\n",
      "Q: how does modular design work in vehicles ‚úì   top-score=0.3477\n",
      "\n",
      "Recall@3: 2/2  ‚Üí  100.0%\n",
      "‚úÖ RAG Pipeline completed! FAISS log ‚Üí /Users/mohammadalmusaiteer/PyNucleus-Model/chunk_reports/faiss_analysis_20250610_160726.txt\n",
      "üîç Testing RAG queries...\n",
      "\n",
      "üìù Query: What are the key challenges in implementing modular chemical plants?\n",
      "   1. Score: 0.5875 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      "   2. Score: 0.6000 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      "   3. Score: 0.6108 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      "\n",
      "üìù Query: How does supply chain management affect modular design?\n",
      "   1. Score: 0.7411 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_modular_design.txt\n",
      "   2. Score: 0.7464 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_supply_chain.txt\n",
      "   3. Score: 0.8460 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_modular_design.txt\n",
      "\n",
      "üìù Query: What are the economic benefits of modular construction?\n",
      "   1. Score: 0.5366 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_modular_design.txt\n",
      "   2. Score: 0.6558 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_modular_design.txt\n",
      "   3. Score: 0.6602 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_modular_design.txt\n",
      "\n",
      "üìù Query: How does software architecture relate to modular design?\n",
      "   1. Score: 0.4339 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_modular_design.txt\n",
      "   2. Score: 0.6026 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_software_architecture.txt\n",
      "   3. Score: 0.6121 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/web_sources/wikipedia_modular_design.txt\n",
      "\n",
      "üìù Query: What are the environmental impacts of modular manufacturing?\n",
      "   1. Score: 0.7035 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      "   2. Score: 0.7424 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      "   3. Score: 0.7768 | Source: /Users/mohammadalmusaiteer/PyNucleus-Model/converted_to_txt/Manuscript Draft_Can Modular Plants Lower African Industrialization Barriers.txt\n",
      "‚úÖ Query testing completed! 15 results collected.\n",
      "üìä RAG Statistics:\n",
      "   ‚Ä¢ Total Chunks: 846\n",
      "   ‚Ä¢ Average Chunk Size: 375.2 characters\n",
      "   ‚Ä¢ Number of Sources: 10\n",
      "üî¨ Starting DWSIM Simulations...\n",
      "üìã Running 5 simulation cases...\n",
      "\n",
      "üß™ Case 1/5: distillation_ethanol_water\n",
      "   ‚úÖ Success - Duration: 0.00s\n",
      "\n",
      "üß™ Case 2/5: reactor_methane_combustion\n",
      "   ‚úÖ Success - Duration: 0.00s\n",
      "\n",
      "üß™ Case 3/5: heat_exchanger_steam\n",
      "   ‚úÖ Success - Duration: 0.00s\n",
      "\n",
      "üß™ Case 4/5: absorber_co2_capture\n",
      "   ‚úÖ Success - Duration: 0.00s\n",
      "\n",
      "üß™ Case 5/5: crystallizer_salt\n",
      "   ‚úÖ Success - Duration: 0.00s\n",
      "\n",
      "üìä Simulation Summary:\n",
      "   ‚Ä¢ Successful simulations: 5/5\n",
      "   ‚Ä¢ Failed simulations: 0/5\n",
      "üìä DWSIM Statistics:\n",
      "   ‚Ä¢ Total Simulations: 5\n",
      "   ‚Ä¢ Success Rate: 100.0%\n",
      "   ‚Ä¢ Average Duration: 0.00s\n",
      "\n",
      "üíæ Exporting all results to CSV files...\n",
      "‚úÖ RAG results exported: results/rag_query_results.csv\n",
      "   üìä 15 query results exported\n",
      "‚úÖ DWSIM results exported: results/dwsim_simulation_results.csv\n",
      "   üìä 5 simulation results exported\n",
      "‚úÖ Statistics exported: results/rag_statistics.csv\n",
      "‚úÖ Statistics exported: results/dwsim_statistics.csv\n",
      "‚úÖ Pipeline summary exported: results/pipeline_summary.csv\n",
      "\n",
      "üéâ Export completed successfully!\n",
      "üìÅ All results saved in: results\n",
      "üìà Files created:\n",
      "   ‚Ä¢ rag_query_results.csv (12,340 bytes)\n",
      "   ‚Ä¢ dwsim_simulation_results.csv (1,539 bytes)\n",
      "   ‚Ä¢ rag_statistics.csv (95 bytes)\n",
      "   ‚Ä¢ dwsim_statistics.csv (136 bytes)\n",
      "   ‚Ä¢ pipeline_summary.csv (288 bytes)\n",
      "‚úÖ Complete pipeline finished in 24.7 seconds!\n",
      "\n",
      "üéâ Pipeline completed in 24.7 seconds!\n",
      "üìä RAG Results: 15 queries processed\n",
      "üî¨ DWSIM Results: 5 simulations completed\n",
      "üìÅ Exported Files: 5 CSV files created\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# SECTION 1: COMPLETE PIPELINE - Run Everything\n",
    "# ========================================\n",
    "\n",
    "# Run the complete pipeline (RAG + DWSIM + Export)\n",
    "results = pipeline.run_complete_pipeline()\n",
    "\n",
    "# Display results summary\n",
    "if results:\n",
    "    print(f\"\\nüéâ Pipeline completed in {results['duration']:.1f} seconds!\")\n",
    "    print(f\"üìä RAG Results: {len(results['rag_data'])} queries processed\")\n",
    "    print(f\"üî¨ DWSIM Results: {len(results['dwsim_data'])} simulations completed\")\n",
    "    print(f\"üìÅ Exported Files: {len(results['exported_files'])} CSV files created\")\n",
    "else:\n",
    "    print(\"‚ùå Pipeline execution failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# SECTION 2: INDIVIDUAL PIPELINE COMPONENTS\n",
    "# ========================================\n",
    "\n",
    "# Option 1: Run only RAG Pipeline\n",
    "print(\"üìö RAG Only Pipeline:\")\n",
    "rag_results = pipeline.run_rag_only()\n",
    "if rag_results:\n",
    "    print(f\"   ‚úÖ {len(rag_results['rag_data'])} RAG queries processed\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Option 2: Run only DWSIM Simulations  \n",
    "print(\"üî¨ DWSIM Only Pipeline:\")\n",
    "dwsim_results = pipeline.run_dwsim_only()\n",
    "if dwsim_results:\n",
    "    print(f\"   ‚úÖ {len(dwsim_results['dwsim_data'])} DWSIM simulations completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# SECTION 3: UTILITY FUNCTIONS\n",
    "# ========================================\n",
    "\n",
    "# View pipeline status\n",
    "pipeline.print_pipeline_status()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# View results summary\n",
    "pipeline.view_results_summary()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Quick test\n",
    "test_results = pipeline.quick_test()\n",
    "print(f\"‚úÖ Quick test completed! Found {test_results['csv_files_count']} CSV files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# SECTION 4: SIMPLE FUNCTION CALLS\n",
    "# ========================================\n",
    "\n",
    "print(\"üéØ Simple Function Calls for Easy Testing:\")\n",
    "print()\n",
    "\n",
    "# Individual Component Access\n",
    "print(\"üìö Access individual components:\")\n",
    "print(\"   ‚Ä¢ rag = pipeline.rag_pipeline\")\n",
    "print(\"   ‚Ä¢ dwsim = pipeline.dwsim_pipeline\") \n",
    "print(\"   ‚Ä¢ exporter = pipeline.exporter\")\n",
    "print()\n",
    "\n",
    "# Custom Simulations\n",
    "print(\"üß™ Run custom simulations:\")\n",
    "custom_case = {\n",
    "    \"name\": \"custom_test\",\n",
    "    \"type\": \"reactor\", \n",
    "    \"components\": [\"hydrogen\", \"nitrogen\"],\n",
    "    \"description\": \"Custom ammonia synthesis reactor\"\n",
    "}\n",
    "\n",
    "print(f\"Running custom simulation: {custom_case['name']}\")\n",
    "custom_result = pipeline.dwsim_pipeline.run_single_simulation(custom_case)\n",
    "if custom_result:\n",
    "    print(f\"   ‚úÖ Custom simulation completed: {custom_result['success']}\")\n",
    "\n",
    "print()\n",
    "print(\"üìÅ All results automatically saved as CSV files in ./results/ directory\")\n",
    "print(\"üîÑ Run any cell again to re-execute that specific pipeline component\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up and reset (optional)\n",
    "# pipeline.clean_all_results()  # Uncomment to clean all previous results\n",
    "\n",
    "print(\" PyNucleus Pipeline is ready!\")\n",
    "print(\" Use the functions above to run different parts of the pipeline\")\n",
    "print(\" All results are automatically exported to CSV files\")\n",
    "print(\" You can run any cell multiple times to re-execute components\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete pipeline\n",
    "results = pipeline.run_complete_pipeline()\n",
    "\n",
    "# Individual components\n",
    "rag_results = pipeline.run_rag_only()\n",
    "dwsim_results = pipeline.run_dwsim_only()\n",
    "\n",
    "# Utilities\n",
    "pipeline.quick_test()\n",
    "pipeline.view_results_summary()\n",
    "pipeline.print_pipeline_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the last step in the code for version control purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting GitHub update...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Files added to staging\n",
      "[main fa452cd] Update: 2025-06-10 16:24:56\n",
      " 2 files changed, 11 insertions(+), 88 deletions(-)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Changes committed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enumerating objects: 65, done.\n",
      "Counting objects: 100% (65/65), done.\n",
      "Delta compression using up to 8 threads\n",
      "Compressing objects: 100% (53/53), done.\n",
      "Writing objects: 100% (55/55), 55.16 KiB | 13.79 MiB/s, done.\n",
      "Total 55 (delta 13), reused 0 (delta 0), pack-reused 0 (from 0)\n",
      "remote: Resolving deltas: 100% (13/13), completed with 5 local objects.\u001b[K\n",
      "To https://github.com/Saytor20/PyNucleus-Model.git\n",
      "   08ec141..fa452cd  main -> main\n",
      "‚úÖ Changes pushed to GitHub successfully!\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Log end time\n",
    "with open(\"update_log.txt\", \"a\") as f:\n",
    "    f.write(f\"\\n {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} changes made and pushed to origin main\\n\")\n",
    "\n",
    "# Simple GitHub update function\n",
    "def update_github():\n",
    "    print(\" Starting GitHub update...\")\n",
    "    !git add .\n",
    "    print(\"üì¶ Files added to staging\")\n",
    "    !git commit -m \"Update: $(date +'%Y-%m-%d %H:%M:%S')\"\n",
    "    print(\"üíæ Changes committed\")\n",
    "    !git push origin main\n",
    "    print(\"‚úÖ Changes pushed to GitHub successfully!\")\n",
    "\n",
    "# To use it, just run:\n",
    "update_github()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
