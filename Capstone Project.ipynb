{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# **PyNucleus Model - User Interface** 🚀\n",
    "\n",
    "## **Welcome to PyNucleus!** \n",
    "\n",
    "This notebook provides a simple interface to run the PyNucleus pipeline for chemical process analysis.\n",
    "\n",
    "### **What PyNucleus Does:**\n",
    "- **📚 Document Analysis**: Processes chemical engineering documents using RAG with real FAISS vector store (7141 documents)\n",
    "- **🔬 DWSIM Simulations**: Runs chemical process simulations with predefined scenarios\n",
    "- **📊 Results Export**: Automatically exports results to CSV files for analysis\n",
    "- **💡 LLM Integration**: Generates intelligent summaries and reports\n",
    "\n",
    "### **Recent Updates (2025-06-18):**\n",
    "- ✅ **Real FAISS Integration**: Now uses actual indexed documents instead of mock responses\n",
    "- ✅ **Enhanced Vector Store**: 7141 documents with 384-dimensional embeddings\n",
    "- ✅ **Improved Performance**: Realistic processing times and better result validation\n",
    "- ✅ **Fixed File Detection**: Proper CSV and JSON file detection and display\n",
    "\n",
    "### **How to Use This Notebook:**\n",
    "1. **Run Cell 1**: Initialize the system with real FAISS integration\n",
    "2. **Run Cell 2**: Execute the complete pipeline with real document retrieval\n",
    "3. **Run Cell 3**: View your results with enhanced dashboard\n",
    "\n",
    "**⚡ That's it! The system now uses real documents and provides authentic results.**\n",
    "\n",
    "---\n",
    "**💡 For developers**: Advanced features and diagnostics are available in `Developer_Notebook.ipynb`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Initializing PyNucleus Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/mohammadalmusaiteer/PyNucleus-Model/src/pynucleus/rag/vector_store.py:340: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = SentenceTransformerEmbeddings(model_name='all-MiniLM-L6-v2')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PyNucleus Model initialized successfully!\n",
      "📋 System Ready:\n",
      "   • RAG Pipeline - Document processing and retrieval\n",
      "   • DWSIM Pipeline - Chemical process simulation\n",
      "   • Results Export - CSV and report generation\n",
      "   • LLM Integration - Intelligent analysis and summaries\n",
      "\n",
      "🎯 Ready to run analysis! Execute Cell 2 to start.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: System Initialization\n",
    "# ===================================\n",
    "# This cell sets up PyNucleus and prepares all components\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"🔧 Initializing PyNucleus Model...\")\n",
    "\n",
    "# Add src to Python path\n",
    "src_path = str(Path().resolve() / \"src\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "try:\n",
    "    # Import PyNucleus components\n",
    "    from pynucleus.pipeline import PipelineUtils\n",
    "    from pynucleus.integration.llm_output_generator import LLMOutputGenerator\n",
    "    \n",
    "    # Initialize pipeline\n",
    "    pipeline = PipelineUtils(results_dir=\"data/05_output/results\")\n",
    "    llm_generator = LLMOutputGenerator(results_dir=\"data/05_output/reports\")\n",
    "    \n",
    "    print(\"✅ PyNucleus Model initialized successfully!\")\n",
    "    print(\"📋 System Ready:\")\n",
    "    print(\"   • RAG Pipeline - Document processing and retrieval\")\n",
    "    print(\"   • DWSIM Pipeline - Chemical process simulation\")\n",
    "    print(\"   • Results Export - CSV and report generation\")\n",
    "    print(\"   • LLM Integration - Intelligent analysis and summaries\")\n",
    "    print(\"\\n🎯 Ready to run analysis! Execute Cell 2 to start.\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"❌ Import Error: {e}\")\n",
    "    print(\"💡 Please ensure you're in the PyNucleus-Model directory\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Initialization Error: {e}\")\n",
    "    print(\"💡 Please check your system setup\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Complete PyNucleus Analysis...\n",
      "\n",
      "📊 This will run:\n",
      "   1. Document processing and RAG analysis\n",
      "   2. DWSIM chemical process simulations\n",
      "   3. Results export and report generation\n",
      "\n",
      "⏳ Please wait... This may take 20-30 seconds.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to export RAG results: Object of type float32 is not JSON serializable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎉 Analysis completed successfully in 14.4 seconds!\n",
      "\n",
      "📊 Results Summary:\n",
      "   • Documents Processed: 3 queries\n",
      "   • Simulations Completed: 3 scenarios\n",
      "   • Files Generated: 1 CSV files\n",
      "⚠️ Enhanced analysis unavailable (using basic results only)\n",
      "\n",
      "📁 All results saved to:\n",
      "   • CSV Files: data/05_output/results/\n",
      "   • Reports: data/05_output/reports/\n",
      "\n",
      "✅ Analysis complete! Run Cell 3 to explore your results.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Run Complete Analysis\n",
    "# ===================================\n",
    "# This cell runs the complete PyNucleus pipeline\n",
    "\n",
    "print(\"🚀 Starting Complete PyNucleus Analysis...\")\n",
    "print(\"\\n📊 This will run:\")\n",
    "print(\"   1. Document processing and RAG analysis\")\n",
    "print(\"   2. DWSIM chemical process simulations\")\n",
    "print(\"   3. Results export and report generation\")\n",
    "print(\"\\n⏳ Please wait... This may take 20-30 seconds.\\n\")\n",
    "\n",
    "try:\n",
    "    # Run the complete pipeline\n",
    "    results = pipeline.run_complete_pipeline()\n",
    "    \n",
    "    if results:\n",
    "        print(f\"\\n🎉 Analysis completed successfully in {results['duration']:.1f} seconds!\")\n",
    "        print(\"\\n📊 Results Summary:\")\n",
    "        print(f\"   • Documents Processed: {len(results['rag_data'])} queries\")\n",
    "        print(f\"   • Simulations Completed: {len(results['dwsim_data'])} scenarios\")\n",
    "        print(f\"   • Files Generated: {len(results['exported_files'])} CSV files\")\n",
    "        \n",
    "        # Generate enhanced reports if available\n",
    "        try:\n",
    "            from pynucleus.integration.dwsim_rag_integrator import DWSIMRAGIntegrator\n",
    "            \n",
    "            integrator = DWSIMRAGIntegrator(\n",
    "                rag_pipeline=pipeline.rag_pipeline,\n",
    "                results_dir=\"data/05_output/results\"\n",
    "            )\n",
    "            \n",
    "            # Enhanced analysis\n",
    "            dwsim_results = pipeline.dwsim_pipeline.get_results()\n",
    "            if dwsim_results:\n",
    "                enhanced_results = integrator.integrate_simulation_results(\n",
    "                    dwsim_results, perform_rag_analysis=True\n",
    "                )\n",
    "                \n",
    "                # Generate LLM reports\n",
    "                report_files = []\n",
    "                for result in enhanced_results[:3]:  # Generate reports for first 3 simulations\n",
    "                    report_file = llm_generator.export_llm_ready_text(result)\n",
    "                    report_files.append(report_file)\n",
    "                \n",
    "                # Financial analysis\n",
    "                financial_file = llm_generator.export_financial_analysis(enhanced_results)\n",
    "                metrics = llm_generator._calculate_key_metrics(enhanced_results)\n",
    "                \n",
    "                print(\"\\n💰 Financial Analysis:\")\n",
    "                print(f\"   • Recovery Rate: {metrics['avg_recovery']:.1f}%\")\n",
    "                print(f\"   • Daily Revenue: ${metrics['estimated_revenue']:,.2f}\")\n",
    "                print(f\"   • Daily Profit: ${metrics['net_profit']:,.2f}\")\n",
    "                print(f\"   • ROI: {metrics['roi']:.1f}%\")\n",
    "                \n",
    "                print(f\"\\n📄 Generated Reports: {len(report_files)} detailed analysis files\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(\"⚠️ Enhanced analysis unavailable (using basic results only)\")\n",
    "        \n",
    "        print(\"\\n📁 All results saved to:\")\n",
    "        print(\"   • CSV Files: data/05_output/results/\")\n",
    "        print(\"   • Reports: data/05_output/reports/\")\n",
    "        print(\"\\n✅ Analysis complete! Run Cell 3 to explore your results.\")\n",
    "        \n",
    "    else:\n",
    "        print(\"❌ Pipeline execution failed\")\n",
    "        print(\"💡 Please check your data directories and try again\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error during analysis: {e}\")\n",
    "    print(\"💡 Please ensure all components are properly initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 PyNucleus Results Dashboard\n",
      "========================================\n",
      "📁 Results Directory: data/05_output/results\n",
      "📄 CSV Files Found: 2\n",
      "\n",
      "📋 Available Files:\n",
      "   • dev_simulation_config.csv (171 bytes)\n",
      "   • bulk_modular_plants_template.csv (1372 bytes)\n",
      "\n",
      "========================================\n",
      "📊 PyNucleus System Summary\n",
      "------------------------------\n",
      "📁 Main Results Dir (results): 23 JSON files\n",
      "📁 Results Subdir (results): 28 JSON files\n",
      "📁 Config Files: 2 CSV files\n",
      "\n",
      "🔧 Pipeline Status:\n",
      "   • RAG Pipeline: Initialized\n",
      "   • DWSIM Pipeline: Initialized\n",
      "   • Results Directory: data/05_output/results\n",
      "\n",
      "📋 Recent Generated Files:\n",
      "   • dwsim_results_20250618_155648.json\n",
      "   • rag_results_20250618_155648.json\n",
      "   • integrated_results_20250618_153352.json\n",
      "   • dwsim_results_20250618_153352.json\n",
      "   • rag_results_20250618_153352.json\n",
      "\n",
      "🔧 Additional Options:\n",
      "   • Re-run Cell 2 to generate new results\n",
      "   • Check data/05_output/ folder for all generated files\n",
      "   • View Developer_Notebook.ipynb for advanced features\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: View Results and Summary\n",
    "# ===================================\n",
    "# This cell displays your results and provides access to files\n",
    "\n",
    "print(\"📊 PyNucleus Results Dashboard\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    # Quick status check\n",
    "    status = pipeline.quick_test()\n",
    "    \n",
    "    print(f\"📁 Results Directory: {status['results_dir']}\")\n",
    "    print(f\"📄 CSV Files Found: {status['csv_files_count']}\")\n",
    "    \n",
    "    if status['csv_files_count'] > 0:\n",
    "        print(\"\\n📋 Available Files:\")\n",
    "        for file_info in status['csv_files']:\n",
    "            print(f\"   • {file_info['name']} ({file_info['size']} bytes)\")\n",
    "    \n",
    "    # Display detailed summary\n",
    "    print(\"\\n\" + \"=\" * 40)\n",
    "    pipeline.view_results_summary()\n",
    "    \n",
    "    print(\"\\n🔧 Additional Options:\")\n",
    "    print(\"   • Re-run Cell 2 to generate new results\")\n",
    "    print(\"   • Check data/05_output/ folder for all generated files\")\n",
    "    print(\"   • View Developer_Notebook.ipynb for advanced features\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error viewing results: {e}\")\n",
    "    print(\"💡 Please run Cell 2 first to generate results\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## **Optional: Individual Components**\n",
    "\n",
    "The cells below allow you to run specific parts of the pipeline individually if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Cell 4A: Run Only Document Analysis (RAG)\n",
    "# ====================================================\n",
    "# Uncomment and run this cell if you only want document processing\n",
    "\n",
    "# print(\"📚 Running Document Analysis Only...\")\n",
    "# rag_results = pipeline.run_rag_only()\n",
    "# if rag_results:\n",
    "#     print(f\"✅ Processed {len(rag_results['rag_data'])} document queries\")\n",
    "#     print(\"📁 Results saved to data/05_output/results/\")\n",
    "# else:\n",
    "#     print(\"❌ Document analysis failed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Cell 4B: Run Only Chemical Simulations (DWSIM)\n",
    "# =======================================================\n",
    "# Uncomment and run this cell if you only want DWSIM simulations\n",
    "\n",
    "# print(\"🔬 Running Chemical Simulations Only...\")\n",
    "# dwsim_results = pipeline.run_dwsim_only()\n",
    "# if dwsim_results:\n",
    "#     print(f\"✅ Completed {len(dwsim_results['dwsim_data'])} simulations\")\n",
    "#     print(\"📁 Results saved to data/05_output/results/\")\n",
    "# else:\n",
    "#     print(\"❌ Chemical simulations failed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Cell 5: Clean Up Results\n",
    "# =================================\n",
    "# Uncomment and run this cell to clear all previous results\n",
    "\n",
    "# print(\"🗑️ Cleaning up previous results...\")\n",
    "# pipeline.clean_all_results()\n",
    "# print(\"✅ All results cleared. You can now run a fresh analysis.\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## **Need More Features?**\n",
    "\n",
    "🔧 **For Developers**: Advanced features, debugging, and system diagnostics are available in:\n",
    "- `Developer_Notebook.ipynb` - Full development environment\n",
    "- `scripts/comprehensive_system_diagnostic.py` - System health checks\n",
    "\n",
    "📚 **Documentation**: Check the `docs/` folder for detailed guides:\n",
    "- `README.md` - Complete setup and usage guide\n",
    "- `docs/ENHANCED_PIPELINE_SUMMARY.md` - Advanced features overview\n",
    "- `docs/project_info/` - Technical documentation\n",
    "\n",
    "💡 **Support**: For issues or questions, check the project documentation or create an issue in the repository.\n",
    "\n",
    "---\n",
    "\n",
    "**🎉 Thank you for using PyNucleus!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting GitHub update...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Files added to staging\n",
      "[main 4f810f3] Update: 2025-06-18 15:58:47\n",
      " 18 files changed, 435 insertions(+), 27 deletions(-)\n",
      " create mode 100644 data/validation/results/system_validation_20250618_155738.json\n",
      " create mode 100644 logs/pynucleus_20250618_155154.log\n",
      " create mode 100644 logs/pynucleus_20250618_155209.log\n",
      " create mode 100644 logs/pynucleus_20250618_155245.log\n",
      " create mode 100644 logs/pynucleus_20250618_155312.log\n",
      " create mode 100644 logs/pynucleus_20250618_155323.log\n",
      " create mode 100644 logs/pynucleus_20250618_155351.log\n",
      " create mode 100644 logs/pynucleus_20250618_155353.log\n",
      " create mode 100644 logs/pynucleus_20250618_155355.log\n",
      " create mode 100644 logs/pynucleus_20250618_155410.log\n",
      " create mode 100644 logs/pynucleus_20250618_155435.log\n",
      " create mode 100644 src/pynucleus/api/__init__.py\n",
      " create mode 100644 src/pynucleus/api/app.py\n",
      " create mode 100644 tests/test_api_health.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Changes committed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enumerating objects: 39, done.\n",
      "Counting objects: 100% (39/39), done.\n",
      "Delta compression using up to 8 threads\n",
      "Compressing objects: 100% (25/25), done.\n",
      "Writing objects: 100% (26/26), 7.19 KiB | 7.19 MiB/s, done.\n",
      "Total 26 (delta 13), reused 0 (delta 0), pack-reused 0 (from 0)\n",
      "remote: Resolving deltas: 100% (13/13), completed with 10 local objects.\u001b[K\n",
      "To https://github.com/Saytor20/PyNucleus-Model.git\n",
      "   2a549d0..4f810f3  main -> main\n",
      " Changes pushed to GitHub successfully!\n"
     ]
    }
   ],
   "source": [
    "# # ========================================\n",
    "# # VERSION CONTROL (Optional - For Maintainers Only)\n",
    "# # ========================================\n",
    "# # Uncomment the lines below if you need to update the repository:\n",
    "\n",
    "# from datetime import datetime\n",
    "\n",
    "# # Log end time\n",
    "# with open(\"update_log.txt\", \"a\") as f:\n",
    "#     f.write(f\"\\n {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} changes made and pushed to origin main\\n\")\n",
    "\n",
    "# # Simple GitHub update function\n",
    "# def update_github():\n",
    "#     print(\" Starting GitHub update...\")\n",
    "#     !git add .\n",
    "#     print(\" Files added to staging\")\n",
    "#     !git commit -m \"Update: $(date +'%Y-%m-%d %H:%M:%S')\"\n",
    "#     print(\" Changes committed\")\n",
    "#     !git push origin main\n",
    "#     print(\" Changes pushed to GitHub successfully!\")\n",
    "\n",
    "# # To use it, just run:\n",
    "# update_github()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
