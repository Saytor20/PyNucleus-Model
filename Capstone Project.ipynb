{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":18,"metadata":{"id":"pxJK6GpyVui7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d0cbc029-8866-45ce-8f28-58f657b0fdb5","executionInfo":{"status":"ok","timestamp":1748925828681,"user_tz":240,"elapsed":746,"user":{"displayName":"Mohammad A.","userId":"15199683412159334052"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Commented out IPython magic to ensure Python compatibility.\n","from google.colab import drive, userdata\n","import os\n","from datetime import datetime\n","\n","# --- 1. Mount Google Drive ---\n","# This gives Colab access to your files in Google Drive.\n","drive.mount('/content/drive')\n","\n","# --- 2. Configure GitHub Details ---\n","# Make sure you have 'GITHUB_USERNAME' and 'GITHUB_TOKEN' saved as secrets in Colab.\n","GITHUB_USERNAME = userdata.get('GITHUB_USERNAME')\n","GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n","REPOSITORY_NAME = 'PyNucleus-Model' # Your repository name\n","\n","# Path to your master notebook in Google Drive\n","NOTEBOOK_DRIVE_PATH = \"/content/drive/MyDrive/PyNucleus Project/Capstone Project.ipynb\"\n","# The name you want for the notebook file in your GitHub repo\n","NOTEBOOK_REPO_FILENAME = \"Capstone Project.ipynb\"\n","LOG_FILENAME = \"update_log.txt\"\n"]},{"cell_type":"code","source":["# --- 3. Clone the Repository ---\n","# This downloads your repo into the Colab environment.\n","repo_path = f'/content/{REPOSITORY_NAME}'\n","!git clone https://{GITHUB_TOKEN}@github.com/{GITHUB_USERNAME}/{REPOSITORY_NAME}.git {repo_path}\n","\n","# Change the current working directory to the repository\n","# All subsequent commands will run from inside the repo folder.\n","os.chdir(repo_path)\n","\n","# --- 4. Create Log, Copy Notebook, and Commit ---\n","# Add a new line to your log file with the current date and time.\n","log_message = f\"Notebook saved on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n","with open(LOG_FILENAME, \"a\") as f:\n","    f.write(log_message + \"\\n\")\n","print(f\"Updated '{LOG_FILENAME}'\")\n","\n","# Copy the latest version of your notebook from Drive into the cloned repo.\n","!cp \"{NOTEBOOK_DRIVE_PATH}\" \"{NOTEBOOK_REPO_FILENAME}\"\n","print(f\"Copied '{NOTEBOOK_REPO_FILENAME}' from Google Drive.\")\n","\n","# Set your Git identity\n","!git config user.name \"{GITHUB_USERNAME}\"\n","!git config user.email \"{GITHUB_USERNAME}@users.noreply.github.com\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qqy1ABswnFgQ","executionInfo":{"status":"ok","timestamp":1748925829706,"user_tz":240,"elapsed":1020,"user":{"displayName":"Mohammad A.","userId":"15199683412159334052"}},"outputId":"1104e78c-fbf3-4a4f-a133-24e5af153f6a"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path '/content/PyNucleus-Model' already exists and is not an empty directory.\n","Updated 'update_log.txt'\n","Copied 'Capstone Project.ipynb' from Google Drive.\n"]}]},{"cell_type":"code","source":["# # --- Installation Cell (Run this ONCE per session) ---\n","# print(\"Installing all required packages...\")\n","\n","# # Core LangChain and Community Packages\n","# !pip install -q langchain langchain-core langchain-community langchain-text-splitters\n","\n","# # Document Loading & Processing (Unstructured handles many file types including OCR)\n","# !pip install -q \"unstructured[local-inference]\"\n","\n","# # LLM & ML Libraries\n","# !pip install -q transformers accelerate bitsandbytes torch sentence-transformers\n","\n","# # Vector Stores\n","# !pip install -q chromadb faiss-cpu # faiss-gpu if you have a Pro Colab with a good GPU\n","\n","# # Data Handling & Utilities\n","# !pip install -q pandas numpy tqdm PyYAML\n","\n","# print(\"All packages installed successfully.\")"],"metadata":{"id":"DfNy6HlnOsXc","executionInfo":{"status":"ok","timestamp":1748925829774,"user_tz":240,"elapsed":66,"user":{"displayName":"Mohammad A.","userId":"15199683412159334052"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# # --- Core Utilities & File Handling ---\n","# import getpass\n","# import yaml # Make sure PyYAML is installed\n","# from pathlib import Path\n","\n","# # --- Data Handling & Progress Bars ---\n","# import pandas as pd\n","# import numpy as np\n","# from tqdm import tqdm\n","\n","# # --- Document Loading ---\n","# # UnstructuredFileLoader is now in langchain_community\n","# from langchain_community.document_loaders import UnstructuredFileLoader\n","# # For future testing of more specific loaders:\n","# # from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader\n","\n","# # --- OCR Libraries ---\n","# # No direct imports needed here if using UnstructuredFileLoader with local-inference,\n","# # as it handles OCR internally.\n","# # You would only import these for a manual OCR process:\n","# # import pytesseract\n","# # from pdf2image import convert_from_path\n","# # from PIL import Image\n","\n","# # --- Core ML & LLM Libraries ---\n","# import torch\n","# import transformers\n","# from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","# import bitsandbytes\n","# import accelerate # Often used with transformers\n","\n","# # --- Vector Stores & Embeddings ---\n","# # Using ChromaDB as the primary vector store.\n","# import chromadb\n","# from langchain_community.vectorstores import Chroma # Chroma is now in langchain_community\n","# from langchain_community.embeddings import HuggingFaceEmbeddings # Embeddings are also in langchain_community\n","# # For future testing of a high-performance alternative:\n","# # import faiss\n","# # from langchain_community.vectorstores import FAISS\n","\n","# # --- RAG/Agent Frameworks ---\n","# # Core LangChain components\n","# import langchain\n","# from langchain_core.prompts import ChatPromptTemplate\n","# from langchain_core.output_parsers import StrOutputParser\n","# # For future testing of an alternative RAG-focused toolkit:\n","# # from llama_index.core import SimpleDirectoryReader, VectorStoreIndex"],"metadata":{"id":"BPyfUDJoDjgn","executionInfo":{"status":"ok","timestamp":1748925829775,"user_tz":240,"elapsed":3,"user":{"displayName":"Mohammad A.","userId":"15199683412159334052"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["# **Data Ingestion and Preprocessing for RAG**"],"metadata":{"id":"OL-SmhSQQ_21"}},{"cell_type":"code","source":[],"metadata":{"id":"I69992m0RE82","executionInfo":{"status":"ok","timestamp":1748925829780,"user_tz":240,"elapsed":5,"user":{"displayName":"Mohammad A.","userId":"15199683412159334052"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["# This is the last cell of the code"],"metadata":{"id":"hISFF6TUEB_H"}},{"cell_type":"code","source":["# Add the notebook to the staging area\n","!git add \"{NOTEBOOK_REPO_FILENAME}\"\n","!git add \"{LOG_FILENAME}\"\n","\n","\n","# Commit the changes with a more descriptive message\n","commit_message = f\"Update notebook and log file on {datetime.now().strftime('%Y-%m-%d')}\"\n","!git commit -m \"{commit_message}\"\n","\n","# --- 5. Push to GitHub ---\n","# Push the committed changes to the 'main' branch of your repository.\n","print(\"\\nPushing changes to GitHub...\")\n","!git push origin main\n","\n","print(f\"\\n Successfully saved '{NOTEBOOK_REPO_FILENAME}' to your GitHub repository!\")\n"],"metadata":{"id":"tjThfmG7EDzG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748925830962,"user_tz":240,"elapsed":1181,"user":{"displayName":"Mohammad A.","userId":"15199683412159334052"}},"outputId":"ce4cfb74-9807-4294-fa2a-9c0d7632139b"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["[main 5f4484a] Update notebook and log file on 2025-06-03\n"," 2 files changed, 2 insertions(+), 1 deletion(-)\n"," rewrite Capstone Project.ipynb (97%)\n","\n","Pushing changes to GitHub...\n","Enumerating objects: 7, done.\n","Counting objects: 100% (7/7), done.\n","Delta compression using up to 2 threads\n","Compressing objects: 100% (4/4), done.\n","Writing objects: 100% (4/4), 1.29 KiB | 1.29 MiB/s, done.\n","Total 4 (delta 3), reused 0 (delta 0), pack-reused 0\n","remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n","To https://github.com/Saytor20/PyNucleus-Model.git\n","   bbf1156..5f4484a  main -> main\n","\n"," Successfully saved 'Capstone Project.ipynb' to your GitHub repository!\n"]}]}]}