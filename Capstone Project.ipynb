{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":12,"metadata":{"id":"pxJK6GpyVui7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a29a47db-412a-4178-8fb1-a28530a9b2ff","executionInfo":{"status":"ok","timestamp":1748925441150,"user_tz":240,"elapsed":741,"user":{"displayName":"Mohammad A.","userId":"15199683412159334052"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Commented out IPython magic to ensure Python compatibility.\n","from google.colab import drive, userdata\n","import os\n","from datetime import\n","\n","# --- 1. Mount Google Drive ---\n","# This gives Colab access to your files in Google Drive.\n","drive.mount('/content/drive')\n","\n","# --- 2. Configure GitHub Details ---\n","# Make sure you have 'GITHUB_USERNAME' and 'GITHUB_TOKEN' saved as secrets in Colab.\n","GITHUB_USERNAME = userdata.get('GITHUB_USERNAME')\n","GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n","REPOSITORY_NAME = 'PyNucleus-Model' # Your repository name\n","\n","# Path to your master notebook in Google Drive\n","NOTEBOOK_DRIVE_PATH = \"/content/drive/MyDrive/PyNucleus Project/Capstone Project.ipynb\"\n","# The name you want for the notebook file in your GitHub repo\n","NOTEBOOK_REPO_FILENAME = \"Capstone Project.ipynb\"\n","LOG_FILENAME = \"update_log.txt\"\n"]},{"cell_type":"code","source":["# --- 3. Clone the Repository ---\n","# This downloads your repo into the Colab environment.\n","repo_path = f'/content/{REPOSITORY_NAME}'\n","!git clone https://{GITHUB_TOKEN}@github.com/{GITHUB_USERNAME}/{REPOSITORY_NAME}.git {repo_path}\n","\n","# Change the current working directory to the repository\n","# All subsequent commands will run from inside the repo folder.\n","os.chdir(repo_path)\n","\n","# --- 4. Create Log, Copy Notebook, and Commit ---\n","# Add a new line to your log file with the current date and time.\n","log_message = f\"Notebook saved on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n","with open(LOG_FILENAME, \"a\") as f:\n","    f.write(log_message + \"\\n\")\n","print(f\"Updated '{LOG_FILENAME}'\")\n","\n","# Copy the latest version of your notebook from Drive into the cloned repo.\n","!cp \"{NOTEBOOK_DRIVE_PATH}\" \"{NOTEBOOK_REPO_FILENAME}\"\n","print(f\"Copied '{NOTEBOOK_REPO_FILENAME}' from Google Drive.\")\n","\n","# Set your Git identity\n","!git config user.name \"{GITHUB_USERNAME}\"\n","!git config user.email \"{GITHUB_USERNAME}@users.noreply.github.com\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qqy1ABswnFgQ","executionInfo":{"status":"ok","timestamp":1748925442487,"user_tz":240,"elapsed":1332,"user":{"displayName":"Mohammad A.","userId":"15199683412159334052"}},"outputId":"c2369a52-d84b-484d-a7f0-a06f00f4c80c"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into '/content/PyNucleus-Model'...\n","remote: Enumerating objects: 69, done.\u001b[K\n","remote: Counting objects: 100% (69/69), done.\u001b[K\n","remote: Compressing objects: 100% (50/50), done.\u001b[K\n","remote: Total 69 (delta 39), reused 43 (delta 18), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (69/69), 24.39 KiB | 8.13 MiB/s, done.\n","Resolving deltas: 100% (39/39), done.\n"]}]},{"cell_type":"code","source":["# # --- Installation Cell (Run this ONCE per session) ---\n","# print(\"Installing all required packages...\")\n","\n","# # Core LangChain and Community Packages\n","# !pip install -q langchain langchain-core langchain-community langchain-text-splitters\n","\n","# # Document Loading & Processing (Unstructured handles many file types including OCR)\n","# !pip install -q \"unstructured[local-inference]\"\n","\n","# # LLM & ML Libraries\n","# !pip install -q transformers accelerate bitsandbytes torch sentence-transformers\n","\n","# # Vector Stores\n","# !pip install -q chromadb faiss-cpu # faiss-gpu if you have a Pro Colab with a good GPU\n","\n","# # Data Handling & Utilities\n","# !pip install -q pandas numpy tqdm PyYAML\n","\n","# print(\"All packages installed successfully.\")"],"metadata":{"id":"DfNy6HlnOsXc","executionInfo":{"status":"ok","timestamp":1748925442503,"user_tz":240,"elapsed":2,"user":{"displayName":"Mohammad A.","userId":"15199683412159334052"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# # --- Core Utilities & File Handling ---\n","# import getpass\n","# import yaml # Make sure PyYAML is installed\n","# from pathlib import Path\n","\n","# # --- Data Handling & Progress Bars ---\n","# import pandas as pd\n","# import numpy as np\n","# from tqdm import tqdm\n","\n","# # --- Document Loading ---\n","# # UnstructuredFileLoader is now in langchain_community\n","# from langchain_community.document_loaders import UnstructuredFileLoader\n","# # For future testing of more specific loaders:\n","# # from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader\n","\n","# # --- OCR Libraries ---\n","# # No direct imports needed here if using UnstructuredFileLoader with local-inference,\n","# # as it handles OCR internally.\n","# # You would only import these for a manual OCR process:\n","# # import pytesseract\n","# # from pdf2image import convert_from_path\n","# # from PIL import Image\n","\n","# # --- Core ML & LLM Libraries ---\n","# import torch\n","# import transformers\n","# from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","# import bitsandbytes\n","# import accelerate # Often used with transformers\n","\n","# # --- Vector Stores & Embeddings ---\n","# # Using ChromaDB as the primary vector store.\n","# import chromadb\n","# from langchain_community.vectorstores import Chroma # Chroma is now in langchain_community\n","# from langchain_community.embeddings import HuggingFaceEmbeddings # Embeddings are also in langchain_community\n","# # For future testing of a high-performance alternative:\n","# # import faiss\n","# # from langchain_community.vectorstores import FAISS\n","\n","# # --- RAG/Agent Frameworks ---\n","# # Core LangChain components\n","# import langchain\n","# from langchain_core.prompts import ChatPromptTemplate\n","# from langchain_core.output_parsers import StrOutputParser\n","# # For future testing of an alternative RAG-focused toolkit:\n","# # from llama_index.core import SimpleDirectoryReader, VectorStoreIndex"],"metadata":{"id":"BPyfUDJoDjgn","executionInfo":{"status":"ok","timestamp":1748925442548,"user_tz":240,"elapsed":44,"user":{"displayName":"Mohammad A.","userId":"15199683412159334052"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["# **Data Ingestion and Preprocessing for RAG**"],"metadata":{"id":"OL-SmhSQQ_21"}},{"cell_type":"code","source":[],"metadata":{"id":"I69992m0RE82","executionInfo":{"status":"ok","timestamp":1748925442548,"user_tz":240,"elapsed":43,"user":{"displayName":"Mohammad A.","userId":"15199683412159334052"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["# This is the last cell of the code"],"metadata":{"id":"hISFF6TUEB_H"}},{"cell_type":"code","source":["# Add the notebook to the staging area\n","!git add \"{NOTEBOOK_REPO_FILENAME}\"\n","!git add \"{LOG_FILENAME}\"\n","\n","\n","# Commit the changes with a more descriptive message\n","commit_message = f\"Update notebook and log file on {datetime.now().strftime('%Y-%m-%d')}\"\n","!git commit -m \"{commit_message}\"\n","\n","# --- 5. Push to GitHub ---\n","# Push the committed changes to the 'main' branch of your repository.\n","!git push origin main\n","\n","print(f\"\\n Successfully saved '{NOTEBOOK_REPO_FILENAME}' to your GitHub repository!\")\n"],"metadata":{"id":"tjThfmG7EDzG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748925443544,"user_tz":240,"elapsed":997,"user":{"displayName":"Mohammad A.","userId":"15199683412159334052"}},"outputId":"839ca590-4285-49ef-e006-3e6f8c82c6eb"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["[main bbf1156] Update: Capstone Project.ipynb\n"," 1 file changed, 1 insertion(+), 1 deletion(-)\n"," rewrite Capstone Project.ipynb (97%)\n","Enumerating objects: 5, done.\n","Counting objects: 100% (5/5), done.\n","Delta compression using up to 2 threads\n","Compressing objects: 100% (3/3), done.\n","Writing objects: 100% (3/3), 1.41 KiB | 1.41 MiB/s, done.\n","Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\n","remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n","To https://github.com/Saytor20/PyNucleus-Model.git\n","   dd9a58a..bbf1156  main -> main\n","\n","âœ… Successfully saved 'Capstone Project.ipynb' to your GitHub repository!\n"]}]}]}