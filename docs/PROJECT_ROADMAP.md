# PyNucleus Model - Project Roadmap

**Version**: 2.0  
**Last Updated**: 2025-01-18  
**Status**: Production-Ready Core, Deployment Phase

---

## ðŸŽ¯ Executive Summary

PyNucleus is a comprehensive chemical engineering platform that integrates Retrieval-Augmented Generation (RAG) with DWSIM chemical process simulation. The system has achieved **100% operational health** with all core components validated and production-ready. This roadmap outlines the path to complete the CLI interface and deploy via Flask with a lightweight UI.

**Current System Health**: âœ… 100% EXCELLENT  
**Core Features**: âœ… Complete  
**Production Readiness**: âœ… Docker, monitoring, validation frameworks active  
**Remaining Effort**: ~3.5 days to full deployment

---

## 1. ðŸ“‹ Current Capabilities

### âœ… **Core Infrastructure (100% Complete)**
- **RAG Pipeline**: Document processing with FAISS indexing (7,141 documents, 384-dim embeddings)
- **Vector Store**: Real FAISS implementation with semantic search & fallback systems
- **DWSIM Integration**: Chemical process simulation with enhanced analytics
- **Pipeline Orchestration**: Complete pipeline utilities with RAG+DWSIM integration
- **Document Processing**: PDF, DOCX, TXT with automatic conversion and chunking
- **LLM Integration**: Query management with Jinja2 prompt templates

### âœ… **Production Features (100% Complete)**
- **Packaging**: Full `src/pynucleus/` structure with proper entry points
- **CLI Foundation**: Typer-based CLI with `run`, `pipeline-and-ask`, and `test-logging` commands
- **Configuration Management**: JSON/CSV templates with validation
- **Logging & Monitoring**: Structured logging with configurable levels
- **Testing Framework**: Comprehensive diagnostics and validation systems
- **Docker Support**: Dockerfile and docker-compose.yml ready

### âœ… **Data & Analytics (100% Complete)**
- **Results Export**: CSV and JSON export with timestamp tracking
- **Financial Analysis**: ROI calculations, profit analysis, recovery rates
- **Citation Tracking**: Ground-truth validation with source backtracking
- **Performance Monitoring**: System health checks and validation metrics
- **Integration Layer**: DWSIM-RAG integrator with enhanced reporting

### âœ… **User Interfaces (100% Complete)**
- **Jupyter Notebooks**: `Capstone Project.ipynb` (3-step process) and `Developer_Notebook.ipynb`
- **CLI Entry Points**: 9 console commands via setuptools entry points
- **Configuration Templates**: Pre-built simulation scenarios and bulk processing templates

---

## 2. âš¡ Immediate Low-Effort Tasks (â‰¤ 1 day)

### **Task 2.1: CLI Command Completion** (2-3 hours)
```bash
# Missing Typer commands to implement in run_pipeline.py
pynucleus ingest --source-dir data/01_raw --output-dir data/02_processed
pynucleus build-faiss --chunk-dir data/02_processed --index-dir data/04_models
pynucleus ask "How to optimize distillation efficiency?" --model-id falcon-rw-0.3b
```

**Implementation**: Add 3 new `@app.command()` functions to `run_pipeline.py`:
- `ingest()`: Wrapper around `document_processor.main()`
- `build_faiss()`: Wrapper around existing FAISS vector store building
- `ask()`: Wrapper around `llm.query_llm.main()`

### **Task 2.2: Import Path Consolidation** (1 hour)
- All sub-packages already exist in `src/pynucleus/`
- Fix any remaining import path issues in entry points
- Verify all 9 console scripts work via `pip install -e .`

### **Task 2.3: Linting Cleanup** (30 minutes)
```bash
ruff --fix src/ scripts/ automation_tools/
black src/ scripts/ automation_tools/
```

**Expected fixes**: Minor formatting and import ordering (project already has 81.4% script health)

---

## 3. ðŸš€ Deployment Blueprint

### **Flask API Architecture**

#### **3.1 Core Endpoints**
```python
# File: src/pynucleus/api/app.py
from flask import Flask, request, jsonify
from pynucleus.pipeline import PipelineUtils
from pynucleus.llm.query_llm import LLMQueryManager

app = Flask(__name__)

@app.route('/health', methods=['GET'])
def health_check():
    """System health and component status"""
    return {"status": "healthy", "version": "2.0", "components": {...}}

@app.route('/ingest', methods=['POST'])  
def ingest_documents():
    """Upload and process documents into vector store"""
    # files = request.files.getlist('documents')
    # result = pipeline.process_documents(files)
    return {"job_id": "...", "status": "processing", "estimated_time": "2-5 min"}

@app.route('/ask', methods=['POST'])
def query_system():
    """Query RAG+DWSIM system with intelligent routing"""
    # data = request.json  # {"question": "...", "context": "simulation|documents"}
    # result = pipeline.intelligent_query(data['question'], context=data.get('context'))
    return {"answer": "...", "sources": [...], "confidence": 0.87, "type": "rag+simulation"}
```

#### **3.2 Authentication & Rate Limiting**
```python
# Simple API key authentication
@app.before_request
def verify_api_key():
    api_key = request.headers.get('X-API-Key')
    if not api_key or api_key != os.getenv('PYNUCLEUS_API_KEY'):
        return jsonify({"error": "Invalid API key"}), 401

# Rate limiting (using Flask-Limiter)
from flask_limiter import Limiter
limiter = Limiter(app, key_func=lambda: request.remote_addr)

@app.route('/ask', methods=['POST'])
@limiter.limit("10 per minute")  # Prevent LLM abuse
def query_system():
    ...
```

### **3.3 Frontend Design**

#### **Simple HTML/JS Interface**
```html
<!-- File: src/pynucleus/api/static/index.html -->
<!DOCTYPE html>
<html>
<head>
    <title>PyNucleus - Chemical Process Intelligence</title>
    <script src="https://unpkg.com/htmx.org@1.9.10"></script>
    <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
</head>
<body class="bg-gray-50">
    <div class="container mx-auto p-6">
        <h1 class="text-3xl font-bold text-blue-600 mb-6">PyNucleus Chemical Intelligence</h1>
        
        <!-- Query Interface -->
        <div class="bg-white rounded-lg shadow p-6 mb-6">
            <textarea 
                id="question" 
                placeholder="Ask about chemical processes, optimization, or DWSIM simulations..."
                class="w-full p-3 border rounded-lg h-24"></textarea>
            <button 
                hx-post="/ask" 
                hx-include="#question"
                hx-target="#results"
                class="mt-3 bg-blue-600 text-white px-6 py-2 rounded-lg hover:bg-blue-700">
                Ask PyNucleus
            </button>
        </div>
        
        <!-- Results Display -->
        <div id="results" class="bg-white rounded-lg shadow p-6">
            <p class="text-gray-500">Ask a question to see intelligent answers...</p>
        </div>
    </div>
</body>
</html>
```

#### **React Alternative (for advanced UI)**
```jsx
// File: frontend/src/App.jsx
import React, { useState } from 'react';
import axios from 'axios';

function App() {
  const [question, setQuestion] = useState('');
  const [result, setResult] = useState(null);
  const [loading, setLoading] = useState(false);

  const handleQuery = async () => {
    setLoading(true);
    try {
      const response = await axios.post('/api/ask', { question });
      setResult(response.data);
    } catch (error) {
      setResult({ error: 'Query failed. Please try again.' });
    }
    setLoading(false);
  };

  return (
    <div className="max-w-4xl mx-auto p-6">
      <h1 className="text-3xl font-bold mb-6">PyNucleus Intelligence</h1>
      <div className="space-y-4">
        <textarea
          value={question}
          onChange={(e) => setQuestion(e.target.value)}
          placeholder="Ask about chemical processes..."
          className="w-full p-3 border rounded-lg h-24"
        />
        <button
          onClick={handleQuery}
          disabled={loading}
          className="bg-blue-600 text-white px-6 py-2 rounded-lg hover:bg-blue-700 disabled:opacity-50"
        >
          {loading ? 'Processing...' : 'Ask PyNucleus'}
        </button>
        {result && (
          <div className="bg-gray-50 p-4 rounded-lg">
            <h3 className="font-semibold mb-2">Answer:</h3>
            <p>{result.answer}</p>
            {result.sources && (
              <div className="mt-3">
                <h4 className="font-medium">Sources:</h4>
                <ul className="list-disc list-inside text-sm text-gray-600">
                  {result.sources.map((source, i) => <li key={i}>{source}</li>)}
                </ul>
              </div>
            )}
          </div>
        )}
      </div>
    </div>
  );
}

export default App;
```

### **3.4 Docker Configuration**

#### **Multi-Stage Dockerfile**
```dockerfile
# File: docker/Dockerfile.production
# Stage 1: Builder
FROM python:3.11-slim as builder

WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Stage 2: Runtime
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# Copy Python packages from builder
COPY --from=builder /usr/local/lib/python3.11/site-packages /usr/local/lib/python3.11/site-packages
COPY --from=builder /usr/local/bin /usr/local/bin

# Copy application code
COPY src/ ./src/
COPY configs/ ./configs/
COPY data/04_models/ ./data/04_models/  # Pre-built FAISS index
COPY docker/entrypoint.sh ./entrypoint.sh

# Install PyNucleus in production mode
RUN pip install -e . --no-deps

# Create non-root user
RUN useradd -m -u 1000 pynucleus && chown -R pynucleus:pynucleus /app
USER pynucleus

EXPOSE 5000
CMD ["./entrypoint.sh"]
```

#### **Production Docker Compose**
```yaml
# File: docker/docker-compose.production.yml
version: '3.8'

services:
  pynucleus-api:
    build:
      context: ..
      dockerfile: docker/Dockerfile.production
    ports:
      - "5000:5000"
    environment:
      - FLASK_ENV=production
      - PYNUCLEUS_API_KEY=${PYNUCLEUS_API_KEY}
      - MODEL_DIR=/app/data/04_models
      - DEVICE=cpu
      - VSTORE_BACKEND=faiss
      - LOG_LEVEL=INFO
    volumes:
      - ./logs:/app/logs
      - ./data/05_output:/app/data/05_output
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl  # SSL certificates
    depends_on:
      - pynucleus-api
    restart: unless-stopped
```

### **3.5 Environment Configuration**

| Variable | Default | Description |
|----------|---------|-------------|
| `FLASK_ENV` | `development` | Flask environment (development/production) |
| `PYNUCLEUS_API_KEY` | `None` | API authentication key |
| `MODEL_DIR` | `data/04_models` | Directory for FAISS indices and models |
| `DEVICE` | `cpu` | Compute device (cpu/cuda) |
| `VSTORE_BACKEND` | `faiss` | Vector store backend (faiss/chroma) |
| `LLM_MODEL_ID` | `tiiuae/falcon-rw-0.3b` | Default LLM model |
| `MAX_TOKENS` | `512` | Maximum LLM response tokens |
| `TEMPERATURE` | `0.7` | LLM sampling temperature |
| `LOG_LEVEL` | `INFO` | Logging level (DEBUG/INFO/WARNING/ERROR) |
| `DATA_DIR` | `data` | Base data directory |
| `RESULTS_DIR` | `data/05_output` | Results output directory |
| `CHUNK_SIZE` | `512` | Document chunking size |
| `SIMILARITY_THRESHOLD` | `0.7` | Vector search similarity threshold |

---

## 4. ðŸ§ª LLM Integration & Testing Strategy

### **4.1 Testing Framework Architecture**

#### **Unit Tests** (pytest)
```python
# File: tests/test_api.py
import pytest
from pynucleus.api.app import app

@pytest.fixture
def client():
    app.config['TESTING'] = True
    with app.test_client() as client:
        yield client

def test_health_endpoint(client):
    """Test system health endpoint"""
    response = client.get('/health')
    assert response.status_code == 200
    data = response.get_json()
    assert data['status'] == 'healthy'
    assert 'components' in data

def test_ask_endpoint(client):
    """Test question-answering endpoint"""
    response = client.post('/ask', json={'question': 'What is distillation?'})
    assert response.status_code == 200
    data = response.get_json()
    assert 'answer' in data
    assert 'sources' in data
    assert 'confidence' in data
```

#### **Integration Tests** (Flask test client)
```python
# File: tests/test_integration.py
import pytest
from pynucleus.pipeline import PipelineUtils
from pynucleus.rag.vector_store import RealFAISSVectorStore

def test_end_to_end_rag_query():
    """Test complete RAG pipeline"""
    pipeline = PipelineUtils()
    result = pipeline.rag_pipeline.query("How to optimize chemical processes?")
    
    assert result['answer'] is not None
    assert len(result['sources']) > 0
    assert result['confidence'] > 0.0

def test_dwsim_simulation_integration():
    """Test DWSIM simulation execution"""
    pipeline = PipelineUtils()
    config = {
        "case_name": "test_distillation",
        "type": "distillation",
        "components": "ethanol, water"
    }
    result = pipeline._dwsim_pipeline.run_simulation(config)
    
    assert result['success'] == True
    assert 'simulation_data' in result
```

### **4.2 RAG Evaluation Metrics**

#### **Self-Contained Q&A Dataset**
```csv
# File: tests/data/rag_evaluation_qa.csv
question,expected_answer_keywords,context_type,difficulty
"What is distillation?","separation,boiling,vapor,liquid","general",1
"How to optimize reactor conversion?","temperature,pressure,catalyst,residence","simulation",2
"Best practices for heat exchanger design?","area,temperature,flow,efficiency","technical",3
"Economic analysis of modular plants?","capex,opex,roi,payback","financial",2
"Safety considerations for chemical processes?","hazard,risk,safety,emergency","safety",3
```

#### **Evaluation Metrics Implementation**
```python
# File: tests/evaluation/rag_metrics.py
import pandas as pd
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

class RAGEvaluator:
    def __init__(self):
        self.model = SentenceTransformer('all-MiniLM-L6-v2')
    
    def evaluate_answer_quality(self, question: str, generated_answer: str, expected_keywords: list) -> dict:
        """Evaluate generated answer quality"""
        
        # Keyword coverage
        keyword_coverage = sum(1 for kw in expected_keywords if kw.lower() in generated_answer.lower()) / len(expected_keywords)
        
        # Semantic similarity (if reference answer provided)
        question_emb = self.model.encode([question])
        answer_emb = self.model.encode([generated_answer])
        relevance_score = cosine_similarity(question_emb, answer_emb)[0][0]
        
        # Length and completeness
        completeness_score = min(len(generated_answer.split()) / 50, 1.0)  # Target ~50 words
        
        return {
            'keyword_coverage': keyword_coverage,
            'relevance_score': float(relevance_score),
            'completeness_score': completeness_score,
            'overall_score': (keyword_coverage * 0.4 + relevance_score * 0.4 + completeness_score * 0.2)
        }
    
    def run_full_evaluation(self, qa_dataset_path: str) -> dict:
        """Run complete evaluation on Q&A dataset"""
        df = pd.read_csv(qa_dataset_path)
        results = []
        
        for _, row in df.iterrows():
            # Generate answer using PyNucleus
            generated_answer = self.query_pynucleus(row['question'])
            
            # Evaluate
            metrics = self.evaluate_answer_quality(
                row['question'], 
                generated_answer, 
                row['expected_answer_keywords'].split(',')
            )
            
            results.append({
                'question': row['question'],
                'context_type': row['context_type'],
                'difficulty': row['difficulty'],
                **metrics
            })
        
        # Aggregate metrics
        results_df = pd.DataFrame(results)
        return {
            'overall_score': results_df['overall_score'].mean(),
            'by_context': results_df.groupby('context_type')['overall_score'].mean().to_dict(),
            'by_difficulty': results_df.groupby('difficulty')['overall_score'].mean().to_dict(),
            'detailed_results': results
        }
```

### **4.3 CI/CD Integration**

#### **GitHub Actions Workflow**
```yaml
# File: .github/workflows/test_and_deploy.yml
name: PyNucleus Test & Deploy

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.9, 3.11]
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install -e .
    
    - name: Run unit tests
      run: pytest tests/unit/ -v --cov=src/pynucleus
    
    - name: Run integration tests
      run: pytest tests/integration/ -v
    
    - name: Run RAG evaluation
      run: python tests/evaluation/run_rag_eval.py
    
    - name: Test CLI commands
      run: |
        pynucleus --help
        pynucleus run --help
        pynucleus ask --help
    
    - name: End-to-end conversation test
      run: |
        echo "What is distillation?" | pynucleus ask --model-id tiiuae/falcon-rw-0.3b > e2e_result.txt
        if grep -q "distillation" e2e_result.txt; then echo "E2E test passed"; else exit 1; fi

  deploy:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Build Docker image
      run: docker build -f docker/Dockerfile.production -t pynucleus:latest .
    
    - name: Deploy to staging
      run: |
        # Deploy to staging environment
        echo "Deploying to staging..."
```

---

## 5. ðŸ“… Phased Timeline (Gantt-style)

### **Phase 0: CLI Completion** (Â½ day - 4 hours)
```
Day 1 Morning (4 hours):
â”œâ”€â”€ 09:00-10:30 â”‚ Add missing Typer commands (ingest, build-faiss, ask)
â”œâ”€â”€ 10:30-11:00 â”‚ Fix import paths and test all entry points  
â”œâ”€â”€ 11:00-11:30 â”‚ Run ruff --fix and black for linting cleanup
â””â”€â”€ 11:30-12:00 â”‚ Final CLI testing and validation
```

**Deliverables**:
- âœ… All CLI commands functional
- âœ… Clean linting (100% compliance)
- âœ… Entry points verified

### **Phase 1: Flask API Scaffold** (1 day - 8 hours)
```
Day 1 Afternoon + Day 2 Morning:
â”œâ”€â”€ 13:00-15:00 â”‚ Create Flask app with /health, /ingest, /ask endpoints
â”œâ”€â”€ 15:00-16:00 â”‚ Add authentication and rate limiting
â”œâ”€â”€ 16:00-17:00 â”‚ Error handling and request validation
â”œâ”€â”€ 09:00-11:00 â”‚ Integration with existing PyNucleus pipeline
â”œâ”€â”€ 11:00-12:00 â”‚ API testing and documentation
â””â”€â”€ 12:00-13:00 â”‚ Performance optimization and caching
```

**Deliverables**:
- âœ… Functional Flask API
- âœ… All endpoints working with PyNucleus backend
- âœ… Basic security and rate limiting

### **Phase 2: UI + Docker** (1 day - 8 hours)
```
Day 2 Afternoon + Day 3 Morning:
â”œâ”€â”€ 13:00-15:00 â”‚ Create HTML/JS frontend with HTMX
â”œâ”€â”€ 15:00-16:00 â”‚ Styling with Tailwind CSS
â”œâ”€â”€ 16:00-17:00 â”‚ Frontend-API integration
â”œâ”€â”€ 09:00-10:30 â”‚ Production Dockerfile (multi-stage build)
â”œâ”€â”€ 10:30-11:30 â”‚ Docker Compose with Nginx
â””â”€â”€ 11:30-12:00 â”‚ Container testing and optimization
```

**Deliverables**:
- âœ… Working web interface
- âœ… Production Docker containers
- âœ… Full deployment stack

### **Phase 3: LLM Evaluation Harness** (1 day - 8 hours)
```
Day 3 Afternoon + Day 4 Morning:
â”œâ”€â”€ 13:00-14:30 â”‚ Create Q&A evaluation dataset
â”œâ”€â”€ 14:30-16:00 â”‚ Implement RAG evaluation metrics
â”œâ”€â”€ 16:00-17:00 â”‚ Unit and integration test suite
â”œâ”€â”€ 09:00-10:30 â”‚ CI/CD pipeline setup (GitHub Actions)
â”œâ”€â”€ 10:30-11:30 â”‚ End-to-end conversation testing
â””â”€â”€ 11:30-12:00 â”‚ Performance benchmarking and reporting
```

**Deliverables**:
- âœ… Automated testing framework
- âœ… CI/CD pipeline
- âœ… Quality metrics and benchmarks

---

## 6. ðŸ‘¥ Ownership & Next Steps

### **Task Ownership Matrix**

| Task | Owner | ETA | Status |
|------|-------|-----|--------|
| **Phase 0: CLI Completion** | Senior Engineer | Jan 18 PM | Ready to start |
| Add missing Typer commands | Backend Developer | 2 hours | - |
| Import path fixes | DevOps Engineer | 1 hour | - |
| Linting cleanup | Any Developer | 30 min | - |
| **Phase 1: Flask API** | Full-Stack Developer | Jan 19 | Ready to start |
| API endpoint implementation | Backend Developer | 4 hours | - |
| Authentication & security | Security Engineer | 2 hours | - |
| Pipeline integration | Senior Engineer | 2 hours | - |
| **Phase 2: UI + Docker** | Frontend + DevOps | Jan 20 | Ready to start |
| HTML/JS interface | Frontend Developer | 3 hours | - |
| Docker containerization | DevOps Engineer | 3 hours | - |
| Deployment testing | QA Engineer | 2 hours | - |
| **Phase 3: Testing & CI** | QA + DevOps | Jan 21 | Ready to start |
| Evaluation framework | ML Engineer | 4 hours | - |
| CI/CD pipeline | DevOps Engineer | 2 hours | - |
| Performance testing | QA Engineer | 2 hours | - |

### **Critical Path Dependencies**
1. **Phase 0** â†’ **Phase 1**: CLI must be complete before API wrapper
2. **Phase 1** â†’ **Phase 2**: API must be functional before UI integration
3. **Phase 2** â†’ **Phase 3**: Deployment stack needed for CI/CD testing

### **Risk Mitigation**
- **Model Loading**: FAISS index (7GB) requires sufficient memory - ensure Docker limits
- **LLM Performance**: Falcon-0.3b may be slow - consider GPU acceleration or model swap
- **Concurrency**: Flask dev server won't handle production load - use Gunicorn + Nginx

### **GitHub Issues (Create These)**
1. [Issue #1](https://github.com/org/PyNucleus-Model/issues/1): Complete CLI Typer commands (Phase 0)
2. [Issue #2](https://github.com/org/PyNucleus-Model/issues/2): Flask API implementation (Phase 1)  
3. [Issue #3](https://github.com/org/PyNucleus-Model/issues/3): Web UI and Docker deployment (Phase 2)
4. [Issue #4](https://github.com/org/PyNucleus-Model/issues/4): Testing framework and CI/CD (Phase 3)

### **Success Metrics**
- **Phase 0**: All CLI commands pass `pytest tests/test_cli.py`
- **Phase 1**: API responds to health check and question queries within 5 seconds
- **Phase 2**: Docker container starts and serves UI within 30 seconds
- **Phase 3**: CI pipeline runs full test suite in under 10 minutes

---

## ðŸ“ž **Support & Contact**

**Project Lead**: Senior Engineer  
**Technical Questions**: Backend Team  
**Deployment Issues**: DevOps Team  
**UI/UX Feedback**: Frontend Team  

**Documentation**: `docs/` folder contains detailed technical guides  
**Bug Reports**: Use GitHub Issues with appropriate labels  
**Feature Requests**: Discuss in team meetings before implementation

---

**ðŸŽ¯ Total Timeline: 3.5 days to full production deployment**  
**ðŸš€ Current Status: All core features complete, ready for CLI finalization and deployment** 