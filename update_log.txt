2025-06-04 12:38:21 Log:
- Fixed a minor issue in the data processing pipeline. The script now correctly processes the data and generates the necessary outputs.
2025-06-04 12:50:22 changes made and pushed to origin main


 2025-06-04 12:50:49: Log Update
- Right now the data scrapping script scrapes wikipedia only. Future work can be paid services for Google API as we have tried to use python library but the error 429.2025-06-04 13:23:04 changes made and pushed to origin main
- Finished with the data chunking code and analysis and is ready for use 
- Next to work on the Vector DB code 
2025-06-04 13:24:12 changes made and pushed to origin main

2025-06-04 14:09:22 Log Update
- Implemented VectorDB setup and management system using FAISS
- Added comprehensive output logging with score explanations
- Script has the following features:
  * Embedding model setup using sentence-transformers
  * FAISS vector database creation and management
  * Semantic search functionality with similarity scoring
  * Detailed output logging to text files
  * Score explanations and quality metrics
- Tested with multiple queries related to modular design and chemical plants
- Output files are now saved in vectordb_outputs directory with timestamps
-Updated the README.md file 


 2025-06-04 15:58:48 changes made and pushed to origin main

- all codes have been transferred into their own .py file for formatting purposes. The main notebook contains only function calling now
- new file named performance_analyzer have been created to measure the performance of the model 

To Do: 
- Need to figure out why the function calling is not working in the main .ipynb for performance_analyzer but works in the performance_analyzer.py
- Need to work on the process simulation integration and python scriptting
- Need to work on API integration for cost of goods, news, and others 
- Need to create a script that would clean the data before ingesting into LLM or VectorDB (to veryify best approach)
- understand the structure and how to view the vectorDB data 

 2025-06-04 17:58:12 changes made and pushed to origin main

Need to connect github to Docker so that the below steps are followed: 
# 1) Mono + Debian base
FROM mono:6.12.0 AS mono-base

# 2) Install Python 3 and pip, then pythonnet & ML deps
RUN apt-get update && apt-get install -y \
        python3 python3-pip \
    && pip3 install --upgrade pip \
    && pip3 install \
        pythonnet \
        pandas \
        faiss-cpu \
        transformers \
        torch \
        langchain \
        openai \
        openpyxl

# 3) Copy DWSIM assemblies into monoâ€™s GAC path
#    (adjust source path if you checked them into your repo under /libs)
COPY libs/DWSIM.Thermodynamics.dll /usr/local/lib/mono/4.5/
COPY libs/DWSIM.Interfaces.dll     /usr/local/lib/mono/4.5/

# 4) Copy your RAG + simulation code
WORKDIR /app
COPY . /app

# 5) Set entrypoint (you can override in `docker run`)
ENTRYPOINT ["python3", "run_pipeline.py"]
CMD ["--help"]


 2025-06-09 15:12:14 changes made and pushed to origin main
