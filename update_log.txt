2025-06-04 12:38:21 Log:
- Fixed a minor issue in the data processing pipeline. The script now correctly processes the data and generates the necessary outputs.
2025-06-04 12:50:22 changes made and pushed to origin main


 2025-06-05 12:50:49: Log Update
- Right now the data scrapping script scrapes wikipedia only. Future work can be paid services for Google API as we have tried to use python library but the error 429.2025-06-04 13:23:04 changes made and pushed to origin main
- Finished with the data chunking code and analysis and is ready for use 
- Next to work on the Vector DB code 
2025-06-04 13:24:12 changes made and pushed to origin main

2025-06-04 14:09:22 Log Update
- Implemented VectorDB setup and management system using FAISS
- Added comprehensive output logging with score explanations
- Script has the following features:
  * Embedding model setup using sentence-transformers
  * FAISS vector database creation and management
  * Semantic search functionality with similarity scoring
  * Detailed output logging to text files
  * Score explanations and quality metrics
- Tested with multiple queries related to modular design and chemical plants
- Output files are now saved in vectordb_outputs directory with timestamps
-Updated the README.md file 


 2025-06-06 15:58:48 changes made and pushed to origin main

- all codes have been transferred into their own .py file for formatting purposes. The main notebook contains only function calling now
- new file named performance_analyzer have been created to measure the performance of the model 

To Do: 
- Need to figure out why the function calling is not working in the main .ipynb for performance_analyzer but works in the performance_analyzer.py
- Need to work on the process simulation integration and python scriptting
- Need to work on API integration for cost of goods, news, and others 
- Need to create a script that would clean the data before ingesting into LLM or VectorDB (to veryify best approach)
- understand the structure and how to view the vectorDB data 

 2025-06-07 17:58:12 changes made and pushed to origin main
 1) need to connect docker to the system so that it can on anything 
 2) need to fix the issue of pull from github because it is not pulling the latest update on github 

  2025-06-08 01:20:12 
  1) updated the folders and the did full clean house of the files naming and folders 
  2) implemented docker settings for cross board implementation of the system 
  3) enhanced the RAG sysstem implementation so that it is more efficient 
  4) tested the pipeline and made sure everything is working well 
  5) createed a file name system_diagonstic.py that can tell what is being wrong and should be enhanced frequently 
  6) installed the DWSIM lib successfully
  
  To Do: 
  1) Confirm everything is good from the docker app 
  2) start testing the DWSIM simulation 
  

 2025-06-10 01:33:47 changes made and pushed to origin main

1) New updates have been made in terms of formatting and organization of the folders 
2) system check and output verifications have been completed with satisfactory output 
3) new config.py have been created to include all configuration requirements 
4) DWSIM is now functionating and all results are converted to .csv files 
5) the .ipynb file Capstone Project have been revised so that it covers DWSIM, data processing, chuncking and converting to VectorDB 
6) all folders have been updated so that it is organized as per the function 


To do: 
1) update the code to include DWSIM script for window so that it switches seamsly between hosting API and using windows
2) update system_diagonstic.py to be aligned with the new changes 
3) Need to work on the DWSIM conversion to be understood by the RAG and to have input and output integration between the two 
4) The results and analysis should then be converted to a .txt file so that it is used as input to the LLM model to have a robust output 
5) Need to revise the DWSIM so that it can be easily adjusted later 

 2025-06-10 16:27:15 changes made and pushed to origin main
 Completed: 
1) Need to work on the DWSIM conversion to be understood by the RAG and to have input and output integration between the two 
2) The results and analysis should then be converted to a .txt file so that it is used as input to the LLM model to have a robust output 
3) Need to revise the DWSIM so that it can be easily adjusted later
4) the .ipynb have been revised to include both basic pipeline and advanced pipeline with integration ready context to be fed to the LLM 

To Do: 
1) update the code to include DWSIM script for window so that it switches seamsly between hosting API and using windows
2) update system_diagonstic.py to be aligned with the new changes 
3) change the folders directory for different outputs like LLM and the results 
4) make sure that the LLM ready document has the feed conditions which can be fetched easily from .json value 
5) update the @project_structure.md to have everything updated 
6) run another docker build 
 2025-06-10 17:46:14 changes made and pushed to origin main

Completed: 
1) change the folders directory for different outputs like LLM and the results 
2) make sure that the LLM ready document has the feed conditions which can be fetched easily from .json value 
3) update the @project_structure.md to have everything updated 
4) run another docker build- it is needed to build anything. Note: the current builder covers only the DWSIM API calling 
5) ran everything and everything is working fine 
6) update the code to include DWSIM script for window so that it switches seamsly between hosting API and using windows

To Do: 
1) Enhance the system based on the generated output from ChatGPT to enhance the overall structure of the system before proceeding with LLM integration
2) fix the DWSIM pipeline and remove mocked data from output if possible 
3) Start implementing the LLM in google colab... but write the full script here with or very small model before transferring to google colab 


 2025-06-10 21:28:05 changes made and pushed to origin main
Completed: 
1) src-layout migration (core_modules â†’ src/pynucleus)- completed
2) Data directory consolidation- Completed 
3) Pydantic settings + ConfigManager refactor- Completed 
4) Jinja2 templating for LLMOutputGenerator- Completed 


To Do: 



 2025-06-10 23:02:23 changes made and pushed to origin main
