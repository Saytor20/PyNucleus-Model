2025-06-11 18:33:50 | [32mINFO[0m | pynucleus                      | 📋 Logging configured (INFO level)
2025-06-11 18:33:50 | [32mINFO[0m | pynucleus                      | 📁 Log file: logs/pipeline.log
2025-06-11 18:33:50 | [32mINFO[0m | pynucleus.run_pipeline         | 🚀 Starting Pipeline-and-Ask command
2025-06-11 18:33:50 | [32mINFO[0m | pynucleus.run_pipeline         | 📋 Configuration: /var/folders/9z/fhqbcx0d6sqc_273srv0dv300000gn/T/tmpzqjhk0qk/missing_config.json
2025-06-11 18:33:50 | [32mINFO[0m | pynucleus.run_pipeline         | ❓ Question: What are the key findings?
2025-06-11 18:33:50 | [32mINFO[0m | pynucleus.run_pipeline         | 🤖 Model ID: gpt2
2025-06-11 18:33:50 | [32mINFO[0m | pynucleus.run_pipeline         | 📁 Output directory: /var/folders/9z/fhqbcx0d6sqc_273srv0dv300000gn/T/tmpzqjhk0qk/output
2025-06-11 18:33:50 | [31mERROR[0m | pynucleus.run_pipeline         | ❌ Configuration file not found: /var/folders/9z/fhqbcx0d6sqc_273srv0dv300000gn/T/tmpzqjhk0qk/missing_config.json
2025-06-11 18:33:50 | [31mERROR[0m | pynucleus.run_pipeline         | ❌ Command failed: exceptions must derive from BaseException
2025-06-11 18:33:50 | [32mINFO[0m | pynucleus.run_pipeline         | 🚀 Starting Pipeline-and-Ask command
2025-06-11 18:33:50 | [32mINFO[0m | pynucleus.run_pipeline         | 📋 Configuration: /var/folders/9z/fhqbcx0d6sqc_273srv0dv300000gn/T/tmp_zcbtu38/test_config.json
2025-06-11 18:33:50 | [32mINFO[0m | pynucleus.run_pipeline         | ❓ Question: What are the key findings?
2025-06-11 18:33:50 | [32mINFO[0m | pynucleus.run_pipeline         | 🤖 Model ID: gpt2
2025-06-11 18:33:50 | [32mINFO[0m | pynucleus.run_pipeline         | 📁 Output directory: /var/folders/9z/fhqbcx0d6sqc_273srv0dv300000gn/T/tmp_zcbtu38/output
2025-06-11 18:33:50 | [32mINFO[0m | pynucleus.run_pipeline         | ⚙️ Loading configuration...
2025-06-11 18:33:50 | [32mINFO[0m | pynucleus.run_pipeline         | ✅ Configuration loaded successfully
2025-06-11 18:33:50 | [31mERROR[0m | pynucleus.run_pipeline         | ❌ Pipeline execution failed
2025-06-11 18:33:50 | [31mERROR[0m | pynucleus.run_pipeline         | ❌ Command failed: exceptions must derive from BaseException
2025-06-11 18:33:50 | [32mINFO[0m | pynucleus.run_pipeline         | 🚀 Starting Pipeline-and-Ask command
2025-06-11 18:33:50 | [32mINFO[0m | pynucleus.run_pipeline         | 📋 Configuration: /var/folders/9z/fhqbcx0d6sqc_273srv0dv300000gn/T/tmpsomdzrux/test_config.json
2025-06-11 18:33:50 | [32mINFO[0m | pynucleus.run_pipeline         | ❓ Question: What are the key findings?
2025-06-11 18:33:50 | [32mINFO[0m | pynucleus.run_pipeline         | 🤖 Model ID: gpt2
2025-06-11 18:33:50 | [32mINFO[0m | pynucleus.run_pipeline         | 📁 Output directory: /var/folders/9z/fhqbcx0d6sqc_273srv0dv300000gn/T/tmpsomdzrux/output
2025-06-11 18:33:50 | [32mINFO[0m | pynucleus.run_pipeline         | ⚙️ Loading configuration...
2025-06-11 18:33:50 | [32mINFO[0m | pynucleus.run_pipeline         | ✅ Configuration loaded successfully
2025-06-11 18:33:50 | [32mINFO[0m | pynucleus.run_pipeline         | 📄 Using report: /var/folders/9z/fhqbcx0d6sqc_273srv0dv300000gn/T/tmpsomdzrux/output/llm_reports/test_report.md
2025-06-11 18:33:50 | [32mINFO[0m | pynucleus.run_pipeline         | 🤖 LLM Manager initialized with model: gpt2
2025-06-11 18:33:50 | [32mINFO[0m | pynucleus.run_pipeline         | ✅ LLM query completed successfully
2025-06-11 18:34:40 | [32mINFO[0m | pynucleus                      | 📋 Logging configured (INFO level)
2025-06-11 18:34:40 | [32mINFO[0m | pynucleus                      | 📁 Log file: logs/pipeline.log
2025-06-11 18:34:40 | [32mINFO[0m | pynucleus.run_pipeline         | 🚀 Starting Pipeline-and-Ask command
2025-06-11 18:34:40 | [32mINFO[0m | pynucleus.run_pipeline         | 📋 Configuration: /var/folders/9z/fhqbcx0d6sqc_273srv0dv300000gn/T/tmp_6ubn2xv/missing_config.json
2025-06-11 18:34:40 | [32mINFO[0m | pynucleus.run_pipeline         | ❓ Question: What are the key findings?
2025-06-11 18:34:40 | [32mINFO[0m | pynucleus.run_pipeline         | 🤖 Model ID: gpt2
2025-06-11 18:34:40 | [32mINFO[0m | pynucleus.run_pipeline         | 📁 Output directory: /var/folders/9z/fhqbcx0d6sqc_273srv0dv300000gn/T/tmp_6ubn2xv/output
2025-06-11 18:34:40 | [31mERROR[0m | pynucleus.run_pipeline         | ❌ Configuration file not found: /var/folders/9z/fhqbcx0d6sqc_273srv0dv300000gn/T/tmp_6ubn2xv/missing_config.json
2025-06-11 18:34:40 | [31mERROR[0m | pynucleus.run_pipeline         | ❌ Command failed: exceptions must derive from BaseException
2025-06-11 18:34:40 | [32mINFO[0m | pynucleus.run_pipeline         | 🚀 Starting Pipeline-and-Ask command
2025-06-11 18:34:40 | [32mINFO[0m | pynucleus.run_pipeline         | 📋 Configuration: /var/folders/9z/fhqbcx0d6sqc_273srv0dv300000gn/T/tmp_nc6i9e4/test_config.json
2025-06-11 18:34:40 | [32mINFO[0m | pynucleus.run_pipeline         | ❓ Question: What are the key findings?
2025-06-11 18:34:40 | [32mINFO[0m | pynucleus.run_pipeline         | 🤖 Model ID: gpt2
2025-06-11 18:34:40 | [32mINFO[0m | pynucleus.run_pipeline         | 📁 Output directory: /var/folders/9z/fhqbcx0d6sqc_273srv0dv300000gn/T/tmp_nc6i9e4/output
2025-06-11 18:34:40 | [32mINFO[0m | pynucleus.run_pipeline         | ⚙️ Loading configuration...
2025-06-11 18:34:40 | [32mINFO[0m | pynucleus.run_pipeline         | ✅ Configuration loaded successfully
2025-06-11 18:34:40 | [31mERROR[0m | pynucleus.run_pipeline         | ❌ Pipeline execution failed
2025-06-11 18:34:40 | [31mERROR[0m | pynucleus.run_pipeline         | ❌ Command failed: exceptions must derive from BaseException
2025-06-11 18:34:40 | [32mINFO[0m | pynucleus.run_pipeline         | 🚀 Starting Pipeline-and-Ask command
2025-06-11 18:34:40 | [32mINFO[0m | pynucleus.run_pipeline         | 📋 Configuration: /var/folders/9z/fhqbcx0d6sqc_273srv0dv300000gn/T/tmpw9plbw04/test_config.json
2025-06-11 18:34:40 | [32mINFO[0m | pynucleus.run_pipeline         | ❓ Question: What are the key findings?
2025-06-11 18:34:40 | [32mINFO[0m | pynucleus.run_pipeline         | 🤖 Model ID: gpt2
2025-06-11 18:34:40 | [32mINFO[0m | pynucleus.run_pipeline         | 📁 Output directory: /var/folders/9z/fhqbcx0d6sqc_273srv0dv300000gn/T/tmpw9plbw04/output
2025-06-11 18:34:40 | [32mINFO[0m | pynucleus.run_pipeline         | ⚙️ Loading configuration...
2025-06-11 18:34:40 | [32mINFO[0m | pynucleus.run_pipeline         | ✅ Configuration loaded successfully
2025-06-11 18:34:40 | [32mINFO[0m | pynucleus.run_pipeline         | 📄 Using report: /var/folders/9z/fhqbcx0d6sqc_273srv0dv300000gn/T/tmpw9plbw04/output/llm_reports/test_report.md
2025-06-11 18:34:40 | [32mINFO[0m | pynucleus.run_pipeline         | 🤖 LLM Manager initialized with model: gpt2
2025-06-11 18:34:40 | [32mINFO[0m | pynucleus.run_pipeline         | ✅ LLM query completed successfully
2025-06-11 18:35:20 | [36mDEBUG[0m | pynucleus                      | 🔧 Debug logging enabled
2025-06-11 18:35:20 | [36mDEBUG[0m | pynucleus                      | 📁 Log file: logs/pipeline.log
2025-06-11 18:35:20 | [36mDEBUG[0m | pynucleus                      | 📊 Console output: True
2025-06-11 18:35:20 | [36mDEBUG[0m | pynucleus                      | 💾 File output: True
2025-06-11 18:35:20 | [32mINFO[0m | pynucleus.main                 | 🚀 Starting Pipeline-and-Ask command
2025-06-11 18:35:20 | [32mINFO[0m | pynucleus.main                 | 📋 Configuration: configs/simulation_config_template.json
2025-06-11 18:35:20 | [32mINFO[0m | pynucleus.main                 | ❓ Question: What are the key performance metrics from this simulation report?
2025-06-11 18:35:20 | [32mINFO[0m | pynucleus.main                 | 🤖 Model ID: gpt2
2025-06-11 18:35:20 | [32mINFO[0m | pynucleus.main                 | 📁 Output directory: data/05_output
2025-06-11 18:35:20 | [32mINFO[0m | pynucleus.main                 | ⚙️ Loading configuration...
2025-06-11 18:35:20 | [32mINFO[0m | pynucleus.main                 | ✅ Configuration loaded successfully
2025-06-11 18:35:20 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 🚀 Starting PyNucleus full pipeline...
2025-06-11 18:35:20 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 📁 Output directory: data/05_output
2025-06-11 18:35:20 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | ⚙️ Configuration: 1 simulations loaded
2025-06-11 18:35:20 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 🔍 RAG settings: top_k=5, threshold=0.3
2025-06-11 18:35:20 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 📝 LLM settings: summary_length=300
2025-06-11 18:35:20 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 🔄 Running complete pipeline (RAG + DWSIM + Export)
2025-06-11 18:35:20 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): packages.unstructured.io:443
2025-06-11 18:35:21 | [36mDEBUG[0m | urllib3.connectionpool         | https://packages.unstructured.io:443 "GET /python-telemetry?version=0.17.2&platform=Darwin&python3.13&arch=arm64&gpu=False&dev=false HTTP/1.1" 200 596
2025-06-11 18:35:21 | [33mWARNING[0m | unstructured                   | libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.
2025-06-11 18:35:21 | [33mWARNING[0m | unstructured                   | libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.
2025-06-11 18:35:22 | [33mWARNING[0m | unstructured                   | libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.
2025-06-11 18:35:22 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): en.wikipedia.org:443
2025-06-11 18:35:22 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /w/api.php?action=query&list=search&srsearch=modular%20design&format=json HTTP/1.1" 200 None
2025-06-11 18:35:22 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): en.wikipedia.org:443
2025-06-11 18:35:22 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /wiki/Modular%20design HTTP/1.1" 301 0
2025-06-11 18:35:22 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /wiki/Modular_design HTTP/1.1" 200 34687
2025-06-11 18:35:23 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): en.wikipedia.org:443
2025-06-11 18:35:23 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /w/api.php?action=query&list=search&srsearch=software%20architecture&format=json HTTP/1.1" 200 None
2025-06-11 18:35:23 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): en.wikipedia.org:443
2025-06-11 18:35:23 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /wiki/Software%20architecture HTTP/1.1" 301 0
2025-06-11 18:35:23 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /wiki/Software_architecture HTTP/1.1" 200 51657
2025-06-11 18:35:23 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): en.wikipedia.org:443
2025-06-11 18:35:24 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /w/api.php?action=query&list=search&srsearch=system%20design&format=json HTTP/1.1" 200 None
2025-06-11 18:35:24 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): en.wikipedia.org:443
2025-06-11 18:35:24 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /wiki/Systems%20design HTTP/1.1" 301 0
2025-06-11 18:35:24 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /wiki/Systems_design HTTP/1.1" 200 32779
2025-06-11 18:35:24 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): en.wikipedia.org:443
2025-06-11 18:35:25 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /w/api.php?action=query&list=search&srsearch=industrial%20design&format=json HTTP/1.1" 200 None
2025-06-11 18:35:25 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): en.wikipedia.org:443
2025-06-11 18:35:25 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /wiki/Industrial%20design HTTP/1.1" 301 0
2025-06-11 18:35:25 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /wiki/Industrial_design HTTP/1.1" 200 None
2025-06-11 18:35:25 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): en.wikipedia.org:443
2025-06-11 18:35:25 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /w/api.php?action=query&list=search&srsearch=supply%20chain&format=json HTTP/1.1" 200 None
2025-06-11 18:35:25 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): en.wikipedia.org:443
2025-06-11 18:35:25 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /wiki/Supply%20chain HTTP/1.1" 301 0
2025-06-11 18:35:26 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /wiki/Supply_chain HTTP/1.1" 200 48732
2025-06-11 18:35:26 | [32mINFO[0m | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-06-11 18:35:26 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): huggingface.co:443
2025-06-11 18:35:26 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-06-11 18:35:27 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 200 0
2025-06-11 18:35:27 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 200 0
2025-06-11 18:35:27 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-06-11 18:35:27 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json HTTP/1.1" 200 0
2025-06-11 18:35:27 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json HTTP/1.1" 404 0
2025-06-11 18:35:27 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 200 0
2025-06-11 18:35:28 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-06-11 18:35:28 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-06-11 18:35:28 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/revision/main HTTP/1.1" 200 6786
2025-06-11 18:35:28 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2 HTTP/1.1" 200 6786
2025-06-11 18:35:34 | [36mDEBUG[0m | faiss.loader                   | Environment variable FAISS_OPT_LEVEL is not set, so let's pick the instruction set according to the current CPU
2025-06-11 18:35:34 | [32mINFO[0m | faiss.loader                   | Loading faiss.
2025-06-11 18:35:34 | [32mINFO[0m | faiss.loader                   | Successfully loaded faiss.
2025-06-11 18:35:34 | [32mINFO[0m | faiss                          | Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-06-11 18:35:35 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | ✅ Pipeline completed successfully in 14.8s
2025-06-11 18:35:35 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 📊 Results: 15 RAG, 5 DWSIM
2025-06-11 18:35:35 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 📁 Files exported: 2
2025-06-11 18:35:35 | [32mINFO[0m | pynucleus.main                 | 📄 Using report: data/05_output/llm_reports/system_test_distillation_summary.md
2025-06-11 18:35:35 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /gpt2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-06-11 18:35:35 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "GET /api/models/gpt2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 133
2025-06-11 18:35:35 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "GET /api/models/openai-community/gpt2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-06-11 18:35:35 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /gpt2/resolve/main/config.json HTTP/1.1" 200 0
2025-06-11 18:35:35 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /gpt2/resolve/main/generation_config.json HTTP/1.1" 200 0
2025-06-11 18:35:35 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /gpt2/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
2025-06-11 18:35:35 | [32mINFO[0m | pynucleus.llm.query_llm        | Template environment set up with directory: /Users/mohammadalmusaiteer/PyNucleus-Model/prompt_templates
2025-06-11 18:35:35 | [32mINFO[0m | pynucleus.llm.query_llm        | LLMQueryManager initialized with model: gpt2, max_tokens: 8192
2025-06-11 18:35:35 | [32mINFO[0m | pynucleus.main                 | 🤖 LLM Manager initialized with model: gpt2
2025-06-11 18:35:35 | [32mINFO[0m | pynucleus.llm.query_llm        | Loaded report from data/05_output/llm_reports/system_test_distillation_summary.md (962 characters)
2025-06-11 18:35:35 | [36mDEBUG[0m | pynucleus.llm.query_llm        | Rendered prompt using template: qwen_prompt.j2
2025-06-11 18:35:35 | [32mINFO[0m | pynucleus.utils.token_utils    | Loading tokenizer for model: gpt2
2025-06-11 18:35:35 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /gpt2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-06-11 18:35:35 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "GET /api/models/gpt2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 133
2025-06-11 18:35:35 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "GET /api/models/openai-community/gpt2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-06-11 18:35:35 | [32mINFO[0m | pynucleus.llm.query_llm        | Base prompt tokens: 82, Reserved for generation: 2457
2025-06-11 18:35:35 | [36mDEBUG[0m | pynucleus.llm.query_llm        | Content fits within limits: 292/5653 tokens
2025-06-11 18:35:35 | [36mDEBUG[0m | pynucleus.llm.query_llm        | Rendered prompt using template: qwen_prompt.j2
2025-06-11 18:35:35 | [32mINFO[0m | pynucleus.llm.query_llm        | Final prompt tokens: 382/8192
2025-06-11 18:35:35 | [32mINFO[0m | pynucleus.llm.query_llm        | Querying LLM...
2025-06-11 18:35:38 | [32mINFO[0m | pynucleus.llm.query_llm        | LLM response generated (471 characters)
2025-06-11 18:35:38 | [32mINFO[0m | pynucleus.main                 | ✅ LLM query completed successfully
2025-06-11 18:35:53 | [36mDEBUG[0m | pynucleus                      | 🔧 Debug logging enabled
2025-06-11 18:35:53 | [36mDEBUG[0m | pynucleus                      | 📁 Log file: logs/pipeline.log
2025-06-11 18:35:53 | [36mDEBUG[0m | pynucleus                      | 📊 Console output: True
2025-06-11 18:35:53 | [36mDEBUG[0m | pynucleus                      | 💾 File output: True
2025-06-11 18:35:53 | [32mINFO[0m | pynucleus.main                 | 🚀 Starting Pipeline-and-Ask command
2025-06-11 18:35:53 | [32mINFO[0m | pynucleus.main                 | 📋 Configuration: configs/simulation_config_template.json
2025-06-11 18:35:53 | [32mINFO[0m | pynucleus.main                 | ❓ Question: What are the key findings from this simulation report?
2025-06-11 18:35:53 | [32mINFO[0m | pynucleus.main                 | 🤖 Model ID: gpt2
2025-06-11 18:35:53 | [32mINFO[0m | pynucleus.main                 | 📁 Output directory: data/05_output
2025-06-11 18:35:53 | [32mINFO[0m | pynucleus.main                 | ⚙️ Loading configuration...
2025-06-11 18:35:53 | [32mINFO[0m | pynucleus.main                 | ✅ Configuration loaded successfully
2025-06-11 18:35:53 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 🚀 Starting PyNucleus full pipeline...
2025-06-11 18:35:53 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 📁 Output directory: data/05_output
2025-06-11 18:35:53 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | ⚙️ Configuration: 1 simulations loaded
2025-06-11 18:35:53 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 🔍 RAG settings: top_k=5, threshold=0.3
2025-06-11 18:35:53 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 📝 LLM settings: summary_length=300
2025-06-11 18:35:53 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 🔄 Running complete pipeline (RAG + DWSIM + Export)
2025-06-11 18:35:53 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): packages.unstructured.io:443
2025-06-11 18:35:54 | [36mDEBUG[0m | urllib3.connectionpool         | https://packages.unstructured.io:443 "GET /python-telemetry?version=0.17.2&platform=Darwin&python3.13&arch=arm64&gpu=False&dev=false HTTP/1.1" 200 596
2025-06-11 18:35:54 | [33mWARNING[0m | unstructured                   | libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.
2025-06-11 18:35:54 | [33mWARNING[0m | unstructured                   | libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.
2025-06-11 18:35:55 | [33mWARNING[0m | unstructured                   | libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.
2025-06-11 18:35:55 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): en.wikipedia.org:443
2025-06-11 18:35:55 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /w/api.php?action=query&list=search&srsearch=modular%20design&format=json HTTP/1.1" 200 None
2025-06-11 18:35:55 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): en.wikipedia.org:443
2025-06-11 18:35:55 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /wiki/Modular%20design HTTP/1.1" 301 0
2025-06-11 18:35:55 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /wiki/Modular_design HTTP/1.1" 200 34687
2025-06-11 18:35:55 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): en.wikipedia.org:443
2025-06-11 18:35:56 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /w/api.php?action=query&list=search&srsearch=software%20architecture&format=json HTTP/1.1" 200 None
2025-06-11 18:35:56 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): en.wikipedia.org:443
2025-06-11 18:35:56 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /wiki/Software%20architecture HTTP/1.1" 301 0
2025-06-11 18:35:56 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /wiki/Software_architecture HTTP/1.1" 200 51657
2025-06-11 18:35:56 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): en.wikipedia.org:443
2025-06-11 18:35:56 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /w/api.php?action=query&list=search&srsearch=system%20design&format=json HTTP/1.1" 200 None
2025-06-11 18:35:56 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): en.wikipedia.org:443
2025-06-11 18:35:56 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /wiki/Systems%20design HTTP/1.1" 301 0
2025-06-11 18:35:57 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /wiki/Systems_design HTTP/1.1" 200 32779
2025-06-11 18:35:57 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): en.wikipedia.org:443
2025-06-11 18:35:57 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /w/api.php?action=query&list=search&srsearch=industrial%20design&format=json HTTP/1.1" 200 None
2025-06-11 18:35:57 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): en.wikipedia.org:443
2025-06-11 18:35:57 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /wiki/Industrial%20design HTTP/1.1" 301 0
2025-06-11 18:35:57 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /wiki/Industrial_design HTTP/1.1" 200 47625
2025-06-11 18:35:57 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): en.wikipedia.org:443
2025-06-11 18:35:58 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /w/api.php?action=query&list=search&srsearch=supply%20chain&format=json HTTP/1.1" 200 None
2025-06-11 18:35:58 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): en.wikipedia.org:443
2025-06-11 18:35:58 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /wiki/Supply%20chain HTTP/1.1" 301 0
2025-06-11 18:35:58 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /wiki/Supply_chain HTTP/1.1" 200 48732
2025-06-11 18:35:59 | [32mINFO[0m | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-06-11 18:35:59 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): huggingface.co:443
2025-06-11 18:36:00 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-06-11 18:36:00 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 200 0
2025-06-11 18:36:00 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 200 0
2025-06-11 18:36:00 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-06-11 18:36:00 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json HTTP/1.1" 200 0
2025-06-11 18:36:00 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json HTTP/1.1" 404 0
2025-06-11 18:36:00 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 200 0
2025-06-11 18:36:01 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-06-11 18:36:01 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-06-11 18:36:01 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/revision/main HTTP/1.1" 200 6786
2025-06-11 18:36:01 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2 HTTP/1.1" 200 6786
2025-06-11 18:36:08 | [36mDEBUG[0m | faiss.loader                   | Environment variable FAISS_OPT_LEVEL is not set, so let's pick the instruction set according to the current CPU
2025-06-11 18:36:08 | [32mINFO[0m | faiss.loader                   | Loading faiss.
2025-06-11 18:36:08 | [32mINFO[0m | faiss.loader                   | Successfully loaded faiss.
2025-06-11 18:36:08 | [32mINFO[0m | faiss                          | Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-06-11 18:36:08 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | ✅ Pipeline completed successfully in 14.6s
2025-06-11 18:36:08 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 📊 Results: 15 RAG, 5 DWSIM
2025-06-11 18:36:08 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 📁 Files exported: 2
2025-06-11 18:36:08 | [32mINFO[0m | pynucleus.main                 | 📄 Using report: data/05_output/llm_reports/system_test_distillation_summary.md
2025-06-11 18:36:08 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /gpt2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-06-11 18:36:08 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "GET /api/models/gpt2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 133
2025-06-11 18:36:08 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "GET /api/models/openai-community/gpt2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-06-11 18:36:08 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /gpt2/resolve/main/config.json HTTP/1.1" 200 0
2025-06-11 18:36:08 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /gpt2/resolve/main/generation_config.json HTTP/1.1" 200 0
2025-06-11 18:36:08 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /gpt2/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
2025-06-11 18:36:08 | [32mINFO[0m | pynucleus.llm.query_llm        | Template environment set up with directory: /Users/mohammadalmusaiteer/PyNucleus-Model/prompt_templates
2025-06-11 18:36:08 | [32mINFO[0m | pynucleus.llm.query_llm        | LLMQueryManager initialized with model: gpt2, max_tokens: 8192
2025-06-11 18:36:08 | [32mINFO[0m | pynucleus.main                 | 🤖 LLM Manager initialized with model: gpt2
2025-06-11 18:36:08 | [32mINFO[0m | pynucleus.llm.query_llm        | Loaded report from data/05_output/llm_reports/system_test_distillation_summary.md (962 characters)
2025-06-11 18:36:08 | [36mDEBUG[0m | pynucleus.llm.query_llm        | Rendered prompt using template: qwen_prompt.j2
2025-06-11 18:36:08 | [32mINFO[0m | pynucleus.utils.token_utils    | Loading tokenizer for model: gpt2
2025-06-11 18:36:08 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /gpt2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-06-11 18:36:08 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "GET /api/models/gpt2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 133
2025-06-11 18:36:08 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "GET /api/models/openai-community/gpt2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-06-11 18:36:08 | [32mINFO[0m | pynucleus.llm.query_llm        | Base prompt tokens: 81, Reserved for generation: 2457
2025-06-11 18:36:08 | [36mDEBUG[0m | pynucleus.llm.query_llm        | Content fits within limits: 292/5654 tokens
2025-06-11 18:36:08 | [36mDEBUG[0m | pynucleus.llm.query_llm        | Rendered prompt using template: qwen_prompt.j2
2025-06-11 18:36:08 | [32mINFO[0m | pynucleus.llm.query_llm        | Final prompt tokens: 381/8192
2025-06-11 18:36:08 | [32mINFO[0m | pynucleus.llm.query_llm        | Querying LLM...
2025-06-11 18:36:11 | [32mINFO[0m | pynucleus.llm.query_llm        | LLM response generated (235 characters)
2025-06-11 18:36:11 | [32mINFO[0m | pynucleus.main                 | ✅ LLM query completed successfully
2025-06-11 18:37:15 | [32mINFO[0m | pynucleus                      | 📋 Logging configured (INFO level)
2025-06-11 18:37:15 | [32mINFO[0m | pynucleus                      | 📁 Log file: logs/pipeline.log
2025-06-11 18:37:15 | [32mINFO[0m | pynucleus.main                 | 🚀 Starting Pipeline-and-Ask command
2025-06-11 18:37:15 | [32mINFO[0m | pynucleus.main                 | 📋 Configuration: configs/simulation_config_template.json
2025-06-11 18:37:15 | [32mINFO[0m | pynucleus.main                 | ❓ Question: What are the key performance metrics?
2025-06-11 18:37:15 | [32mINFO[0m | pynucleus.main                 | 🤖 Model ID: tiiuae/falcon-rw-0.3b
2025-06-11 18:37:15 | [32mINFO[0m | pynucleus.main                 | 📁 Output directory: data/05_output
2025-06-11 18:37:15 | [32mINFO[0m | pynucleus.main                 | ⚙️ Loading configuration...
2025-06-11 18:37:15 | [32mINFO[0m | pynucleus.main                 | ✅ Configuration loaded successfully
2025-06-11 18:37:15 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 🚀 Starting PyNucleus full pipeline...
2025-06-11 18:37:15 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 📁 Output directory: data/05_output
2025-06-11 18:37:15 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | ⚙️ Configuration: 1 simulations loaded
2025-06-11 18:37:15 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 🔍 RAG settings: top_k=5, threshold=0.3
2025-06-11 18:37:15 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 📝 LLM settings: summary_length=300
2025-06-11 18:37:16 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 🔄 Running complete pipeline (RAG + DWSIM + Export)
2025-06-11 18:37:16 | [33mWARNING[0m | unstructured                   | libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.
2025-06-11 18:37:17 | [33mWARNING[0m | unstructured                   | libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.
2025-06-11 18:37:17 | [33mWARNING[0m | unstructured                   | libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.
2025-06-11 18:37:22 | [32mINFO[0m | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-06-11 18:37:29 | [32mINFO[0m | faiss.loader                   | Loading faiss.
2025-06-11 18:37:29 | [32mINFO[0m | faiss.loader                   | Successfully loaded faiss.
2025-06-11 18:37:29 | [32mINFO[0m | faiss                          | Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-06-11 18:37:29 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | ✅ Pipeline completed successfully in 14.0s
2025-06-11 18:37:29 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 📊 Results: 15 RAG, 5 DWSIM
2025-06-11 18:37:29 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 📁 Files exported: 2
2025-06-11 18:37:29 | [32mINFO[0m | pynucleus.main                 | 📄 Using report: data/05_output/llm_reports/system_test_distillation_summary.md
2025-06-11 18:37:29 | [31mERROR[0m | pynucleus.main                 | ❌ LLM query failed: Failed to load model tiiuae/falcon-rw-0.3b: tiiuae/falcon-rw-0.3b is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
2025-06-11 18:37:29 | [31mERROR[0m | pynucleus.main                 | ❌ Command failed: 1
2025-06-11 18:37:32 | [36mDEBUG[0m | pynucleus                      | 🔧 Debug logging enabled
2025-06-11 18:37:32 | [36mDEBUG[0m | pynucleus                      | 📁 Log file: logs/pipeline.log
2025-06-11 18:37:32 | [36mDEBUG[0m | pynucleus                      | 📊 Console output: True
2025-06-11 18:37:32 | [36mDEBUG[0m | pynucleus                      | 💾 File output: True
2025-06-11 18:37:32 | [32mINFO[0m | pynucleus.main                 | 🚀 Starting Pipeline-and-Ask command
2025-06-11 18:37:32 | [32mINFO[0m | pynucleus.main                 | 📋 Configuration: configs/simulation_config_template.json
2025-06-11 18:37:32 | [32mINFO[0m | pynucleus.main                 | ❓ Question: What are the main findings?
2025-06-11 18:37:32 | [32mINFO[0m | pynucleus.main                 | 🤖 Model ID: gpt2
2025-06-11 18:37:32 | [32mINFO[0m | pynucleus.main                 | 📁 Output directory: data/05_output
2025-06-11 18:37:32 | [32mINFO[0m | pynucleus.main                 | ⚙️ Loading configuration...
2025-06-11 18:37:32 | [32mINFO[0m | pynucleus.main                 | ✅ Configuration loaded successfully
2025-06-11 18:37:32 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 🚀 Starting PyNucleus full pipeline...
2025-06-11 18:37:32 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 📁 Output directory: data/05_output
2025-06-11 18:37:32 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | ⚙️ Configuration: 1 simulations loaded
2025-06-11 18:37:32 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 🔍 RAG settings: top_k=5, threshold=0.3
2025-06-11 18:37:32 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 📝 LLM settings: summary_length=300
2025-06-11 18:37:32 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 🔄 Running complete pipeline (RAG + DWSIM + Export)
2025-06-11 18:37:32 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): packages.unstructured.io:443
2025-06-11 18:37:33 | [36mDEBUG[0m | urllib3.connectionpool         | https://packages.unstructured.io:443 "GET /python-telemetry?version=0.17.2&platform=Darwin&python3.13&arch=arm64&gpu=False&dev=false HTTP/1.1" 200 596
2025-06-11 18:37:33 | [33mWARNING[0m | unstructured                   | libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.
2025-06-11 18:37:33 | [33mWARNING[0m | unstructured                   | libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.
2025-06-11 18:37:34 | [33mWARNING[0m | unstructured                   | libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.
2025-06-11 18:37:34 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): en.wikipedia.org:443
2025-06-11 18:37:34 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /w/api.php?action=query&list=search&srsearch=modular%20design&format=json HTTP/1.1" 200 None
2025-06-11 18:37:34 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): en.wikipedia.org:443
2025-06-11 18:37:34 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /wiki/Modular%20design HTTP/1.1" 301 0
2025-06-11 18:37:34 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /wiki/Modular_design HTTP/1.1" 200 34687
2025-06-11 18:37:35 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): en.wikipedia.org:443
2025-06-11 18:37:35 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /w/api.php?action=query&list=search&srsearch=software%20architecture&format=json HTTP/1.1" 200 None
2025-06-11 18:37:35 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): en.wikipedia.org:443
2025-06-11 18:37:35 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /wiki/Software%20architecture HTTP/1.1" 301 0
2025-06-11 18:37:35 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /wiki/Software_architecture HTTP/1.1" 200 51657
2025-06-11 18:37:35 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): en.wikipedia.org:443
2025-06-11 18:37:36 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /w/api.php?action=query&list=search&srsearch=system%20design&format=json HTTP/1.1" 200 None
2025-06-11 18:37:36 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): en.wikipedia.org:443
2025-06-11 18:37:36 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /wiki/Systems%20design HTTP/1.1" 301 0
2025-06-11 18:37:36 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /wiki/Systems_design HTTP/1.1" 200 32779
2025-06-11 18:37:36 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): en.wikipedia.org:443
2025-06-11 18:37:36 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /w/api.php?action=query&list=search&srsearch=industrial%20design&format=json HTTP/1.1" 200 None
2025-06-11 18:37:36 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): en.wikipedia.org:443
2025-06-11 18:37:37 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /wiki/Industrial%20design HTTP/1.1" 301 0
2025-06-11 18:37:37 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /wiki/Industrial_design HTTP/1.1" 200 47625
2025-06-11 18:37:37 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): en.wikipedia.org:443
2025-06-11 18:37:37 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /w/api.php?action=query&list=search&srsearch=supply%20chain&format=json HTTP/1.1" 200 None
2025-06-11 18:37:37 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): en.wikipedia.org:443
2025-06-11 18:37:37 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /wiki/Supply%20chain HTTP/1.1" 301 0
2025-06-11 18:37:37 | [36mDEBUG[0m | urllib3.connectionpool         | https://en.wikipedia.org:443 "GET /wiki/Supply_chain HTTP/1.1" 200 48732
2025-06-11 18:37:38 | [32mINFO[0m | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-06-11 18:37:38 | [36mDEBUG[0m | urllib3.connectionpool         | Starting new HTTPS connection (1): huggingface.co:443
2025-06-11 18:37:38 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-06-11 18:37:38 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 200 0
2025-06-11 18:37:38 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 200 0
2025-06-11 18:37:38 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-06-11 18:37:38 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json HTTP/1.1" 200 0
2025-06-11 18:37:38 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json HTTP/1.1" 404 0
2025-06-11 18:37:38 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 200 0
2025-06-11 18:37:39 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-06-11 18:37:39 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-06-11 18:37:39 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/revision/main HTTP/1.1" 200 6786
2025-06-11 18:37:39 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2 HTTP/1.1" 200 6786
2025-06-11 18:37:45 | [36mDEBUG[0m | faiss.loader                   | Environment variable FAISS_OPT_LEVEL is not set, so let's pick the instruction set according to the current CPU
2025-06-11 18:37:45 | [32mINFO[0m | faiss.loader                   | Loading faiss.
2025-06-11 18:37:45 | [32mINFO[0m | faiss.loader                   | Successfully loaded faiss.
2025-06-11 18:37:45 | [32mINFO[0m | faiss                          | Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-06-11 18:37:45 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | ✅ Pipeline completed successfully in 13.0s
2025-06-11 18:37:45 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 📊 Results: 15 RAG, 5 DWSIM
2025-06-11 18:37:45 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 📁 Files exported: 2
2025-06-11 18:37:45 | [32mINFO[0m | pynucleus.main                 | 📄 Using report: data/05_output/llm_reports/system_test_distillation_summary.md
2025-06-11 18:37:45 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /gpt2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-06-11 18:37:45 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "GET /api/models/gpt2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 133
2025-06-11 18:37:45 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "GET /api/models/openai-community/gpt2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-06-11 18:37:45 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /gpt2/resolve/main/config.json HTTP/1.1" 200 0
2025-06-11 18:37:45 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /gpt2/resolve/main/generation_config.json HTTP/1.1" 200 0
2025-06-11 18:37:45 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /gpt2/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
2025-06-11 18:37:45 | [32mINFO[0m | pynucleus.llm.query_llm        | Template environment set up with directory: /Users/mohammadalmusaiteer/PyNucleus-Model/prompt_templates
2025-06-11 18:37:45 | [32mINFO[0m | pynucleus.llm.query_llm        | LLMQueryManager initialized with model: gpt2, max_tokens: 8192
2025-06-11 18:37:45 | [32mINFO[0m | pynucleus.main                 | 🤖 LLM Manager initialized with model: gpt2
2025-06-11 18:37:45 | [32mINFO[0m | pynucleus.llm.query_llm        | Loaded report from data/05_output/llm_reports/system_test_distillation_summary.md (962 characters)
2025-06-11 18:37:45 | [36mDEBUG[0m | pynucleus.llm.query_llm        | Rendered prompt using template: qwen_prompt.j2
2025-06-11 18:37:45 | [32mINFO[0m | pynucleus.utils.token_utils    | Loading tokenizer for model: gpt2
2025-06-11 18:37:45 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "HEAD /gpt2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-06-11 18:37:45 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "GET /api/models/gpt2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 133
2025-06-11 18:37:45 | [36mDEBUG[0m | urllib3.connectionpool         | https://huggingface.co:443 "GET /api/models/openai-community/gpt2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-06-11 18:37:45 | [32mINFO[0m | pynucleus.llm.query_llm        | Base prompt tokens: 77, Reserved for generation: 2457
2025-06-11 18:37:45 | [36mDEBUG[0m | pynucleus.llm.query_llm        | Content fits within limits: 292/5658 tokens
2025-06-11 18:37:45 | [36mDEBUG[0m | pynucleus.llm.query_llm        | Rendered prompt using template: qwen_prompt.j2
2025-06-11 18:37:45 | [32mINFO[0m | pynucleus.llm.query_llm        | Final prompt tokens: 377/8192
2025-06-11 18:37:45 | [32mINFO[0m | pynucleus.llm.query_llm        | Querying LLM...
2025-06-11 18:37:48 | [32mINFO[0m | pynucleus.llm.query_llm        | LLM response generated (262 characters)
2025-06-11 18:37:48 | [32mINFO[0m | pynucleus.main                 | ✅ LLM query completed successfully
2025-06-11 18:37:51 | [32mINFO[0m | pynucleus                      | 📋 Logging configured (INFO level)
2025-06-11 18:37:51 | [32mINFO[0m | pynucleus                      | 📁 Log file: logs/pipeline.log
2025-06-11 18:37:51 | [32mINFO[0m | pynucleus.main                 | 🚀 Starting Pipeline-and-Ask command
2025-06-11 18:37:51 | [32mINFO[0m | pynucleus.main                 | 📋 Configuration: configs/my_config.json
2025-06-11 18:37:51 | [32mINFO[0m | pynucleus.main                 | ❓ Question: What are the optimization recommendations?
2025-06-11 18:37:51 | [32mINFO[0m | pynucleus.main                 | 🤖 Model ID: tiiuae/falcon-rw-0.3b
2025-06-11 18:37:51 | [32mINFO[0m | pynucleus.main                 | 📁 Output directory: custom_output
2025-06-11 18:37:51 | [31mERROR[0m | pynucleus.main                 | ❌ Configuration file not found: configs/my_config.json
2025-06-11 18:37:51 | [31mERROR[0m | pynucleus.main                 | ❌ Command failed: 1
2025-06-11 18:45:26 | [32mINFO[0m | pynucleus                      | 📋 Logging configured (INFO level)
2025-06-11 18:45:26 | [32mINFO[0m | pynucleus                      | 📁 Log file: logs/pipeline.log
2025-06-11 18:45:26 | [32mINFO[0m | pynucleus.main                 | 🚀 Starting Pipeline-and-Ask command
2025-06-11 18:45:26 | [32mINFO[0m | pynucleus.main                 | 📋 Configuration: configs/simulation_config_template.json
2025-06-11 18:45:26 | [32mINFO[0m | pynucleus.main                 | ❓ Question: What are the performance metrics from the integrated simulation and document data?
2025-06-11 18:45:26 | [32mINFO[0m | pynucleus.main                 | 🤖 Model ID: gpt2
2025-06-11 18:45:26 | [32mINFO[0m | pynucleus.main                 | 📁 Output directory: data/05_output
2025-06-11 18:45:26 | [32mINFO[0m | pynucleus.main                 | ⚙️ Loading configuration...
2025-06-11 18:45:26 | [32mINFO[0m | pynucleus.main                 | ✅ Configuration loaded successfully
2025-06-11 18:45:26 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 🚀 Starting PyNucleus full pipeline...
2025-06-11 18:45:26 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 📁 Output directory: data/05_output
2025-06-11 18:45:26 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | ⚙️ Configuration: 1 simulations loaded
2025-06-11 18:45:26 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 🔍 RAG settings: top_k=5, threshold=0.3
2025-06-11 18:45:26 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 📝 LLM settings: summary_length=300
2025-06-11 18:45:27 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 🔄 Running complete pipeline (RAG + DWSIM + Export + Integration)
2025-06-11 18:45:27 | [33mWARNING[0m | unstructured                   | libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.
2025-06-11 18:45:28 | [33mWARNING[0m | unstructured                   | libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.
2025-06-11 18:45:28 | [33mWARNING[0m | unstructured                   | libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.
2025-06-11 18:45:33 | [32mINFO[0m | pynucleus.integration.dwsim_data_integrator | DWSIMDataIntegrator initialized with output: data/05_output
2025-06-11 18:45:33 | [32mINFO[0m | pynucleus.integration.dwsim_data_integrator | Starting DWSIM data integration with RAG knowledge base
2025-06-11 18:45:33 | [32mINFO[0m | pynucleus.integration.dwsim_data_integrator | Loaded 5 DWSIM simulation results
2025-06-11 18:45:33 | [32mINFO[0m | pynucleus.integration.dwsim_data_integrator | Created 5 simulation text chunks
2025-06-11 18:45:33 | [32mINFO[0m | pynucleus.integration.dwsim_data_integrator | Loaded 846 existing document chunks
2025-06-11 18:45:33 | [32mINFO[0m | pynucleus.integration.dwsim_data_integrator | Saved integrated chunks to data/03_intermediate/converted_chunked_data/chunked_data_full.json
2025-06-11 18:45:33 | [32mINFO[0m | pynucleus.integration.dwsim_data_integrator | Updated integration statistics: 851 total chunks
2025-06-11 18:45:33 | [32mINFO[0m | pynucleus.integration.dwsim_data_integrator | Integration completed: 851 total chunks (846 docs + 5 sims)
2025-06-11 18:45:33 | [32mINFO[0m | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-06-11 18:45:42 | [32mINFO[0m | faiss.loader                   | Loading faiss.
2025-06-11 18:45:42 | [32mINFO[0m | faiss.loader                   | Successfully loaded faiss.
2025-06-11 18:45:42 | [32mINFO[0m | faiss                          | Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-06-11 18:45:42 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | ✅ Pipeline completed successfully in 15.3s
2025-06-11 18:45:42 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 📊 Results: 21 RAG, 5 DWSIM
2025-06-11 18:45:42 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 📁 Files exported: 2
2025-06-11 18:45:42 | [32mINFO[0m | pynucleus.pipeline.pipeline_utils | 🔗 DWSIM-RAG integration successful
2025-06-11 18:45:42 | [32mINFO[0m | pynucleus.main                 | 📄 Using report: data/05_output/llm_reports/system_test_distillation_summary.md
2025-06-11 18:45:42 | [32mINFO[0m | pynucleus.llm.query_llm        | Template environment set up with directory: /Users/mohammadalmusaiteer/PyNucleus-Model/prompt_templates
2025-06-11 18:45:42 | [32mINFO[0m | pynucleus.llm.query_llm        | LLMQueryManager initialized with model: gpt2, max_tokens: 8192
2025-06-11 18:45:42 | [32mINFO[0m | pynucleus.main                 | 🤖 LLM Manager initialized with model: gpt2
2025-06-11 18:45:42 | [32mINFO[0m | pynucleus.llm.query_llm        | Loaded report from data/05_output/llm_reports/system_test_distillation_summary.md (962 characters)
2025-06-11 18:45:42 | [32mINFO[0m | pynucleus.utils.token_utils    | Loading tokenizer for model: gpt2
2025-06-11 18:45:42 | [32mINFO[0m | pynucleus.llm.query_llm        | Base prompt tokens: 84, Reserved for generation: 2457
2025-06-11 18:45:42 | [32mINFO[0m | pynucleus.llm.query_llm        | Final prompt tokens: 384/8192
2025-06-11 18:45:42 | [32mINFO[0m | pynucleus.llm.query_llm        | Querying LLM...
2025-06-11 18:45:45 | [32mINFO[0m | pynucleus.llm.query_llm        | LLM response generated (547 characters)
2025-06-11 18:45:45 | [32mINFO[0m | pynucleus.main                 | ✅ LLM query completed successfully
2025-06-11 18:46:22 | [32mINFO[0m | pynucleus                      | 📋 Logging configured (INFO level)
2025-06-11 18:46:22 | [32mINFO[0m | pynucleus                      | 📁 Log file: logs/pipeline.log
2025-06-11 18:46:22 | [32mINFO[0m | pynucleus.run_pipeline         | 🚀 Starting Pipeline-and-Ask command
2025-06-11 18:46:22 | [32mINFO[0m | pynucleus.run_pipeline         | 📋 Configuration: /var/folders/9z/fhqbcx0d6sqc_273srv0dv300000gn/T/tmpsol1ywxd/missing_config.json
2025-06-11 18:46:22 | [32mINFO[0m | pynucleus.run_pipeline         | ❓ Question: What are the key findings?
2025-06-11 18:46:22 | [32mINFO[0m | pynucleus.run_pipeline         | 🤖 Model ID: gpt2
2025-06-11 18:46:22 | [32mINFO[0m | pynucleus.run_pipeline         | 📁 Output directory: /var/folders/9z/fhqbcx0d6sqc_273srv0dv300000gn/T/tmpsol1ywxd/output
2025-06-11 18:46:22 | [31mERROR[0m | pynucleus.run_pipeline         | ❌ Configuration file not found: /var/folders/9z/fhqbcx0d6sqc_273srv0dv300000gn/T/tmpsol1ywxd/missing_config.json
2025-06-11 18:46:22 | [31mERROR[0m | pynucleus.run_pipeline         | ❌ Command failed: exceptions must derive from BaseException
2025-06-11 18:46:22 | [32mINFO[0m | pynucleus.run_pipeline         | 🚀 Starting Pipeline-and-Ask command
2025-06-11 18:46:22 | [32mINFO[0m | pynucleus.run_pipeline         | 📋 Configuration: /var/folders/9z/fhqbcx0d6sqc_273srv0dv300000gn/T/tmplgax9uue/test_config.json
2025-06-11 18:46:22 | [32mINFO[0m | pynucleus.run_pipeline         | ❓ Question: What are the key findings?
2025-06-11 18:46:22 | [32mINFO[0m | pynucleus.run_pipeline         | 🤖 Model ID: gpt2
2025-06-11 18:46:22 | [32mINFO[0m | pynucleus.run_pipeline         | 📁 Output directory: /var/folders/9z/fhqbcx0d6sqc_273srv0dv300000gn/T/tmplgax9uue/output
2025-06-11 18:46:22 | [32mINFO[0m | pynucleus.run_pipeline         | ⚙️ Loading configuration...
2025-06-11 18:46:22 | [32mINFO[0m | pynucleus.run_pipeline         | ✅ Configuration loaded successfully
2025-06-11 18:46:22 | [31mERROR[0m | pynucleus.run_pipeline         | ❌ Pipeline execution failed
2025-06-11 18:46:22 | [31mERROR[0m | pynucleus.run_pipeline         | ❌ Command failed: exceptions must derive from BaseException
2025-06-11 18:46:22 | [32mINFO[0m | pynucleus.run_pipeline         | 🚀 Starting Pipeline-and-Ask command
2025-06-11 18:46:22 | [32mINFO[0m | pynucleus.run_pipeline         | 📋 Configuration: /var/folders/9z/fhqbcx0d6sqc_273srv0dv300000gn/T/tmpu9gnall0/test_config.json
2025-06-11 18:46:22 | [32mINFO[0m | pynucleus.run_pipeline         | ❓ Question: What are the key findings?
2025-06-11 18:46:22 | [32mINFO[0m | pynucleus.run_pipeline         | 🤖 Model ID: gpt2
2025-06-11 18:46:22 | [32mINFO[0m | pynucleus.run_pipeline         | 📁 Output directory: /var/folders/9z/fhqbcx0d6sqc_273srv0dv300000gn/T/tmpu9gnall0/output
2025-06-11 18:46:22 | [32mINFO[0m | pynucleus.run_pipeline         | ⚙️ Loading configuration...
2025-06-11 18:46:22 | [32mINFO[0m | pynucleus.run_pipeline         | ✅ Configuration loaded successfully
2025-06-11 18:46:22 | [32mINFO[0m | pynucleus.run_pipeline         | 📄 Using report: /var/folders/9z/fhqbcx0d6sqc_273srv0dv300000gn/T/tmpu9gnall0/output/llm_reports/test_report.md
2025-06-11 18:46:22 | [32mINFO[0m | pynucleus.run_pipeline         | 🤖 LLM Manager initialized with model: gpt2
2025-06-11 18:46:22 | [32mINFO[0m | pynucleus.run_pipeline         | ✅ LLM query completed successfully
