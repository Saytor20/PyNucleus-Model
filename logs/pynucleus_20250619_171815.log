2025-06-19 17:18:15,439 | __main__ | INFO | run_pipeline.py:436 | üöÄ Starting RAG query
2025-06-19 17:18:15,439 | __main__ | INFO | run_pipeline.py:437 | ‚ùì Question: What is a heat exchanger?
2025-06-19 17:18:15,439 | __main__ | INFO | run_pipeline.py:438 | ü§ñ Model ID: Qwen/Qwen2.5-1.5B-Instruct
2025-06-19 17:18:15,439 | __main__ | INFO | run_pipeline.py:439 | üìä Top K: 5
2025-06-19 17:18:15,439 | __main__ | INFO | run_pipeline.py:442 | üîÑ Using RAG system for query processing
2025-06-19 17:18:15,853 | chromadb.config | DEBUG | config.py:359 | Starting component System
2025-06-19 17:18:15,853 | chromadb.config | DEBUG | config.py:359 | Starting component Posthog
2025-06-19 17:18:15,859 | pynucleus.rag.vector_store | INFO | vector_store.py:593 | Loaded existing ChromaDB collection: pynucleus_documents
2025-06-19 17:18:15,933 | pynucleus.rag.vector_store | INFO | vector_store.py:598 | ChromaDB collection contains 3602 documents
2025-06-19 17:18:15,933 | pynucleus.pipeline.pipeline_rag | INFO | pipeline_rag.py:36 | Vector store (chroma) initialized successfully
2025-06-19 17:18:15,933 | __main__ | INFO | run_pipeline.py:449 | üîÑ Processing question...
2025-06-19 17:18:15,966 | chromadb.utils.embedding_functions.onnx_mini_lm_l6_v2 | DEBUG | onnx_mini_lm_l6_v2.py:227 | WARNING: No ONNX providers provided, defaulting to available providers: ['CoreMLExecutionProvider', 'AzureExecutionProvider', 'CPUExecutionProvider']
2025-06-19 17:18:16,064 | pynucleus.rag.vector_store | INFO | vector_store.py:683 | ChromaDB search for 'What is a heat exchanger?...' returned 5 results
2025-06-19 17:18:16,064 | pynucleus.pipeline.pipeline_rag | INFO | pipeline_rag.py:104 | RAG query processed: What is a heat exchanger?...
2025-06-19 17:18:18,108 | pynucleus.llm.llm_runner | INFO | llm_runner.py:27 | Loading model: Qwen/Qwen2.5-1.5B-Instruct
2025-06-19 17:18:18,109 | urllib3.connectionpool | DEBUG | connectionpool.py:1049 | Starting new HTTPS connection (1): huggingface.co:443
2025-06-19 17:18:18,240 | urllib3.connectionpool | DEBUG | connectionpool.py:544 | https://huggingface.co:443 "HEAD /Qwen/Qwen2.5-1.5B-Instruct/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-06-19 17:18:18,290 | urllib3.connectionpool | DEBUG | connectionpool.py:544 | https://huggingface.co:443 "GET /api/models/Qwen/Qwen2.5-1.5B-Instruct/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-06-19 17:18:18,515 | urllib3.connectionpool | DEBUG | connectionpool.py:544 | https://huggingface.co:443 "HEAD /Qwen/Qwen2.5-1.5B-Instruct/resolve/main/config.json HTTP/1.1" 200 0
2025-06-19 17:18:26,305 | urllib3.connectionpool | DEBUG | connectionpool.py:544 | https://huggingface.co:443 "HEAD /Qwen/Qwen2.5-1.5B-Instruct/resolve/main/generation_config.json HTTP/1.1" 200 0
2025-06-19 17:18:26,358 | urllib3.connectionpool | DEBUG | connectionpool.py:544 | https://huggingface.co:443 "HEAD /Qwen/Qwen2.5-1.5B-Instruct/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
2025-06-19 17:18:26,360 | pynucleus.llm.llm_runner | INFO | llm_runner.py:47 | Model loaded successfully on device: cpu
2025-06-19 17:18:26,361 | __main__ | INFO | run_pipeline.py:471 | ü§ñ Generating enhanced response with Qwen/Qwen2.5-1.5B-Instruct
2025-06-19 17:18:45,426 | pynucleus.llm.llm_runner | INFO | llm_runner.py:201 | Generated response in 19.05s
2025-06-19 17:18:45,429 | __main__ | INFO | run_pipeline.py:493 | ‚úÖ Question processed successfully
