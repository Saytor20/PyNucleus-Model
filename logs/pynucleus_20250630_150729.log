2025-06-30 15:07:29,859 | __main__ | INFO | run_pipeline.py:517 | ðŸš€ Starting interactive chat session
2025-06-30 15:07:29,859 | __main__ | INFO | run_pipeline.py:518 | ðŸ¤– Model ID: Qwen/Qwen2.5-1.5B-Instruct
2025-06-30 15:07:29,859 | __main__ | INFO | run_pipeline.py:519 | ðŸ“Š Top K: 5
2025-06-30 15:07:29,859 | __main__ | INFO | run_pipeline.py:532 | ðŸ”§ Initializing RAG pipeline and LLM runner
2025-06-30 15:07:29,863 | pynucleus.rag.vector_store | INFO | vector_store.py:601 | ChromaDB client initialized successfully in vector store
2025-06-30 15:07:29,864 | pynucleus.rag.vector_store | INFO | vector_store.py:632 | Loaded existing ChromaDB collection: pynucleus_documents
2025-06-30 15:07:29,866 | pynucleus.rag.vector_store | INFO | vector_store.py:637 | ChromaDB collection contains 3772 documents
2025-06-30 15:07:29,867 | pynucleus.pipeline.pipeline_rag | INFO | pipeline_rag.py:41 | Vector store (chroma) initialized successfully
2025-06-30 15:07:29,868 | pynucleus | INFO | engine.py:58 | ChromaDB collection initialized successfully
2025-06-30 15:07:29,869 | pynucleus.pipeline.pipeline_rag | INFO | pipeline_rag.py:77 | ChromaDB collection contains 3772 documents
2025-06-30 15:07:29,870 | pynucleus.llm.llm_runner | INFO | llm_runner.py:27 | Loading model: Qwen/Qwen2.5-1.5B-Instruct
2025-06-30 15:07:48,617 | pynucleus.llm.llm_runner | INFO | llm_runner.py:47 | Model loaded successfully on device: cpu
2025-06-30 15:09:27,374 | pynucleus | INFO | engine.py:129 | Enhanced retrieval: 3 documents (filtered from 3) for query
2025-06-30 15:09:27,377 | pynucleus | INFO | engine.py:203 | Built enhanced context: 3 chunks, 2366 characters
2025-06-30 15:09:27,377 | pynucleus | INFO | engine.py:416 | Question complexity: Simple, Token limit: 250, Context length: 2366
2025-06-30 15:09:27,378 | pynucleus | INFO | model_loader.py:262 | Generating with HuggingFace model (max_tokens=250, stream=False)
2025-06-30 15:10:48,737 | pynucleus | INFO | answer_processing.py:72 | Deduplication: 7 -> 7 sentences
2025-06-30 15:10:48,746 | pynucleus.rag.answer_processing | INFO | answer_processing.py:219 | Deduplication: 7 -> 7 sentences
2025-06-30 15:10:48,786 | pynucleus | INFO | answer_processing.py:182 | Added citation to answer lacking proper citations
2025-06-30 15:10:48,786 | pynucleus.rag.answer_processing | INFO | answer_processing.py:238 | Added citation to answer lacking proper citations
2025-06-30 15:10:49,938 | pynucleus.eval.confidence_calibration | INFO | confidence_calibration.py:107 | Initialized ConfidenceCalibrator with method=both
2025-06-30 15:10:49,938 | pynucleus.eval.confidence_calibration | INFO | confidence_calibration.py:473 | No saved calibration models found
2025-06-30 15:10:49,940 | pynucleus.eval.confidence_calibration | WARNING | confidence_calibration.py:313 | Calibration models not trained, returning original confidence
2025-06-30 15:10:49,940 | pynucleus | INFO | engine.py:485 | Applied confidence calibration: {'original': 0.85, 'calibrated': 0.85}
2025-06-30 15:12:41,719 | pynucleus.llm.llm_runner | INFO | llm_runner.py:201 | Generated response in 111.71s
2025-06-30 15:13:10,168 | pynucleus | INFO | engine.py:129 | Enhanced retrieval: 3 documents (filtered from 3) for query
2025-06-30 15:13:10,173 | pynucleus | INFO | engine.py:203 | Built enhanced context: 3 chunks, 2325 characters
2025-06-30 15:13:10,173 | pynucleus | INFO | engine.py:416 | Question complexity: Complex, Token limit: 600, Context length: 2325
2025-06-30 15:13:10,175 | pynucleus | INFO | model_loader.py:262 | Generating with HuggingFace model (max_tokens=600, stream=False)
2025-06-30 15:15:15,773 | pynucleus | INFO | answer_processing.py:72 | Deduplication: 12 -> 12 sentences
2025-06-30 15:15:15,774 | pynucleus.rag.answer_processing | INFO | answer_processing.py:219 | Deduplication: 12 -> 12 sentences
2025-06-30 15:15:15,827 | pynucleus | INFO | answer_processing.py:182 | Added citation to answer lacking proper citations
2025-06-30 15:15:15,827 | pynucleus.rag.answer_processing | INFO | answer_processing.py:238 | Added citation to answer lacking proper citations
2025-06-30 15:15:15,829 | pynucleus.eval.confidence_calibration | WARNING | confidence_calibration.py:313 | Calibration models not trained, returning original confidence
2025-06-30 15:15:15,829 | pynucleus | INFO | engine.py:485 | Applied confidence calibration: {'original': 0.73, 'calibrated': 0.73}
2025-06-30 15:15:43,462 | pynucleus.llm.llm_runner | INFO | llm_runner.py:201 | Generated response in 27.55s
