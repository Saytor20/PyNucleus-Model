2025-06-24 20:49:08,676 | __main__ | INFO | run_pipeline.py:517 | ðŸš€ Starting interactive chat session
2025-06-24 20:49:08,676 | __main__ | INFO | run_pipeline.py:518 | ðŸ¤– Model ID: Qwen/Qwen2.5-1.5B-Instruct
2025-06-24 20:49:08,676 | __main__ | INFO | run_pipeline.py:519 | ðŸ“Š Top K: 5
2025-06-24 20:49:08,676 | __main__ | INFO | run_pipeline.py:532 | ðŸ”§ Initializing RAG pipeline and LLM runner
2025-06-24 20:49:08,677 | pynucleus.rag.vector_store | INFO | vector_store.py:601 | ChromaDB client initialized successfully in vector store
2025-06-24 20:49:08,677 | pynucleus.rag.vector_store | INFO | vector_store.py:632 | Loaded existing ChromaDB collection: pynucleus_documents
2025-06-24 20:49:08,678 | pynucleus.rag.vector_store | INFO | vector_store.py:637 | ChromaDB collection contains 3772 documents
2025-06-24 20:49:08,678 | pynucleus.pipeline.pipeline_rag | INFO | pipeline_rag.py:37 | Vector store (chroma) initialized successfully
2025-06-24 20:49:08,678 | pynucleus | INFO | engine.py:58 | ChromaDB collection initialized successfully
2025-06-24 20:49:08,678 | pynucleus.pipeline.pipeline_rag | INFO | pipeline_rag.py:73 | ChromaDB collection contains 3772 documents
2025-06-24 20:49:08,678 | pynucleus.llm.llm_runner | INFO | llm_runner.py:27 | Loading model: Qwen/Qwen2.5-1.5B-Instruct
2025-06-24 20:49:19,813 | pynucleus.llm.llm_runner | INFO | llm_runner.py:47 | Model loaded successfully on device: cpu
2025-06-24 20:49:26,367 | pynucleus | INFO | engine.py:129 | Enhanced retrieval: 3 documents (filtered from 3) for query
2025-06-24 20:49:26,368 | pynucleus | INFO | engine.py:203 | Built enhanced context: 3 chunks, 2292 characters
2025-06-24 20:49:26,368 | pynucleus | INFO | engine.py:406 | Question complexity: Simple, Token limit: 250, Context length: 2292
2025-06-24 20:49:26,368 | pynucleus | INFO | model_loader.py:262 | Generating with HuggingFace model (max_tokens=250, stream=False)
2025-06-24 20:49:44,883 | pynucleus | INFO | answer_processing.py:70 | Deduplication: 8 -> 8 sentences
2025-06-24 20:49:44,884 | pynucleus | INFO | answer_processing.py:180 | Added citation to answer lacking proper citations
2025-06-24 20:50:07,965 | pynucleus.llm.llm_runner | INFO | llm_runner.py:201 | Generated response in 23.07s
2025-06-24 20:50:30,060 | pynucleus | INFO | engine.py:129 | Enhanced retrieval: 3 documents (filtered from 3) for query
2025-06-24 20:50:30,062 | pynucleus | INFO | engine.py:203 | Built enhanced context: 3 chunks, 1635 characters
2025-06-24 20:50:30,062 | pynucleus | INFO | engine.py:406 | Question complexity: Simple, Token limit: 250, Context length: 1635
2025-06-24 20:50:30,062 | pynucleus | INFO | model_loader.py:262 | Generating with HuggingFace model (max_tokens=250, stream=False)
2025-06-24 20:50:49,429 | pynucleus | INFO | answer_processing.py:70 | Deduplication: 13 -> 13 sentences
2025-06-24 20:50:49,429 | pynucleus | INFO | answer_processing.py:180 | Added citation to answer lacking proper citations
2025-06-24 20:51:09,282 | pynucleus.llm.llm_runner | INFO | llm_runner.py:201 | Generated response in 19.84s
