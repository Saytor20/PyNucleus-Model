#!/usr/bin/env python3
"""
PyNucleus Pipeline CLI

Command-line interface for the PyNucleus chemical process simulation and RAG system.
Provides commands to run the full pipeline, query LLMs, and test various components.

Usage:
    python run_pipeline.py run --config-path <config.json> --output-dir <output>
    python run_pipeline.py pipeline-and-ask --config-path <config.json> --question "..."
"""

############################################################
# 4 ‚Äî Typer CLI entrypoint
############################################################
# Dependency: pip install typer[all]

from pathlib import Path
import sys
import typer
from typing import Optional
import glob
import os
from datetime import datetime

# Add src to Python path
src_path = str(Path(__file__).parent / "src")
if src_path not in sys.path:
    sys.path.insert(0, src_path)

from pynucleus.integration.config_manager import ConfigManager
from pynucleus.pipeline.pipeline_utils import run_full_pipeline
from pynucleus.utils.logging_config import configure_logging, get_logger, log_system_info
from pynucleus.llm.query_llm import LLMQueryManager

app = typer.Typer(
    add_completion=False, 
    pretty_exceptions_enable=False,
    help="PyNucleus Pipeline CLI - RAG + DWSIM Chemical Process Simulation"
)

def find_latest_report(output_dir: Path) -> Optional[Path]:
    """
    Find the latest generated report file in the LLM reports directory.
    
    Args:
        output_dir: Base output directory
        
    Returns:
        Path to the latest report file, or None if no reports found
    """
    llm_reports_dir = output_dir / "llm_reports"
    
    if not llm_reports_dir.exists():
        return None
    
    # Look for markdown and text files (common report formats)
    patterns = ["*.md", "*.txt"]
    report_files = []
    
    for pattern in patterns:
        report_files.extend(llm_reports_dir.glob(pattern))
    
    if not report_files:
        return None
    
    # Return the most recently modified file
    latest_file = max(report_files, key=lambda f: f.stat().st_mtime)
    return latest_file

@app.command("run")
def run_pipeline(
    config_path: Path = typer.Option(..., "--config-path", help="JSON/CSV config file"),
    output_dir: Path = typer.Option("data/05_output", "--output-dir", help="Save location"),
    verbose: bool = typer.Option(False, "--verbose/--no-verbose", help="Verbose logging"),
    log_file: Optional[Path] = typer.Option(None, "--log-file", help="Custom log file path (default: logs/pipeline.log)"),
):
    """Execute the full PyNucleus pipeline from the command line."""
    
    # Initialize robust logging configuration
    try:
        # Setup logging with enhanced configuration
        logger = configure_logging(
            level="DEBUG" if verbose else "INFO",
            log_file=log_file
        )
        
        # Get CLI-specific logger
        cli_logger = get_logger(__name__)
        
        # Log startup information
        cli_logger.info("üöÄ PyNucleus CLI started")
        cli_logger.info(f"üìã Configuration: {config_path}")
        cli_logger.info(f"üìÅ Output directory: {output_dir}")
        cli_logger.info(f"üîß Verbose mode: {'ON' if verbose else 'OFF'}")
        
        if verbose:
            log_system_info(cli_logger)
        
        # Validate inputs
        if not config_path.exists():
            cli_logger.error(f"‚ùå Configuration file not found: {config_path}")
            raise typer.Exit(1)
        
        # Load configuration
        cli_logger.info("‚öôÔ∏è Loading configuration...")
        cfg_mgr = ConfigManager(config_dir=config_path.parent)
        settings = cfg_mgr.load(config_path.name)
        cli_logger.info("‚úÖ Configuration loaded successfully")
        
        # Ensure output directory exists
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        cli_logger.info(f"üìÇ Output directory prepared: {output_dir}")
        
        # Run the pipeline
        cli_logger.info("üîÑ Starting pipeline execution...")
        result = run_full_pipeline(settings=settings, output_dir=output_dir)
        
        if result:
            cli_logger.info("üéâ Pipeline completed successfully!")
            cli_logger.info(f"üìä Results: {result.get('summary', 'N/A')}")
        else:
            cli_logger.warning("‚ö†Ô∏è Pipeline completed with warnings")
            
    except KeyboardInterrupt:
        cli_logger.info("‚èπÔ∏è Pipeline interrupted by user")
        raise typer.Exit(130)  # Standard exit code for Ctrl+C
        
    except Exception as e:
        # Use logger if available, otherwise print to stderr
        try:
            cli_logger.error(f"‚ùå Pipeline failed: {str(e)}")
            if verbose:
                cli_logger.exception("Full error details:")
        except:
            print(f"‚ùå Pipeline failed: {str(e)}", file=sys.stderr)
        
        raise typer.Exit(1)

@app.command("pipeline-and-ask")
def pipeline_and_ask(
    config_path: Path = typer.Option(..., "--config-path", help="JSON/CSV config file"),
    question: str = typer.Option(..., "--question", help="Question to ask the LLM about the report"),
    model_id: str = typer.Option("Qwen/Qwen2.5-1.5B-Instruct", "--model-id", help="LLM model ID"),
    output_dir: Path = typer.Option("data/05_output", "--output-dir", help="Save location"),
    verbose: bool = typer.Option(False, "--verbose/--no-verbose", help="Verbose logging"),
    log_file: Optional[Path] = typer.Option(None, "--log-file", help="Custom log file path"),
):
    """Run the pipeline and then query an LLM about the latest generated report."""
    
    try:
        # Setup logging
        logger = configure_logging(
            level="DEBUG" if verbose else "INFO",
            log_file=log_file
        )
        
        cli_logger = get_logger(__name__)
        
        cli_logger.info("üöÄ Starting Pipeline-and-Ask command")
        cli_logger.info(f"üìã Configuration: {config_path}")
        cli_logger.info(f"‚ùì Question: {question}")
        cli_logger.info(f"ü§ñ Model ID: {model_id}")
        cli_logger.info(f"üìÅ Output directory: {output_dir}")
        
        # Validate inputs
        if not config_path.exists():
            cli_logger.error(f"‚ùå Configuration file not found: {config_path}")
            raise typer.Exit(1)
        
        # Step 1: Run the pipeline
        print("=" * 60)
        print("üîÑ STEP 1: Running PyNucleus Pipeline")
        print("=" * 60)
        
        # Load configuration
        cli_logger.info("‚öôÔ∏è Loading configuration...")
        cfg_mgr = ConfigManager(config_dir=config_path.parent)
        settings = cfg_mgr.load(config_path.name)
        cli_logger.info("‚úÖ Configuration loaded successfully")
        
        # Ensure output directory exists
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # Run the pipeline
        pipeline_result = run_full_pipeline(settings=settings, output_dir=output_dir)
        
        if not pipeline_result or not pipeline_result.get('success', True):
            cli_logger.error("‚ùå Pipeline execution failed")
            print("‚ùå Pipeline execution failed. Cannot proceed to LLM query.")
            raise typer.Exit(1)
        
        print("‚úÖ Pipeline completed successfully!")
        
        # Step 2: Find the latest report
        print("\n" + "=" * 60)
        print("üîç STEP 2: Finding Latest Report")
        print("=" * 60)
        
        latest_report = find_latest_report(output_dir)
        
        if not latest_report:
            cli_logger.error("‚ùå No reports found in the output directory")
            print(f"‚ùå No reports found in {output_dir}/llm_reports/")
            print("üí° Make sure the pipeline generates LLM reports before querying.")
            raise typer.Exit(1)
        
        print(f"‚úÖ Found latest report: {latest_report}")
        cli_logger.info(f"üìÑ Using report: {latest_report}")
        
        # Step 3: Query the LLM
        print("\n" + "=" * 60)
        print("ü§ñ STEP 3: Querying LLM")
        print("=" * 60)
        
        print(f"ü§ñ Initializing LLM with model: {model_id}")
        print(f"‚ùì Question: {question}")
        print(f"üìÑ Report: {latest_report.name}")
        
        # Initialize LLM Query Manager
        try:
            llm_manager = LLMQueryManager(
                model_id=model_id,
                device="cpu",  # Default to CPU for compatibility
                max_tokens=8192
            )
            
            cli_logger.info(f"ü§ñ LLM Manager initialized with model: {model_id}")
            
            # Query the LLM
            print("\nüîÑ Generating response...")
            response = llm_manager.ask_llm(
                user_query=question,
                report_file_path=latest_report,
                system_message="You are an expert chemical process engineer analyzing simulation reports.",
                generation_params={
                    'max_length': 500,  # Reasonable response length
                    'temperature': 0.7,
                    'do_sample': True,
                    'top_p': 0.9
                }
            )
            
            # Display results
            print("\n" + "=" * 60)
            print("üìã LLM RESPONSE")
            print("=" * 60)
            print(f"Question: {question}")
            print(f"Report: {latest_report.name}")
            print(f"Model: {model_id}")
            print("-" * 60)
            print(response)
            print("=" * 60)
            
            cli_logger.info("‚úÖ LLM query completed successfully")
            
        except Exception as e:
            cli_logger.error(f"‚ùå LLM query failed: {str(e)}")
            print(f"‚ùå Failed to query LLM: {str(e)}")
            if verbose:
                import traceback
                traceback.print_exc()
            raise typer.Exit(1)
        
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è Operation interrupted by user")
        raise typer.Exit(130)
        
    except Exception as e:
        print(f"‚ùå Command failed: {str(e)}")
        if 'cli_logger' in locals():
            cli_logger.error(f"‚ùå Command failed: {str(e)}")
        raise typer.Exit(1)

@app.command("test-logging")
def test_logging():
    """Test the logging configuration."""
    
    # Setup logging in test mode
    logger = configure_logging(level="DEBUG")
    cli_logger = get_logger("test")
    
    print("üß™ Testing logging configuration...")
    
    # Test different log levels
    cli_logger.debug("üîç This is a DEBUG message")
    cli_logger.info("üìã This is an INFO message") 
    cli_logger.warning("‚ö†Ô∏è This is a WARNING message")
    cli_logger.error("‚ùå This is an ERROR message")
    
    # Log system info
    log_system_info(cli_logger)
    
    # Check log file
    log_file = Path("logs/pipeline.log")
    if log_file.exists():
        cli_logger.info(f"‚úÖ Log file created: {log_file}")
        cli_logger.info(f"üìè Log file size: {log_file.stat().st_size} bytes")
    else:
        cli_logger.error("‚ùå Log file not found")
    
    print("‚úÖ Logging test completed!")

@app.command("ingest")
def ingest_documents(
    source_dir: Path = typer.Option(..., "--source-dir", help="Source directory containing documents to ingest"),
    output_dir: Path = typer.Option("data/03_intermediate", "--output-dir", help="Output directory for processed documents"),
    backend: str = typer.Option("chroma", "--backend", help="Vector store backend (chroma|faiss|qdrant)"),
    verbose: bool = typer.Option(False, "--verbose/--no-verbose", help="Verbose logging"),
):
    """Ingest and process documents for RAG system."""
    try:
        # Setup logging
        logger = configure_logging(level="DEBUG" if verbose else "INFO")
        cli_logger = get_logger(__name__)
        
        cli_logger.info("üöÄ Starting document ingestion")
        cli_logger.info(f"üìÅ Source directory: {source_dir}")
        cli_logger.info(f"üìÅ Output directory: {output_dir}")
        
        # Validate source directory
        if not source_dir.exists():
            cli_logger.error(f"‚ùå Source directory not found: {source_dir}")
            raise typer.Exit(1)
        
        # Create output directory
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # Validate backend selection
        if backend not in ['chroma', 'faiss', 'qdrant']:
            cli_logger.error(f"‚ùå Invalid backend: {backend}. Must be 'chroma', 'faiss', or 'qdrant'")
            raise typer.Exit(1)
        
        cli_logger.info(f"üîß Using vector store backend: {backend}")
        
        if backend == 'qdrant':
            cli_logger.info("‚ö†Ô∏è  Qdrant stub -- not yet enabled")
            print("Qdrant stub -- not yet enabled")
            return
        
        # Initialize RAG core
        from pynucleus.rag import RAGCore
        rag_core = RAGCore(data_dir=output_dir.parent)
        
        # Process documents using real ChromaDB ingestion
        cli_logger.info("üîÑ Processing documents...")
        
        if backend == 'chroma':
            # Use the actual ChromaDB ingestion function
            from pynucleus.rag.collector import ingest
            ingest(source_dir=str(source_dir))
            cli_logger.info("‚úÖ Successfully ingested documents into ChromaDB")
            print(f"üìä Documents ingested into ChromaDB collection: pynucleus_documents")
        else:
            # Fallback to RAG core for other backends
            result = rag_core.process_documents(source_dir=str(source_dir))
            if result["status"] == "success":
                cli_logger.info(f"‚úÖ Successfully processed {result['processed_count']} documents")
                print(f"üìä Processed {result['processed_count']} out of {result['total_files']} files")
            else:
                cli_logger.error(f"‚ùå Document processing failed: {result['message']}")
                raise typer.Exit(1)
            
    except Exception as e:
        cli_logger.error(f"‚ùå Ingestion failed: {str(e)}")
        print(f"‚ùå Error: {str(e)}")
        raise typer.Exit(1)

@app.command("build-faiss")  
def build_faiss_index(
    chunk_dir: Path = typer.Option("data/03_intermediate/converted_chunked_data", "--chunk-dir", help="Directory containing chunk data"),
    index_dir: Path = typer.Option("data/04_models/chunk_reports", "--index-dir", help="Output directory for FAISS index"),
    force_rebuild: bool = typer.Option(False, "--force-rebuild", help="Force rebuild even if index exists"),
    verbose: bool = typer.Option(False, "--verbose/--no-verbose", help="Verbose logging"),
):
    """Build FAISS vector index from processed chunks."""
    try:
        # Setup logging
        logger = configure_logging(level="DEBUG" if verbose else "INFO")
        cli_logger = get_logger(__name__)
        
        cli_logger.info("üöÄ Starting FAISS index building")
        cli_logger.info(f"üìÅ Chunk directory: {chunk_dir}")
        cli_logger.info(f"üìÅ Index directory: {index_dir}")
        cli_logger.info(f"üîÑ Force rebuild: {force_rebuild}")
        
        # Validate chunk directory
        if not chunk_dir.exists():
            cli_logger.error(f"‚ùå Chunk directory not found: {chunk_dir}")
            raise typer.Exit(1)
        
        # Create index directory
        index_dir.mkdir(parents=True, exist_ok=True)
        
        # Initialize RAG core
        from pynucleus.rag import RAGCore
        rag_core = RAGCore(data_dir=index_dir.parent.parent)
        
        # Build index
        cli_logger.info("üîÑ Building FAISS index...")
        result = rag_core.build_index(force_rebuild=force_rebuild)
        
        if result["status"] == "success":
            cli_logger.info(f"‚úÖ Successfully built FAISS index")
            print(f"üìä Index size: {result.get('index_size', 'Unknown')}")
            print(f"üìê Dimensions: {result.get('dimensions', 'Unknown')}")
            print(f"üìÑ Chunks indexed: {result.get('chunks_indexed', 'Unknown')}")
            print(f"üìÅ Index saved to: {index_dir}")
        elif result["status"] == "exists":
            print(f"‚ÑπÔ∏è  Index already exists: {result['message']}")
            print(f"üìÅ Existing indices: {result.get('existing_indices', [])}")
        else:
            cli_logger.error(f"‚ùå Index building failed: {result['message']}")
            raise typer.Exit(1)
            
    except Exception as e:
        cli_logger.error(f"‚ùå FAISS index building failed: {str(e)}")
        print(f"‚ùå Error: {str(e)}")
        raise typer.Exit(1)

@app.command("ask")
def ask_question(
    question: str = typer.Option(..., "--question", help="Question to ask the RAG system"),
    model_id: str = typer.Option("Qwen/Qwen2.5-1.5B-Instruct", "--model-id", help="LLM model ID for enhanced responses"),
    top_k: int = typer.Option(5, "--top-k", help="Number of top results to retrieve"),
    verbose: bool = typer.Option(False, "--verbose/--no-verbose", help="Verbose logging"),
):
    """Ask a question to the RAG system."""
    try:
        # Setup logging
        logger = configure_logging(level="DEBUG" if verbose else "INFO")
        cli_logger = get_logger(__name__)
        
        cli_logger.info("üöÄ Starting RAG query")
        cli_logger.info(f"‚ùì Question: {question}")
        cli_logger.info(f"ü§ñ Model ID: {model_id}")
        cli_logger.info(f"üìä Top K: {top_k}")
        
        # DSPy components removed, using RAG system directly
        cli_logger.info("üîÑ Using RAG system for query processing")
        
        # Initialize RAG pipeline
        from pynucleus.pipeline.pipeline_rag import RAGPipeline
        rag_pipeline = RAGPipeline(data_dir="data")
        
        # Query the RAG system
        cli_logger.info("üîÑ Processing question...")
        result = rag_pipeline.query(question, top_k=top_k)
        
        # Display results
        print("=" * 60)
        print("üìã RAG SYSTEM RESPONSE")
        print("=" * 60)
        print(f"Question: {question}")
        print(f"Confidence: {result.get('confidence', 0):.2f}")
        print("-" * 60)
        print(f"Answer: {result.get('answer', 'No answer available')}")
        print("-" * 60)
        print("Sources:")
        for i, source in enumerate(result.get('sources', []), 1):
            print(f"  {i}. {source}")
        print("=" * 60)
        
        # Always use LLM for enhanced response
        try:
            from pynucleus.llm.llm_runner import LLMRunner
            llm_runner = LLMRunner(model_id=model_id)
            
            cli_logger.info(f"ü§ñ Generating enhanced response with {model_id}")
            
            # Create enhanced prompt with context using Guidance integration
            from pynucleus.llm.prompting import build_prompt
            context = result.get('answer', '')
            enhanced_prompt = build_prompt(context, question)
            
            llm_response = llm_runner.ask(
                question=enhanced_prompt,
                max_length=500,
                temperature=0.7
            )
            
            print("\nü§ñ ENHANCED LLM RESPONSE")
            print("-" * 60)
            print(llm_response)
            print("=" * 60)
            
        except Exception as llm_error:
            cli_logger.error(f"‚ùå LLM processing failed: {llm_error}")
            print(f"\n‚ùå LLM processing failed: {llm_error}")
            print("üîÑ Falling back to RAG-only response")
                
        cli_logger.info("‚úÖ Question processed successfully")
        
    except Exception as e:
        cli_logger.error(f"‚ùå Question processing failed: {str(e)}")
        print(f"‚ùå Error: {str(e)}")
        raise typer.Exit(1)

# DSPy command removed - DSPy functionality disabled to avoid API dependencies
# Use the regular 'ask' or 'chat' commands instead for local LLM processing

@app.command("chat")
def interactive_chat(
    model_id: str = typer.Option("Qwen/Qwen2.5-1.5B-Instruct", "--model-id", help="LLM model ID for responses"),
    top_k: int = typer.Option(5, "--top-k", help="Number of top results to retrieve from RAG"),
    verbose: bool = typer.Option(False, "--verbose/--no-verbose", help="Verbose logging"),
    use_dspy: bool = typer.Option(False, "--use-dspy/--no-dspy", help="DSPy disabled - using local RAG+LLM instead"),
):
    """Start an interactive chat session with the LLM."""
    try:
        # Setup logging
        logger = configure_logging(level="DEBUG" if verbose else "INFO")
        cli_logger = get_logger(__name__)
        
        cli_logger.info("üöÄ Starting interactive chat session")
        cli_logger.info(f"ü§ñ Model ID: {model_id}")
        cli_logger.info(f"üìä Top K: {top_k}")
        # DSPy functionality has been removed to avoid API dependencies
        # Using local RAG + LLM processing only
        
        # Initialize systems
        rag_pipeline = None
        llm_runner = None
        
        # Initialize RAG pipeline and LLM
        try:
            from pynucleus.pipeline.pipeline_rag import RAGPipeline
            from pynucleus.llm.llm_runner import LLMRunner
            
            cli_logger.info("üîß Initializing RAG pipeline and LLM runner")
            rag_pipeline = RAGPipeline(data_dir="data")
            llm_runner = LLMRunner(model_id=model_id)
            print("‚úÖ RAG + LLM mode enabled")
        except Exception as e:
            cli_logger.error(f"‚ùå Failed to initialize RAG/LLM systems: {e}")
            print(f"‚ùå Failed to initialize systems: {e}")
            raise typer.Exit(1)
        
        # Start interactive session
        print("\n" + "=" * 60)
        print("ü§ñ PYNUCLEUS INTERACTIVE CHAT")
        print("=" * 60)
        print("üí° Ask questions about chemical processes, simulations, or technical topics")
        print("üìù Type 'quit', 'exit', or press Ctrl+C to end the session")
        print("üîÑ Type 'clear' to clear the screen")
        print("‚ùì Type 'help' for more commands")
        print("=" * 60)
        
        question_count = 0
        
        while True:
            try:
                # Get user input
                print(f"\n[Q{question_count + 1}]", end=" ")
                question = input("üí≠ Your question: ").strip()
                
                # Handle special commands
                if question.lower() in ['quit', 'exit', 'q']:
                    print("üëã Goodbye! Chat session ended.")
                    break
                elif question.lower() == 'clear':
                    os.system('clear' if os.name == 'posix' else 'cls')
                    continue
                elif question.lower() == 'help':
                    print("\nüìã Available Commands:")
                    print("  ‚Ä¢ quit/exit/q  - End chat session")
                    print("  ‚Ä¢ clear        - Clear screen")
                    print("  ‚Ä¢ help         - Show this help")
                    print("  ‚Ä¢ Any question - Ask the AI system")
                    continue
                elif not question:
                    print("‚ùå Please enter a question or command")
                    continue
                
                question_count += 1
                
                print(f"\nüîÑ Processing question {question_count}...")
                start_time = datetime.now()
                
                # Process with RAG + LLM
                try:
                    # Get RAG response
                    rag_result = rag_pipeline.query(question, top_k=top_k)
                    
                    # Get enhanced LLM response using Guidance integration
                    from pynucleus.llm.prompting import build_prompt
                    context = rag_result.get('answer', '')
                    enhanced_prompt = build_prompt(context, question)
                    
                    llm_response = llm_runner.ask(
                        question=enhanced_prompt,
                        max_length=500,
                        temperature=0.7
                    )
                    
                    # Display results
                    print("\n" + "üìã " + "=" * 58)
                    print(f"Answer: {llm_response}")
                    print("=" * 60)
                    
                    # Show sources if available
                    sources = rag_result.get('sources', [])
                    if sources:
                        print("üìö Sources:")
                        for i, source in enumerate(sources[:3], 1):  # Show top 3 sources
                            print(f"  {i}. {source}")
                    
                    end_time = datetime.now()
                    duration = (end_time - start_time).total_seconds()
                    print(f"‚è±Ô∏è  Response time: {duration:.2f}s")
                    print(f"ü§ñ Model: {model_id}")
                    print(f"üìä Confidence: {rag_result.get('confidence', 0):.2f}")
                    
                except Exception as e:
                    cli_logger.error(f"‚ùå RAG/LLM processing failed: {e}")
                    print(f"‚ùå Processing failed: {e}")
                    continue
                
            except KeyboardInterrupt:
                print("\n\n‚èπÔ∏è Chat session interrupted by user")
                break
            except EOFError:
                print("\n\nüëã Chat session ended")
                break
            except Exception as e:
                cli_logger.error(f"‚ùå Unexpected error: {e}")
                print(f"‚ùå Unexpected error: {e}")
                continue
        
        # Session summary
        print(f"\nüìä Chat session summary:")
        print(f"  ‚Ä¢ Questions asked: {question_count}")
        print(f"  ‚Ä¢ System used: RAG + LLM")
        print(f"  ‚Ä¢ Model: {model_id}")
        
        cli_logger.info(f"‚úÖ Chat session ended. Questions processed: {question_count}")
        
    except Exception as e:
        cli_logger.error(f"‚ùå Chat session failed: {str(e)}")
        print(f"‚ùå Error starting chat: {str(e)}")
        raise typer.Exit(1)

@app.command("build")
def build_plant(
    template_id: Optional[int] = typer.Option(None, "--template-id", help="Plant template ID (1-22) - if not provided, will prompt interactively"),
    feedstock: Optional[str] = typer.Option(None, "--feedstock", help="Feedstock type - if not provided, will prompt interactively"),
    production_capacity: Optional[int] = typer.Option(None, "--production-capacity", help="Production capacity in tons/year - if not provided, will prompt interactively"),
    plant_location: Optional[str] = typer.Option(None, "--plant-location", help="Plant location - if not provided, will prompt interactively"),
    operating_hours: Optional[int] = typer.Option(None, "--operating-hours", help="Operating hours per year - if not provided, will prompt interactively"),
    verbose: bool = typer.Option(False, "--verbose/--no-verbose", help="Verbose logging"),
    output_file: Optional[Path] = typer.Option(None, "--output-file", help="Save results to JSON file"),
):
    """Build a modular chemical plant and perform financial analysis with interactive prompts."""
    try:
        # Setup logging
        logger = configure_logging(level="DEBUG" if verbose else "INFO")
        cli_logger = get_logger(__name__)
        
        cli_logger.info("üöÄ Starting Interactive Plant Builder")
        
        # Import required components
        from pynucleus.pipeline.plant_builder import PlantBuilder
        from pynucleus.pipeline.financial_analyzer import FinancialAnalyzer
        from pynucleus.data.mock_data_manager import MockDataManager
        
        # Initialize components
        plant_builder = PlantBuilder()
        financial_analyzer = FinancialAnalyzer()
        mock_data_manager = MockDataManager()
        
        # Get available templates
        templates = mock_data_manager.get_all_plant_templates()
        
        print("=" * 60)
        print("üè≠ INTERACTIVE MODULAR PLANT BUILDER")
        print("=" * 60)
        
        # Step 1: Template Selection
        if template_id is None:
            print("\nüìã Available Plant Templates:")
            print("-" * 40)
            for template in templates:
                print(f"{template['id']:2d}. {template['name']}")
                print(f"    Technology: {template['technology']}")
                print(f"    Description: {template['description']}")
                print()
            
            while True:
                try:
                    template_id = int(input("Enter template ID (1-22): ").strip())
                    if 1 <= template_id <= 22:
                        break
                    else:
                        print("‚ùå Please enter a valid template ID between 1 and 22.")
                except ValueError:
                    print("‚ùå Please enter a valid number.")
        
        # Get selected template details
        selected_template = next((t for t in templates if t['id'] == template_id), None)
        if not selected_template:
            raise ValueError(f"Template ID {template_id} not found")
        
        print(f"\n‚úÖ Selected: {selected_template['name']}")
        print(f"   Technology: {selected_template['technology']}")
        print(f"   Description: {selected_template['description']}")
        
        # Step 2: Feedstock Selection
        if feedstock is None:
            print(f"\nüåø Available feedstock options for {selected_template['name']}:")
            for i, option in enumerate(selected_template['feedstock_options'], 1):
                print(f"   {i}. {option}")
            
            while True:
                try:
                    choice = int(input(f"\nSelect feedstock (1-{len(selected_template['feedstock_options'])}): ").strip())
                    if 1 <= choice <= len(selected_template['feedstock_options']):
                        feedstock = selected_template['feedstock_options'][choice - 1]
                        break
                    else:
                        print(f"‚ùå Please enter a valid choice between 1 and {len(selected_template['feedstock_options'])}.")
                except ValueError:
                    print("‚ùå Please enter a valid number.")
        
        print(f"‚úÖ Selected feedstock: {feedstock}")
        
        # Step 3: Production Capacity
        if production_capacity is None:
            valid_range = selected_template['valid_ranges']['production_capacity_tpd']
            default_capacity = selected_template['default_parameters']['production_capacity_tpd']
            
            print(f"\nüìä Production Capacity:")
            print(f"   Valid range: {valid_range['min']:,} - {valid_range['max']:,} tons/day")
            print(f"   Default: {default_capacity:,} tons/day")
            
            while True:
                try:
                    user_input = input(f"Enter production capacity in tons/day (or press Enter for default): ").strip()
                    if user_input == "":
                        production_capacity = default_capacity
                        break
                    else:
                        production_capacity = int(user_input)
                        if valid_range['min'] <= production_capacity <= valid_range['max']:
                            break
                        else:
                            print(f"‚ùå Please enter a value between {valid_range['min']:,} and {valid_range['max']:,}.")
                except ValueError:
                    print("‚ùå Please enter a valid number.")
        
        print(f"‚úÖ Production capacity: {production_capacity:,} tons/day")
        
        # Step 4: Plant Location
        if plant_location is None:
            print(f"\nüìç Available locations (with cost factors):")
            for location, factor in selected_template['location_factors'].items():
                factor_text = "Standard" if factor == 1.0 else f"{factor:.1f}x cost"
                print(f"   ‚Ä¢ {location} ({factor_text})")
            
            while True:
                plant_location = input(f"\nEnter plant location (or press Enter for 'Texas, USA'): ").strip()
                if plant_location == "":
                    plant_location = "Texas, USA"
                    break
                elif plant_location in selected_template['location_factors']:
                    break
                else:
                    print("‚ùå Please enter a valid location from the list above.")
        
        print(f"‚úÖ Plant location: {plant_location}")
        
        # Step 5: Operating Hours
        if operating_hours is None:
            valid_range = selected_template['valid_ranges']['operating_hours']
            default_hours = selected_template['default_parameters']['operating_hours']
            
            print(f"\n‚è∞ Operating Hours:")
            print(f"   Valid range: {valid_range['min']:,} - {valid_range['max']:,} hours/year")
            print(f"   Default: {default_hours:,} hours/year")
            
            while True:
                try:
                    user_input = input(f"Enter operating hours per year (or press Enter for default): ").strip()
                    if user_input == "":
                        operating_hours = default_hours
                        break
                    else:
                        operating_hours = int(user_input)
                        if valid_range['min'] <= operating_hours <= valid_range['max']:
                            break
                        else:
                            print(f"‚ùå Please enter a value between {valid_range['min']:,} and {valid_range['max']:,}.")
                except ValueError:
                    print("‚ùå Please enter a valid number.")
        
        print(f"‚úÖ Operating hours: {operating_hours:,} hours/year")
        
        # Convert production capacity from tons/day to tons/year for the API
        production_capacity_tpy = production_capacity * 365
        
        # Prepare custom parameters
        custom_parameters = {
            "feedstock": feedstock,
            "production_capacity": production_capacity_tpy,  # API expects tons/year
            "plant_location": plant_location,
            "operating_hours": operating_hours
        }
        
        print("\n" + "=" * 60)
        print("üìã BUILD SUMMARY")
        print("=" * 60)
        print(f"Template: {selected_template['name']}")
        print(f"Technology: {selected_template['technology']}")
        print(f"Feedstock: {feedstock}")
        print(f"Production Capacity: {production_capacity:,} tons/day ({production_capacity_tpy:,} tons/year)")
        print(f"Location: {plant_location}")
        print(f"Operating Hours: {operating_hours:,} hours/year")
        print("=" * 60)
        
        # Confirm before proceeding
        proceed = input("\nProceed with plant build? (y/N): ").strip().lower()
        if proceed not in ['y', 'yes']:
            print("‚ùå Plant build cancelled.")
            return
        
        # Step 6: Build plant configuration
        print("\nüîÑ Step 1: Building plant configuration...")
        plant_config = plant_builder.build_plant(template_id, custom_parameters)
        
        print("‚úÖ Plant configuration built successfully!")
        print(f"   Template: {plant_config['template_info']['name']}")
        print(f"   Technology: {plant_config['template_info']['technology']}")
        print(f"   Capital Cost: ${plant_config['financial_parameters']['capital_cost']:,.0f}")
        print(f"   Operating Cost: ${plant_config['financial_parameters']['operating_cost']:,.0f}/year")
        print(f"   Product Price: ${plant_config['financial_parameters']['product_price']}/ton")
        
        # Step 7: Perform financial analysis
        print("\nüîÑ Step 2: Performing financial analysis...")
        financial_analysis = financial_analyzer.analyze_financials(plant_config)
        
        print("‚úÖ Financial analysis completed!")
        
        # Display results
        print("\n" + "=" * 60)
        print("üí∞ FINANCIAL ANALYSIS RESULTS")
        print("=" * 60)
        
        llm_analysis = financial_analysis.get("llm_analysis", {})
        basic_calc = financial_analysis.get("basic_calculations", {})
        
        print(f"Annual Revenue: ${llm_analysis.get('annual_revenue', 0):,.0f}")
        print(f"Profit Margin: {llm_analysis.get('profit_margin_percent', 0):.1f}%")
        print(f"ROI: {llm_analysis.get('roi_percent', 0):.1f}%")
        
        # Display risks
        risks = llm_analysis.get('financial_risks', [])
        if risks:
            print(f"\n‚ö†Ô∏è  Financial Risks:")
            for i, risk in enumerate(risks, 1):
                print(f"   {i}. {risk}")
        
        # Display recommendations
        recommendations = llm_analysis.get('strategic_recommendations', '')
        if recommendations:
            print(f"\nüí° Strategic Recommendations:")
            print(f"   {recommendations}")
        
        # Display basic calculations for verification
        print(f"\nüìä Basic Calculations (Verification):")
        print(f"   Annual Revenue: ${basic_calc.get('annual_revenue', 0):,.0f}")
        print(f"   Profit Margin: {basic_calc.get('profit_margin_percent', 0):.1f}%")
        print(f"   ROI: {basic_calc.get('roi_percent', 0):.1f}%")
        
        # Save results if output file specified
        if output_file:
            import json
            results = {
                "plant_configuration": plant_config,
                "financial_analysis": financial_analysis,
                "build_metadata": {
                    "template_id": template_id,
                    "custom_parameters": custom_parameters,
                    "build_timestamp": datetime.now().isoformat()
                }
            }
            
            output_file = Path(output_file)
            output_file.parent.mkdir(parents=True, exist_ok=True)
            
            with open(output_file, 'w') as f:
                json.dump(results, f, indent=2)
            
            print(f"\nüíæ Results saved to: {output_file}")
        
        print("=" * 60)
        print("üéâ Plant build and analysis completed successfully!")
        print("=" * 60)
        
        cli_logger.info("‚úÖ Plant build and analysis completed successfully")
        
    except ValueError as e:
        cli_logger.error(f"‚ùå Validation error: {str(e)}")
        print(f"‚ùå Validation error: {str(e)}")
        raise typer.Exit(1)
    except Exception as e:
        cli_logger.error(f"‚ùå Plant build failed: {str(e)}")
        print(f"‚ùå Plant build failed: {str(e)}")
        if verbose:
            import traceback
            traceback.print_exc()
        raise typer.Exit(1)

if __name__ == "__main__":
    app() 