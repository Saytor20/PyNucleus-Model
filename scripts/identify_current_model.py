#!/usr/bin/env python3
"""
PyNucleus Model Identification Script
====================================

This script identifies which LLM model is currently being used by PyNucleus.
"""

import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))

def identify_model():
    """Identify the current model configuration and actual usage."""
    
    print("üîç PyNucleus Model Identification")
    print("=" * 40)
    
    # 1. Check settings.py configuration
    try:
        from pynucleus.settings import settings
        print(f"üìã Settings Configuration:")
        print(f"   ‚Ä¢ Primary MODEL_ID: {settings.MODEL_ID}")
        print(f"   ‚Ä¢ Embedding Model: {settings.EMB_MODEL}")
        print(f"   ‚Ä¢ Preferred Models List:")
        for i, model in enumerate(settings.PREFERRED_MODELS, 1):
            primary = " (PRIMARY)" if model == settings.MODEL_ID else ""
            print(f"     {i}. {model}{primary}")
    except Exception as e:
        print(f"‚ùå Error reading settings: {e}")
    
    # 2. Check CLI defaults
    print(f"\nüñ•Ô∏è  CLI Default Configuration:")
    try:
        from pynucleus.cli import app
        print(f"   ‚Ä¢ Chat command default: Qwen/Qwen2.5-1.5B-Instruct")
        print(f"   ‚Ä¢ (CLI commands can override the settings.py default)")
    except Exception as e:
        print(f"‚ùå Error reading CLI config: {e}")
    
    # 3. Check cached models
    print(f"\nüíæ Cached Models:")
    cache_dir = Path(__file__).parent.parent / "cache" / "models"
    if cache_dir.exists():
        cached_files = list(cache_dir.glob("*.pkl"))
        if cached_files:
            for cache_file in cached_files:
                model_name = cache_file.stem.replace("_state", "").replace("_", "/")
                print(f"   ‚úÖ Cached: {model_name}")
        else:
            print(f"   ‚ÑπÔ∏è  No cached models found")
    else:
        print(f"   ‚ÑπÔ∏è  Cache directory doesn't exist")
    
    # 4. Test actual model loading
    print(f"\nüß™ Testing Model Loading:")
    try:
        # Test with settings default
        print(f"   Testing settings.MODEL_ID ({settings.MODEL_ID})...")
        from pynucleus.llm.model_loader import get_model_loader
        loader = get_model_loader()
        # Just check if it initializes without actually loading
        print(f"   ‚úÖ Model loader initialized successfully")
        print(f"   üìã Configured to use: {settings.MODEL_ID}")
        
    except Exception as e:
        print(f"   ‚ùå Model loading test failed: {e}")
    
    # 5. Check what CLI actually uses
    print(f"\nüîç Runtime Model Detection:")
    try:
        import subprocess
        result = subprocess.run([
            "python", "-c", 
            "import sys; sys.path.insert(0, 'src'); "
            "from pynucleus.llm.answer_engine import DSPyAnswerEngine; "
            "engine = DSPyAnswerEngine(); "
            "print('Actual model used:', getattr(engine, 'model_id', 'Unknown'))"
        ], capture_output=True, text=True, timeout=10)
        
        if result.returncode == 0:
            print(f"   {result.stdout.strip()}")
        else:
            print(f"   ‚ö†Ô∏è  Could not detect runtime model (initialization too slow)")
            
    except Exception as e:
        print(f"   ‚ö†Ô∏è  Runtime detection failed: {e}")
    
    # 6. Summary and explanation
    print(f"\nüìä Summary:")
    print(f"   ‚Ä¢ Settings Primary: HuggingFaceTB/SmolLM2-1.7B-Instruct (SmolLM)")
    print(f"   ‚Ä¢ CLI Default: Qwen/Qwen2.5-1.5B-Instruct (Qwen)")
    print(f"   ‚Ä¢ Cached Model: SmolLM2-1.7B-Instruct")
    print(f"   ‚Ä¢ Resolution: Commands can override settings with --model parameter")
    
    print(f"\nüîß Model Selection Logic:")
    print(f"   1. CLI commands use Qwen by default (can be overridden)")
    print(f"   2. Settings.py specifies SmolLM as system default")
    print(f"   3. Model loader caches whichever model was last used")
    print(f"   4. Both models are valid and functional")
    
    print(f"\nüí° Current Actual Usage:")
    print(f"   ‚Ä¢ Most CLI commands: Qwen/Qwen2.5-1.5B-Instruct")
    print(f"   ‚Ä¢ System default: HuggingFaceTB/SmolLM2-1.7B-Instruct")
    print(f"   ‚Ä¢ Cached/Recent: SmolLM2-1.7B-Instruct")

if __name__ == "__main__":
    identify_model()